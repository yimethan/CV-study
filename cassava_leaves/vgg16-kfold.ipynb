{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:41.742736Z",
     "iopub.status.busy": "2022-05-08T04:13:41.741911Z",
     "iopub.status.idle": "2022-05-08T04:13:47.164743Z",
     "shell.execute_reply": "2022-05-08T04:13:47.164016Z",
     "shell.execute_reply.started": "2022-05-08T04:13:41.742633Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers, applications, optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.166699Z",
     "iopub.status.busy": "2022-05-08T04:13:47.166440Z",
     "iopub.status.idle": "2022-05-08T04:13:47.171840Z",
     "shell.execute_reply": "2022-05-08T04:13:47.171131Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.166665Z"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 300\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.173585Z",
     "iopub.status.busy": "2022-05-08T04:13:47.173310Z",
     "iopub.status.idle": "2022-05-08T04:13:47.211285Z",
     "shell.execute_reply": "2022-05-08T04:13:47.210666Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.173547Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n",
    "train_path = '../input/cassava-leaf-disease-classification/train_images'\n",
    "\n",
    "train_path_second = '../input/more-cassava-disease/train/train/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_id = []\n",
    "second_label = []\n",
    "\n",
    "for img in os.listdir(os.path.join(train_path_second, 'cbb')):\n",
    "    second_id.append('/cbb/'+img)\n",
    "    second_label.append('0')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cbsd')):\n",
    "    second_id.append('/cbsd/'+img)\n",
    "    second_label.append('1')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cgm')):\n",
    "    second_id.append('/cgm/'+img)\n",
    "    second_label.append('2')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cmd')):\n",
    "    second_id.append('/cmd/'+img)\n",
    "    second_label.append('3')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'healthy')):\n",
    "    second_id.append('/healthy/'+img)\n",
    "    second_label.append('4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cbb/train-cbb-0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cbb/train-cbb-1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cbb/train-cbb-10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cbb/train-cbb-100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cbb/train-cbb-101.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image_id label\n",
       "0    /cbb/train-cbb-0.jpg     0\n",
       "1    /cbb/train-cbb-1.jpg     0\n",
       "2   /cbb/train-cbb-10.jpg     0\n",
       "3  /cbb/train-cbb-100.jpg     0\n",
       "4  /cbb/train-cbb-101.jpg     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_second = pd.DataFrame({'image_id':second_id, 'label':second_label})\n",
    "\n",
    "train_second.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del second_id\n",
    "del second_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.213506Z",
     "iopub.status.busy": "2022-05-08T04:13:47.213259Z",
     "iopub.status.idle": "2022-05-08T04:13:47.262727Z",
     "shell.execute_reply": "2022-05-08T04:13:47.262119Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.213472Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_path_first(image):\n",
    "    return os.path.join(train_path,image)\n",
    "\n",
    "def image_path_second(image):\n",
    "    return os.path.join(train_path_second, image)\n",
    "\n",
    "train['image_id'] = train['image_id'].apply(image_path_first)\n",
    "train_second['image_id'] = train_second['image_id'].apply(image_path_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.264008Z",
     "iopub.status.busy": "2022-05-08T04:13:47.263708Z",
     "iopub.status.idle": "2022-05-08T04:13:47.288860Z",
     "shell.execute_reply": "2022-05-08T04:13:47.288111Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.263972Z"
    }
   },
   "outputs": [],
   "source": [
    "train['label'] = train['label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id label\n",
       "0  ../input/cassava-leaf-disease-classification/t...     0\n",
       "1  ../input/cassava-leaf-disease-classification/t...     3\n",
       "2  ../input/cassava-leaf-disease-classification/t...     1\n",
       "3  ../input/cassava-leaf-disease-classification/t...     1\n",
       "4  ../input/cassava-leaf-disease-classification/t...     3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine dataframe to train\n",
    "\n",
    "combined_train = pd.concat([train, train_second], ignore_index=True)\n",
    "\n",
    "combined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27048</th>\n",
       "      <td>/healthy/train-healthy-95.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27049</th>\n",
       "      <td>/healthy/train-healthy-96.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27050</th>\n",
       "      <td>/healthy/train-healthy-97.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27051</th>\n",
       "      <td>/healthy/train-healthy-98.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27052</th>\n",
       "      <td>/healthy/train-healthy-99.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_id label\n",
       "27048  /healthy/train-healthy-95.jpg     4\n",
       "27049  /healthy/train-healthy-96.jpg     4\n",
       "27050  /healthy/train-healthy-97.jpg     4\n",
       "27051  /healthy/train-healthy-98.jpg     4\n",
       "27052  /healthy/train-healthy-99.jpg     4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del train_second\n",
    "\n",
    "train = combined_train\n",
    "\n",
    "del combined_train\n",
    "del train_path\n",
    "del train_path_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27048</th>\n",
       "      <td>/healthy/train-healthy-95.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27049</th>\n",
       "      <td>/healthy/train-healthy-96.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27050</th>\n",
       "      <td>/healthy/train-healthy-97.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27051</th>\n",
       "      <td>/healthy/train-healthy-98.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27052</th>\n",
       "      <td>/healthy/train-healthy-99.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_id label\n",
       "27048  /healthy/train-healthy-95.jpg     4\n",
       "27049  /healthy/train-healthy-96.jpg     4\n",
       "27050  /healthy/train-healthy-97.jpg     4\n",
       "27051  /healthy/train-healthy-98.jpg     4\n",
       "27052  /healthy/train-healthy-99.jpg     4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "SKF = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.290559Z",
     "iopub.status.busy": "2022-05-08T04:13:47.290182Z",
     "iopub.status.idle": "2022-05-08T04:13:47.297720Z",
     "shell.execute_reply": "2022-05-08T04:13:47.296743Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.290501Z"
    }
   },
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input,\n",
    "                                horizontal_flip=True, vertical_flip=True, fill_mode='nearest', brightness_range=[0.7, 1.3],\n",
    "                                rotation_range=270, zoom_range=0.2, shear_range=10, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                rescale = 1./255)\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input, rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:14:31.244455Z",
     "iopub.status.busy": "2022-05-08T04:14:31.244043Z",
     "iopub.status.idle": "2022-05-08T04:14:31.251411Z",
     "shell.execute_reply": "2022-05-08T04:14:31.250572Z",
     "shell.execute_reply.started": "2022-05-08T04:14:31.244416Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_vgg16():\n",
    "    model = Sequential()\n",
    "    model.add(VGG16(input_shape=(image_size,image_size,3), include_top=False, weights='imagenet'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:14:37.434280Z",
     "iopub.status.busy": "2022-05-08T04:14:37.434024Z",
     "iopub.status.idle": "2022-05-08T04:14:38.228147Z",
     "shell.execute_reply": "2022-05-08T04:14:38.227463Z",
     "shell.execute_reply.started": "2022-05-08T04:14:37.434245Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(train['label'])\n",
    "plt.title('Count of disease types')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_var = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4532 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17110 validated image filenames belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1124 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4287 validated image filenames belonging to 5 classes.\n",
      "Fold num: 1\n",
      "Train length: 1070\n",
      "Val length: 268\n",
      "Epoch 1/30\n",
      "   2/1070 [..............................] - ETA: 1:44 - loss: 1.9524 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0580s vs `on_train_batch_end` time: 0.1369s). Check your callbacks.\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.9434 - accuracy: 0.6601\n",
      "Epoch 00001: val_loss improved from inf to 0.78808, saving model to ./k_fold_vgg\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 419s 392ms/step - loss: 0.9434 - accuracy: 0.6601 - val_loss: 0.7881 - val_accuracy: 0.7108\n",
      "Epoch 2/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.7245 - accuracy: 0.7400\n",
      "Epoch 00002: val_loss improved from 0.78808 to 0.59684, saving model to ./k_fold_vgg\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 362s 338ms/step - loss: 0.7245 - accuracy: 0.7400 - val_loss: 0.5968 - val_accuracy: 0.7896\n",
      "Epoch 3/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.7826\n",
      "Epoch 00003: val_loss did not improve from 0.59684\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "1070/1070 [==============================] - 357s 334ms/step - loss: 0.6243 - accuracy: 0.7826 - val_loss: 0.6035 - val_accuracy: 0.7971\n",
      "Epoch 4/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.8217\n",
      "Epoch 00004: val_loss improved from 0.59684 to 0.50804, saving model to ./k_fold_vgg\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 359s 335ms/step - loss: 0.5076 - accuracy: 0.8217 - val_loss: 0.5080 - val_accuracy: 0.8265\n",
      "Epoch 5/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4901 - accuracy: 0.8290\n",
      "Epoch 00005: val_loss did not improve from 0.50804\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "1070/1070 [==============================] - 357s 333ms/step - loss: 0.4901 - accuracy: 0.8290 - val_loss: 0.5083 - val_accuracy: 0.8269\n",
      "Epoch 6/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.8423\n",
      "Epoch 00006: val_loss improved from 0.50804 to 0.48375, saving model to ./k_fold_vgg\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 360s 336ms/step - loss: 0.4584 - accuracy: 0.8423 - val_loss: 0.4838 - val_accuracy: 0.8400\n",
      "Epoch 7/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.8435\n",
      "Epoch 00007: val_loss improved from 0.48375 to 0.47782, saving model to ./k_fold_vgg\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 356s 333ms/step - loss: 0.4554 - accuracy: 0.8435 - val_loss: 0.4778 - val_accuracy: 0.8404\n",
      "Epoch 8/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.8454\n",
      "Epoch 00008: val_loss improved from 0.47782 to 0.46989, saving model to ./k_fold_vgg\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 362s 338ms/step - loss: 0.4489 - accuracy: 0.8454 - val_loss: 0.4699 - val_accuracy: 0.8430\n",
      "Epoch 9/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4466 - accuracy: 0.8457\n",
      "Epoch 00009: val_loss did not improve from 0.46989\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "1070/1070 [==============================] - 357s 333ms/step - loss: 0.4466 - accuracy: 0.8457 - val_loss: 0.4772 - val_accuracy: 0.8367\n",
      "Epoch 10/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.8490\n",
      "Epoch 00010: val_loss did not improve from 0.46989\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "1070/1070 [==============================] - 358s 334ms/step - loss: 0.4381 - accuracy: 0.8490 - val_loss: 0.4705 - val_accuracy: 0.8404\n",
      "Epoch 11/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.8505\n",
      "Epoch 00011: val_loss improved from 0.46989 to 0.46946, saving model to ./k_fold_vgg\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 360s 336ms/step - loss: 0.4389 - accuracy: 0.8505 - val_loss: 0.4695 - val_accuracy: 0.8404\n",
      "Epoch 12/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4364 - accuracy: 0.8490\n",
      "Epoch 00012: val_loss did not improve from 0.46946\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "1070/1070 [==============================] - 357s 334ms/step - loss: 0.4364 - accuracy: 0.8490 - val_loss: 0.4700 - val_accuracy: 0.8407\n",
      "Epoch 13/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8484\n",
      "Epoch 00013: val_loss did not improve from 0.46946\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "1070/1070 [==============================] - 362s 338ms/step - loss: 0.4366 - accuracy: 0.8484 - val_loss: 0.4697 - val_accuracy: 0.8397\n",
      "Epoch 14/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.8479Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.46946\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.279999928271991e-09.\n",
      "1070/1070 [==============================] - 358s 334ms/step - loss: 0.4388 - accuracy: 0.8479 - val_loss: 0.4697 - val_accuracy: 0.8402\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4491 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1165 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17151 validated image filenames belonging to 5 classes.\n",
      "Found 4246 validated image filenames belonging to 5 classes.\n",
      "Fold num: 2\n",
      "Train length: 1072\n",
      "Val length: 266\n",
      "Epoch 1/30\n",
      "   2/1072 [..............................] - ETA: 1:47 - loss: 1.5430 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0602s vs `on_train_batch_end` time: 0.1400s). Check your callbacks.\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.9811 - accuracy: 0.6462\n",
      "Epoch 00001: val_loss improved from inf to 0.79360, saving model to ./k_fold_vgg\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 359s 335ms/step - loss: 0.9811 - accuracy: 0.6462 - val_loss: 0.7936 - val_accuracy: 0.6931\n",
      "Epoch 2/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.7123 - accuracy: 0.7437\n",
      "Epoch 00002: val_loss improved from 0.79360 to 0.71126, saving model to ./k_fold_vgg\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 360s 336ms/step - loss: 0.7123 - accuracy: 0.7437 - val_loss: 0.7113 - val_accuracy: 0.7579\n",
      "Epoch 3/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.6314 - accuracy: 0.7811\n",
      "Epoch 00003: val_loss improved from 0.71126 to 0.58659, saving model to ./k_fold_vgg\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 362s 338ms/step - loss: 0.6314 - accuracy: 0.7811 - val_loss: 0.5866 - val_accuracy: 0.7965\n",
      "Epoch 4/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.7987\n",
      "Epoch 00004: val_loss did not improve from 0.58659\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "1072/1072 [==============================] - 360s 335ms/step - loss: 0.5847 - accuracy: 0.7987 - val_loss: 0.6377 - val_accuracy: 0.7810\n",
      "Epoch 5/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4858 - accuracy: 0.8358\n",
      "Epoch 00005: val_loss improved from 0.58659 to 0.49341, saving model to ./k_fold_vgg\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 358s 334ms/step - loss: 0.4858 - accuracy: 0.8358 - val_loss: 0.4934 - val_accuracy: 0.8290\n",
      "Epoch 6/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4703 - accuracy: 0.8380\n",
      "Epoch 00006: val_loss improved from 0.49341 to 0.45692, saving model to ./k_fold_vgg\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 358s 334ms/step - loss: 0.4703 - accuracy: 0.8380 - val_loss: 0.4569 - val_accuracy: 0.8448\n",
      "Epoch 7/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.8459\n",
      "Epoch 00007: val_loss improved from 0.45692 to 0.45208, saving model to ./k_fold_vgg\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 362s 337ms/step - loss: 0.4551 - accuracy: 0.8459 - val_loss: 0.4521 - val_accuracy: 0.8479\n",
      "Epoch 8/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.8429\n",
      "Epoch 00008: val_loss did not improve from 0.45208\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "1072/1072 [==============================] - 358s 334ms/step - loss: 0.4546 - accuracy: 0.8429 - val_loss: 0.4528 - val_accuracy: 0.8443\n",
      "Epoch 9/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.8528\n",
      "Epoch 00009: val_loss improved from 0.45208 to 0.44327, saving model to ./k_fold_vgg\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 360s 336ms/step - loss: 0.4264 - accuracy: 0.8528 - val_loss: 0.4433 - val_accuracy: 0.8512\n",
      "Epoch 10/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4234 - accuracy: 0.8553\n",
      "Epoch 00010: val_loss improved from 0.44327 to 0.43857, saving model to ./k_fold_vgg\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 357s 333ms/step - loss: 0.4234 - accuracy: 0.8553 - val_loss: 0.4386 - val_accuracy: 0.8507\n",
      "Epoch 11/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4181 - accuracy: 0.8555\n",
      "Epoch 00011: val_loss improved from 0.43857 to 0.43580, saving model to ./k_fold_vgg\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 357s 333ms/step - loss: 0.4181 - accuracy: 0.8555 - val_loss: 0.4358 - val_accuracy: 0.8526\n",
      "Epoch 12/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4182 - accuracy: 0.8566\n",
      "Epoch 00012: val_loss did not improve from 0.43580\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "1072/1072 [==============================] - 360s 336ms/step - loss: 0.4182 - accuracy: 0.8566 - val_loss: 0.4470 - val_accuracy: 0.8509\n",
      "Epoch 13/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8601\n",
      "Epoch 00013: val_loss did not improve from 0.43580\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "1072/1072 [==============================] - 356s 332ms/step - loss: 0.4049 - accuracy: 0.8601 - val_loss: 0.4400 - val_accuracy: 0.8519\n",
      "Epoch 14/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.8609Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.43580\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "1072/1072 [==============================] - 371s 346ms/step - loss: 0.4074 - accuracy: 0.8609 - val_loss: 0.4391 - val_accuracy: 0.8521\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4470 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1186 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17172 validated image filenames belonging to 5 classes.\n",
      "Found 4225 validated image filenames belonging to 5 classes.\n",
      "Fold num: 3\n",
      "Train length: 1074\n",
      "Val length: 265\n",
      "Epoch 1/30\n",
      "   2/1074 [..............................] - ETA: 1:49 - loss: 1.4855 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0609s vs `on_train_batch_end` time: 0.1433s). Check your callbacks.\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.9754 - accuracy: 0.6462\n",
      "Epoch 00001: val_loss improved from inf to 0.72012, saving model to ./k_fold_vgg\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 403s 375ms/step - loss: 0.9754 - accuracy: 0.6462 - val_loss: 0.7201 - val_accuracy: 0.7271\n",
      "Epoch 2/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.7141 - accuracy: 0.7452\n",
      "Epoch 00002: val_loss improved from 0.72012 to 0.63304, saving model to ./k_fold_vgg\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 355s 330ms/step - loss: 0.7141 - accuracy: 0.7452 - val_loss: 0.6330 - val_accuracy: 0.7688\n",
      "Epoch 3/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.6222 - accuracy: 0.7809\n",
      "Epoch 00003: val_loss improved from 0.63304 to 0.58187, saving model to ./k_fold_vgg\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 363s 338ms/step - loss: 0.6222 - accuracy: 0.7809 - val_loss: 0.5819 - val_accuracy: 0.7960\n",
      "Epoch 4/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.5748 - accuracy: 0.7979\n",
      "Epoch 00004: val_loss improved from 0.58187 to 0.54519, saving model to ./k_fold_vgg\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 358s 334ms/step - loss: 0.5748 - accuracy: 0.7979 - val_loss: 0.5452 - val_accuracy: 0.8036\n",
      "Epoch 5/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.8097\n",
      "Epoch 00005: val_loss improved from 0.54519 to 0.48912, saving model to ./k_fold_vgg\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 360s 335ms/step - loss: 0.5481 - accuracy: 0.8097 - val_loss: 0.4891 - val_accuracy: 0.8296\n",
      "Epoch 6/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.8208\n",
      "Epoch 00006: val_loss did not improve from 0.48912\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "1074/1074 [==============================] - 361s 336ms/step - loss: 0.5299 - accuracy: 0.8208 - val_loss: 0.5202 - val_accuracy: 0.8256\n",
      "Epoch 7/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.4442 - accuracy: 0.8471\n",
      "Epoch 00007: val_loss improved from 0.48912 to 0.44947, saving model to ./k_fold_vgg\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 358s 334ms/step - loss: 0.4442 - accuracy: 0.8471 - val_loss: 0.4495 - val_accuracy: 0.8445\n",
      "Epoch 8/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.4329 - accuracy: 0.8536\n",
      "Epoch 00008: val_loss improved from 0.44947 to 0.43392, saving model to ./k_fold_vgg\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 362s 337ms/step - loss: 0.4329 - accuracy: 0.8536 - val_loss: 0.4339 - val_accuracy: 0.8516\n",
      "Epoch 9/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.8582\n",
      "Epoch 00009: val_loss did not improve from 0.43392\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "1074/1074 [==============================] - 359s 334ms/step - loss: 0.4193 - accuracy: 0.8582 - val_loss: 0.4563 - val_accuracy: 0.8459\n",
      "Epoch 10/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.8650\n",
      "Epoch 00010: val_loss improved from 0.43392 to 0.43049, saving model to ./k_fold_vgg\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 359s 335ms/step - loss: 0.3994 - accuracy: 0.8650 - val_loss: 0.4305 - val_accuracy: 0.8542\n",
      "Epoch 11/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3951 - accuracy: 0.8652\n",
      "Epoch 00011: val_loss did not improve from 0.43049\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "1074/1074 [==============================] - 361s 336ms/step - loss: 0.3951 - accuracy: 0.8652 - val_loss: 0.4351 - val_accuracy: 0.8533\n",
      "Epoch 12/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.8676\n",
      "Epoch 00012: val_loss improved from 0.43049 to 0.42727, saving model to ./k_fold_vgg\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 358s 333ms/step - loss: 0.3922 - accuracy: 0.8676 - val_loss: 0.4273 - val_accuracy: 0.8561\n",
      "Epoch 13/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.8668\n",
      "Epoch 00013: val_loss did not improve from 0.42727\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "1074/1074 [==============================] - 363s 338ms/step - loss: 0.3933 - accuracy: 0.8668 - val_loss: 0.4273 - val_accuracy: 0.8549\n",
      "Epoch 14/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.8672\n",
      "Epoch 00014: val_loss did not improve from 0.42727\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "1074/1074 [==============================] - 359s 334ms/step - loss: 0.3926 - accuracy: 0.8672 - val_loss: 0.4275 - val_accuracy: 0.8554\n",
      "Epoch 15/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8677Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.42727\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "1074/1074 [==============================] - 359s 334ms/step - loss: 0.3912 - accuracy: 0.8677 - val_loss: 0.4274 - val_accuracy: 0.8554\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4563 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1093 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17080 validated image filenames belonging to 5 classes.\n",
      "Found 4317 validated image filenames belonging to 5 classes.\n",
      "Fold num: 4\n",
      "Train length: 1068\n",
      "Val length: 270\n",
      "Epoch 1/30\n",
      "   2/1068 [..............................] - ETA: 1:47 - loss: 2.1698 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0608s vs `on_train_batch_end` time: 0.1406s). Check your callbacks.\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.9492 - accuracy: 0.6539\n",
      "Epoch 00001: val_loss improved from inf to 0.69285, saving model to ./k_fold_vgg\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 361s 338ms/step - loss: 0.9492 - accuracy: 0.6539 - val_loss: 0.6928 - val_accuracy: 0.7582\n",
      "Epoch 2/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.7075 - accuracy: 0.7478\n",
      "Epoch 00002: val_loss improved from 0.69285 to 0.56300, saving model to ./k_fold_vgg\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 358s 335ms/step - loss: 0.7075 - accuracy: 0.7478 - val_loss: 0.5630 - val_accuracy: 0.8015\n",
      "Epoch 3/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.7877\n",
      "Epoch 00003: val_loss improved from 0.56300 to 0.53757, saving model to ./k_fold_vgg\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 359s 336ms/step - loss: 0.6118 - accuracy: 0.7877 - val_loss: 0.5376 - val_accuracy: 0.8082\n",
      "Epoch 4/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.8033\n",
      "Epoch 00004: val_loss did not improve from 0.53757\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "1068/1068 [==============================] - 358s 335ms/step - loss: 0.5673 - accuracy: 0.8033 - val_loss: 0.5803 - val_accuracy: 0.7927\n",
      "Epoch 5/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4783 - accuracy: 0.8376\n",
      "Epoch 00005: val_loss improved from 0.53757 to 0.46348, saving model to ./k_fold_vgg\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 357s 335ms/step - loss: 0.4783 - accuracy: 0.8376 - val_loss: 0.4635 - val_accuracy: 0.8429\n",
      "Epoch 6/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.8437\n",
      "Epoch 00006: val_loss did not improve from 0.46348\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "1068/1068 [==============================] - 360s 337ms/step - loss: 0.4611 - accuracy: 0.8437 - val_loss: 0.4661 - val_accuracy: 0.8416\n",
      "Epoch 7/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4354 - accuracy: 0.8501\n",
      "Epoch 00007: val_loss improved from 0.46348 to 0.44665, saving model to ./k_fold_vgg\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 357s 334ms/step - loss: 0.4354 - accuracy: 0.8501 - val_loss: 0.4466 - val_accuracy: 0.8511\n",
      "Epoch 8/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.8527\n",
      "Epoch 00008: val_loss improved from 0.44665 to 0.43710, saving model to ./k_fold_vgg\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 361s 338ms/step - loss: 0.4345 - accuracy: 0.8527 - val_loss: 0.4371 - val_accuracy: 0.8506\n",
      "Epoch 9/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4288 - accuracy: 0.8546\n",
      "Epoch 00009: val_loss improved from 0.43710 to 0.43640, saving model to ./k_fold_vgg\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 358s 335ms/step - loss: 0.4288 - accuracy: 0.8546 - val_loss: 0.4364 - val_accuracy: 0.8531\n",
      "Epoch 10/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.8541\n",
      "Epoch 00010: val_loss improved from 0.43640 to 0.43560, saving model to ./k_fold_vgg\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 357s 335ms/step - loss: 0.4247 - accuracy: 0.8541 - val_loss: 0.4356 - val_accuracy: 0.8536\n",
      "Epoch 11/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4245 - accuracy: 0.8543\n",
      "Epoch 00011: val_loss improved from 0.43560 to 0.43341, saving model to ./k_fold_vgg\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 361s 338ms/step - loss: 0.4245 - accuracy: 0.8543 - val_loss: 0.4334 - val_accuracy: 0.8527\n",
      "Epoch 12/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4187 - accuracy: 0.8570\n",
      "Epoch 00012: val_loss improved from 0.43341 to 0.42884, saving model to ./k_fold_vgg\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 357s 335ms/step - loss: 0.4187 - accuracy: 0.8570 - val_loss: 0.4288 - val_accuracy: 0.8594\n",
      "Epoch 13/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4182 - accuracy: 0.8569\n",
      "Epoch 00013: val_loss did not improve from 0.42884\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "1068/1068 [==============================] - 361s 338ms/step - loss: 0.4182 - accuracy: 0.8569 - val_loss: 0.4326 - val_accuracy: 0.8534\n",
      "Epoch 14/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.8642\n",
      "Epoch 00014: val_loss improved from 0.42884 to 0.42700, saving model to ./k_fold_vgg\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 359s 336ms/step - loss: 0.4088 - accuracy: 0.8642 - val_loss: 0.4270 - val_accuracy: 0.8550\n",
      "Epoch 15/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.8593\n",
      "Epoch 00015: val_loss did not improve from 0.42700\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "1068/1068 [==============================] - 358s 335ms/step - loss: 0.4088 - accuracy: 0.8593 - val_loss: 0.4299 - val_accuracy: 0.8557\n",
      "Epoch 16/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.8605\n",
      "Epoch 00016: val_loss did not improve from 0.42700\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "1068/1068 [==============================] - 361s 338ms/step - loss: 0.4054 - accuracy: 0.8605 - val_loss: 0.4276 - val_accuracy: 0.8578\n",
      "Epoch 17/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.8591Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.42700\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "1068/1068 [==============================] - 357s 334ms/step - loss: 0.4061 - accuracy: 0.8591 - val_loss: 0.4275 - val_accuracy: 0.8580\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4568 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1088 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17075 validated image filenames belonging to 5 classes.\n",
      "Found 4322 validated image filenames belonging to 5 classes.\n",
      "Fold num: 5\n",
      "Train length: 1068\n",
      "Val length: 271\n",
      "Epoch 1/30\n",
      "   2/1068 [..............................] - ETA: 1:47 - loss: 1.7522 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0598s vs `on_train_batch_end` time: 0.1426s). Check your callbacks.\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.9416 - accuracy: 0.6577\n",
      "Epoch 00001: val_loss improved from inf to 0.71775, saving model to ./k_fold_vgg\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 362s 339ms/step - loss: 0.9416 - accuracy: 0.6577 - val_loss: 0.7177 - val_accuracy: 0.7230\n",
      "Epoch 2/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.7507\n",
      "Epoch 00002: val_loss improved from 0.71775 to 0.57922, saving model to ./k_fold_vgg\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 361s 338ms/step - loss: 0.7137 - accuracy: 0.7507 - val_loss: 0.5792 - val_accuracy: 0.7832\n",
      "Epoch 3/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.7724\n",
      "Epoch 00003: val_loss did not improve from 0.57922\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "1068/1068 [==============================] - 358s 335ms/step - loss: 0.6512 - accuracy: 0.7724 - val_loss: 0.6045 - val_accuracy: 0.7714\n",
      "Epoch 4/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.8172\n",
      "Epoch 00004: val_loss improved from 0.57922 to 0.44458, saving model to ./k_fold_vgg\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 363s 340ms/step - loss: 0.5321 - accuracy: 0.8172 - val_loss: 0.4446 - val_accuracy: 0.8498\n",
      "Epoch 5/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.8289\n",
      "Epoch 00005: val_loss did not improve from 0.44458\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "1068/1068 [==============================] - 359s 336ms/step - loss: 0.4979 - accuracy: 0.8289 - val_loss: 0.4564 - val_accuracy: 0.8454\n",
      "Epoch 6/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4737 - accuracy: 0.8364\n",
      "Epoch 00006: val_loss improved from 0.44458 to 0.40438, saving model to ./k_fold_vgg\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 361s 338ms/step - loss: 0.4737 - accuracy: 0.8364 - val_loss: 0.4044 - val_accuracy: 0.8602\n",
      "Epoch 7/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.8374\n",
      "Epoch 00007: val_loss improved from 0.40438 to 0.39713, saving model to ./k_fold_vgg\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 360s 337ms/step - loss: 0.4671 - accuracy: 0.8374 - val_loss: 0.3971 - val_accuracy: 0.8651\n",
      "Epoch 8/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.8383\n",
      "Epoch 00008: val_loss did not improve from 0.39713\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "1068/1068 [==============================] - 358s 336ms/step - loss: 0.4622 - accuracy: 0.8383 - val_loss: 0.4029 - val_accuracy: 0.8607\n",
      "Epoch 9/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4550 - accuracy: 0.8441\n",
      "Epoch 00009: val_loss improved from 0.39713 to 0.39398, saving model to ./k_fold_vgg\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 363s 340ms/step - loss: 0.4550 - accuracy: 0.8441 - val_loss: 0.3940 - val_accuracy: 0.8653\n",
      "Epoch 10/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4592 - accuracy: 0.8428\n",
      "Epoch 00010: val_loss improved from 0.39398 to 0.39366, saving model to ./k_fold_vgg\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 358s 335ms/step - loss: 0.4592 - accuracy: 0.8428 - val_loss: 0.3937 - val_accuracy: 0.8656\n",
      "Epoch 11/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.8430\n",
      "Epoch 00011: val_loss improved from 0.39366 to 0.39225, saving model to ./k_fold_vgg\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 360s 338ms/step - loss: 0.4579 - accuracy: 0.8430 - val_loss: 0.3922 - val_accuracy: 0.8667\n",
      "Epoch 12/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.8449\n",
      "Epoch 00012: val_loss did not improve from 0.39225\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "1068/1068 [==============================] - 360s 337ms/step - loss: 0.4577 - accuracy: 0.8449 - val_loss: 0.3937 - val_accuracy: 0.8640\n",
      "Epoch 13/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.8429\n",
      "Epoch 00013: val_loss did not improve from 0.39225\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "1068/1068 [==============================] - 358s 335ms/step - loss: 0.4544 - accuracy: 0.8429 - val_loss: 0.3924 - val_accuracy: 0.8649\n",
      "Epoch 14/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4480 - accuracy: 0.8464Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.39225\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "1068/1068 [==============================] - 362s 339ms/step - loss: 0.4480 - accuracy: 0.8464 - val_loss: 0.3926 - val_accuracy: 0.8653\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "for train_idx, val_idx in SKF.split(train, train['label']):\n",
    "    training_data = train.iloc[train_idx]\n",
    "    validation_data = train.iloc[val_idx]\n",
    "    \n",
    "    # generator\n",
    "    train_generator = train_gen.flow_from_dataframe(dataframe=training_data, directory=None, x_col='image_id', y_col='label',\n",
    "                                                batch_size=batch_size, seed=1, shuffle=True,\n",
    "                                                class_mode='categorical', target_size=(image_size,image_size))\n",
    "\n",
    "    validation_generator = val_gen.flow_from_dataframe(dataframe=validation_data, directory=None, x_col='image_id', y_col='label',\n",
    "                                                   batch_size=batch_size, seed=1, shuffle=False,\n",
    "                                                   class_mode='categorical', target_size=(image_size,image_size))\n",
    "    \n",
    "    print('Fold num:', fold_var)\n",
    "    print('Train length:', len(train_generator))\n",
    "    print('Val length:', len(validation_generator))\n",
    "    \n",
    "    # build model\n",
    "    model = build_vgg16()\n",
    "    \n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    \n",
    "    # callbacks\n",
    "    checkpoint_filename = './k_fold_vgg/checkpoint_' + str(fold_var) + '.h5'\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_filename, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.2, patience=1, min_lr=0, verbose=1)\n",
    "    \n",
    "    # fit\n",
    "    history = model.fit(train_generator, epochs=30, validation_data=validation_generator, verbose=1,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "                        \n",
    "    # save model\n",
    "    model_filename = './k_fold_vgg/' + str(fold_var) + '.h5'\n",
    "    model.save(model_filename)\n",
    "    \n",
    "    clear_session()\n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/more-cassava-disease/sample_submission_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.132543Z",
     "iopub.status.busy": "2022-05-08T10:53:30.131436Z",
     "iopub.status.idle": "2022-05-08T10:53:30.139242Z",
     "shell.execute_reply": "2022-05-08T10:53:30.138534Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.132482Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = '../input/more-cassava-disease/test/test/test/0'\n",
    "\n",
    "def test_image_path(image):\n",
    "    return os.path.join(test_path,image)\n",
    "\n",
    "test['image_id'] = test['image_id'].apply(test_image_path)\n",
    "test['label'].replace('cbb', '0', inplace=True)\n",
    "test['label'].replace('cbsd', '1', inplace=True)\n",
    "test['label'].replace('cgm', '2', inplace=True)\n",
    "test['label'].replace('cmd', '3', inplace=True)\n",
    "test['label'].replace('healthy', '4', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.141294Z",
     "iopub.status.busy": "2022-05-08T10:53:30.140700Z",
     "iopub.status.idle": "2022-05-08T10:53:30.156795Z",
     "shell.execute_reply": "2022-05-08T10:53:30.156171Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.141256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3774 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = val_gen.flow_from_dataframe(dataframe=test, directory=None, x_col='image_id', y_col='label',\n",
    "                                              preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n",
    "                                              class_mode='categorical', target_size=(image_size,image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.158574Z",
     "iopub.status.busy": "2022-05-08T10:53:30.157879Z",
     "iopub.status.idle": "2022-05-08T10:53:30.468147Z",
     "shell.execute_reply": "2022-05-08T10:53:30.467298Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.158531Z"
    }
   },
   "outputs": [],
   "source": [
    "output = model.predict(test_generator)\n",
    "output = np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CBB       0.21      0.04      0.07       753\n",
      "        CBSD       0.19      0.17      0.18       731\n",
      "         CGM       0.20      0.22      0.21       706\n",
      "         CMD       0.21      0.43      0.29       800\n",
      "     Healthy       0.21      0.16      0.18       784\n",
      "\n",
      "    accuracy                           0.21      3774\n",
      "   macro avg       0.20      0.20      0.18      3774\n",
      "weighted avg       0.20      0.21      0.18      3774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(test_generator.classes, output, target_names=['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy'])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

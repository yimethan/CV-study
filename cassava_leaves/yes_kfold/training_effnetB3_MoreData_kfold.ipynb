{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:41.742736Z",
     "iopub.status.busy": "2022-05-08T04:13:41.741911Z",
     "iopub.status.idle": "2022-05-08T04:13:47.164743Z",
     "shell.execute_reply": "2022-05-08T04:13:47.164016Z",
     "shell.execute_reply.started": "2022-05-08T04:13:41.742633Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers, applications, optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.166699Z",
     "iopub.status.busy": "2022-05-08T04:13:47.166440Z",
     "iopub.status.idle": "2022-05-08T04:13:47.171840Z",
     "shell.execute_reply": "2022-05-08T04:13:47.171131Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.166665Z"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 300\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.173585Z",
     "iopub.status.busy": "2022-05-08T04:13:47.173310Z",
     "iopub.status.idle": "2022-05-08T04:13:47.211285Z",
     "shell.execute_reply": "2022-05-08T04:13:47.210666Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.173547Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n",
    "train_path = '../input/cassava-leaf-disease-classification/train_images'\n",
    "\n",
    "train_path_second = '../input/cassava-disease/train/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_id = []\n",
    "second_label = []\n",
    "\n",
    "for img in os.listdir(os.path.join(train_path_second, 'cbb')):\n",
    "    second_id.append('/cbb/'+img)\n",
    "    second_label.append('0')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cbsd')):\n",
    "    second_id.append('/cbsd/'+img)\n",
    "    second_label.append('1')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cgm')):\n",
    "    second_id.append('/cgm/'+img)\n",
    "    second_label.append('2')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cmd')):\n",
    "    second_id.append('/cmd/'+img)\n",
    "    second_label.append('3')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'healthy')):\n",
    "    second_id.append('/healthy/'+img)\n",
    "    second_label.append('4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cbb/train-cbb-0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cbb/train-cbb-1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cbb/train-cbb-10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cbb/train-cbb-100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cbb/train-cbb-101.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image_id label\n",
       "0    /cbb/train-cbb-0.jpg     0\n",
       "1    /cbb/train-cbb-1.jpg     0\n",
       "2   /cbb/train-cbb-10.jpg     0\n",
       "3  /cbb/train-cbb-100.jpg     0\n",
       "4  /cbb/train-cbb-101.jpg     0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_second = pd.DataFrame({'image_id':second_id, 'label':second_label})\n",
    "\n",
    "train_second.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "del second_id\n",
    "del second_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.213506Z",
     "iopub.status.busy": "2022-05-08T04:13:47.213259Z",
     "iopub.status.idle": "2022-05-08T04:13:47.262727Z",
     "shell.execute_reply": "2022-05-08T04:13:47.262119Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.213472Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_path_first(image):\n",
    "    return os.path.join(train_path,image)\n",
    "\n",
    "def image_path_second(image):\n",
    "    return os.path.join(train_path_second, image)\n",
    "\n",
    "train['image_id'] = train['image_id'].apply(image_path_first)\n",
    "train_second['image_id'] = train_second['image_id'].apply(image_path_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.264008Z",
     "iopub.status.busy": "2022-05-08T04:13:47.263708Z",
     "iopub.status.idle": "2022-05-08T04:13:47.288860Z",
     "shell.execute_reply": "2022-05-08T04:13:47.288111Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.263972Z"
    }
   },
   "outputs": [],
   "source": [
    "train['label'] = train['label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id label\n",
       "0  ../input/cassava-leaf-disease-classification/t...     0\n",
       "1  ../input/cassava-leaf-disease-classification/t...     3\n",
       "2  ../input/cassava-leaf-disease-classification/t...     1\n",
       "3  ../input/cassava-leaf-disease-classification/t...     1\n",
       "4  ../input/cassava-leaf-disease-classification/t...     3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine dataframe to train\n",
    "\n",
    "combined_train = pd.concat([train, train_second], ignore_index=True)\n",
    "\n",
    "combined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27048</th>\n",
       "      <td>/healthy/train-healthy-95.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27049</th>\n",
       "      <td>/healthy/train-healthy-96.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27050</th>\n",
       "      <td>/healthy/train-healthy-97.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27051</th>\n",
       "      <td>/healthy/train-healthy-98.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27052</th>\n",
       "      <td>/healthy/train-healthy-99.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_id label\n",
       "27048  /healthy/train-healthy-95.jpg     4\n",
       "27049  /healthy/train-healthy-96.jpg     4\n",
       "27050  /healthy/train-healthy-97.jpg     4\n",
       "27051  /healthy/train-healthy-98.jpg     4\n",
       "27052  /healthy/train-healthy-99.jpg     4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del train_second\n",
    "\n",
    "train = combined_train\n",
    "\n",
    "del combined_train\n",
    "del train_path\n",
    "del train_path_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27048</th>\n",
       "      <td>/healthy/train-healthy-95.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27049</th>\n",
       "      <td>/healthy/train-healthy-96.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27050</th>\n",
       "      <td>/healthy/train-healthy-97.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27051</th>\n",
       "      <td>/healthy/train-healthy-98.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27052</th>\n",
       "      <td>/healthy/train-healthy-99.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_id label\n",
       "27048  /healthy/train-healthy-95.jpg     4\n",
       "27049  /healthy/train-healthy-96.jpg     4\n",
       "27050  /healthy/train-healthy-97.jpg     4\n",
       "27051  /healthy/train-healthy-98.jpg     4\n",
       "27052  /healthy/train-healthy-99.jpg     4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "SKF = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.290559Z",
     "iopub.status.busy": "2022-05-08T04:13:47.290182Z",
     "iopub.status.idle": "2022-05-08T04:13:47.297720Z",
     "shell.execute_reply": "2022-05-08T04:13:47.296743Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.290501Z"
    }
   },
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
    "                                horizontal_flip=True, vertical_flip=True, fill_mode='nearest', brightness_range=[0.7, 1.3],\n",
    "                                rotation_range=270, zoom_range=0.2, shear_range=10, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                rescale = 1./255)\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:14:31.244455Z",
     "iopub.status.busy": "2022-05-08T04:14:31.244043Z",
     "iopub.status.idle": "2022-05-08T04:14:31.251411Z",
     "shell.execute_reply": "2022-05-08T04:14:31.250572Z",
     "shell.execute_reply.started": "2022-05-08T04:14:31.244416Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_efficientnet_b3():\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB3(input_shape=(image_size,image_size,3), include_top=False, weights='imagenet'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:14:37.434280Z",
     "iopub.status.busy": "2022-05-08T04:14:37.434024Z",
     "iopub.status.idle": "2022-05-08T04:14:38.228147Z",
     "shell.execute_reply": "2022-05-08T04:14:38.227463Z",
     "shell.execute_reply.started": "2022-05-08T04:14:37.434245Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(train['label'])\n",
    "plt.title('Count of disease types')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_var = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4547 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17095 validated image filenames belonging to 5 classes.\n",
      "Found 4302 validated image filenames belonging to 5 classes.\n",
      "Fold num: 1\n",
      "Train length: 1069\n",
      "Val length: 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1109 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.7885 - accuracy: 0.7233\n",
      "Epoch 00001: val_loss improved from inf to 1.79104, saving model to ./k_folds_model\\checkpoint_1.h5\n",
      "1069/1069 [==============================] - 389s 364ms/step - loss: 0.7885 - accuracy: 0.7233 - val_loss: 1.7910 - val_accuracy: 0.1188\n",
      "Epoch 2/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.6051 - accuracy: 0.7913\n",
      "Epoch 00002: val_loss did not improve from 1.79104\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "1069/1069 [==============================] - 388s 363ms/step - loss: 0.6051 - accuracy: 0.7913 - val_loss: 2.1064 - val_accuracy: 0.1188\n",
      "Epoch 3/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.4740 - accuracy: 0.8401\n",
      "Epoch 00003: val_loss did not improve from 1.79104\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "1069/1069 [==============================] - 384s 359ms/step - loss: 0.4740 - accuracy: 0.8401 - val_loss: 1.9627 - val_accuracy: 0.1364\n",
      "Epoch 4/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.4220 - accuracy: 0.8563\n",
      "Epoch 00004: val_loss improved from 1.79104 to 0.46540, saving model to ./k_folds_model\\checkpoint_1.h5\n",
      "1069/1069 [==============================] - 387s 362ms/step - loss: 0.4220 - accuracy: 0.8563 - val_loss: 0.4654 - val_accuracy: 0.8375\n",
      "Epoch 5/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.4112 - accuracy: 0.8588\n",
      "Epoch 00005: val_loss did not improve from 0.46540\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "1069/1069 [==============================] - 384s 359ms/step - loss: 0.4112 - accuracy: 0.8588 - val_loss: 0.5731 - val_accuracy: 0.7922\n",
      "Epoch 6/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.8639\n",
      "Epoch 00006: val_loss improved from 0.46540 to 0.37910, saving model to ./k_folds_model\\checkpoint_1.h5\n",
      "1069/1069 [==============================] - 386s 361ms/step - loss: 0.4008 - accuracy: 0.8639 - val_loss: 0.3791 - val_accuracy: 0.8677\n",
      "Epoch 7/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8621\n",
      "Epoch 00007: val_loss improved from 0.37910 to 0.37851, saving model to ./k_folds_model\\checkpoint_1.h5\n",
      "1069/1069 [==============================] - 385s 360ms/step - loss: 0.3998 - accuracy: 0.8621 - val_loss: 0.3785 - val_accuracy: 0.8675\n",
      "Epoch 8/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8657\n",
      "Epoch 00008: val_loss improved from 0.37851 to 0.37731, saving model to ./k_folds_model\\checkpoint_1.h5\n",
      "1069/1069 [==============================] - 386s 361ms/step - loss: 0.3942 - accuracy: 0.8657 - val_loss: 0.3773 - val_accuracy: 0.8680\n",
      "Epoch 9/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.8691\n",
      "Epoch 00009: val_loss improved from 0.37731 to 0.37508, saving model to ./k_folds_model\\checkpoint_1.h5\n",
      "1069/1069 [==============================] - 385s 360ms/step - loss: 0.3900 - accuracy: 0.8691 - val_loss: 0.3751 - val_accuracy: 0.8691\n",
      "Epoch 10/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3947 - accuracy: 0.8663\n",
      "Epoch 00010: val_loss did not improve from 0.37508\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "1069/1069 [==============================] - 383s 359ms/step - loss: 0.3947 - accuracy: 0.8663 - val_loss: 0.3769 - val_accuracy: 0.8668\n",
      "Epoch 11/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.8674\n",
      "Epoch 00011: val_loss improved from 0.37508 to 0.37417, saving model to ./k_folds_model\\checkpoint_1.h5\n",
      "1069/1069 [==============================] - 385s 360ms/step - loss: 0.3885 - accuracy: 0.8674 - val_loss: 0.3742 - val_accuracy: 0.8684\n",
      "Epoch 12/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8705\n",
      "Epoch 00012: val_loss did not improve from 0.37417\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "1069/1069 [==============================] - 384s 360ms/step - loss: 0.3851 - accuracy: 0.8705 - val_loss: 0.3774 - val_accuracy: 0.8654\n",
      "Epoch 13/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.8697\n",
      "Epoch 00013: val_loss did not improve from 0.37417\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "1069/1069 [==============================] - 391s 366ms/step - loss: 0.3868 - accuracy: 0.8697 - val_loss: 0.3760 - val_accuracy: 0.8668\n",
      "Epoch 14/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8715Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.37417\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "1069/1069 [==============================] - 388s 363ms/step - loss: 0.3838 - accuracy: 0.8715 - val_loss: 0.3752 - val_accuracy: 0.8666\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4552 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1104 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17090 validated image filenames belonging to 5 classes.\n",
      "Found 4307 validated image filenames belonging to 5 classes.\n",
      "Fold num: 2\n",
      "Train length: 1069\n",
      "Val length: 270\n",
      "Epoch 1/30\n",
      "   2/1069 [..............................] - ETA: 2:56 - loss: 1.7183 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1300s vs `on_train_batch_end` time: 0.2021s). Check your callbacks.\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.7644 - accuracy: 0.7339\n",
      "Epoch 00001: val_loss improved from inf to 1.27421, saving model to ./k_folds_model\\checkpoint_2.h5\n",
      "1069/1069 [==============================] - 392s 366ms/step - loss: 0.7644 - accuracy: 0.7339 - val_loss: 1.2742 - val_accuracy: 0.6167\n",
      "Epoch 2/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.7969\n",
      "Epoch 00002: val_loss did not improve from 1.27421\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "1069/1069 [==============================] - 390s 365ms/step - loss: 0.5918 - accuracy: 0.7969 - val_loss: 1.5882 - val_accuracy: 0.3466\n",
      "Epoch 3/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.8414\n",
      "Epoch 00003: val_loss did not improve from 1.27421\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "1069/1069 [==============================] - 389s 364ms/step - loss: 0.4695 - accuracy: 0.8414 - val_loss: 1.6604 - val_accuracy: 0.3097\n",
      "Epoch 4/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.4191 - accuracy: 0.8564\n",
      "Epoch 00004: val_loss improved from 1.27421 to 0.46260, saving model to ./k_folds_model\\checkpoint_2.h5\n",
      "1069/1069 [==============================] - 389s 364ms/step - loss: 0.4191 - accuracy: 0.8564 - val_loss: 0.4626 - val_accuracy: 0.8403\n",
      "Epoch 5/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.4100 - accuracy: 0.8606\n",
      "Epoch 00005: val_loss improved from 0.46260 to 0.44683, saving model to ./k_folds_model\\checkpoint_2.h5\n",
      "1069/1069 [==============================] - 390s 365ms/step - loss: 0.4100 - accuracy: 0.8606 - val_loss: 0.4468 - val_accuracy: 0.8486\n",
      "Epoch 6/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.8628\n",
      "Epoch 00006: val_loss did not improve from 0.44683\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "1069/1069 [==============================] - 389s 363ms/step - loss: 0.4048 - accuracy: 0.8628 - val_loss: 0.4558 - val_accuracy: 0.8451\n",
      "Epoch 7/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3940 - accuracy: 0.8645\n",
      "Epoch 00007: val_loss improved from 0.44683 to 0.39249, saving model to ./k_folds_model\\checkpoint_2.h5\n",
      "1069/1069 [==============================] - 391s 365ms/step - loss: 0.3940 - accuracy: 0.8645 - val_loss: 0.3925 - val_accuracy: 0.8670\n",
      "Epoch 8/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.8672\n",
      "Epoch 00008: val_loss improved from 0.39249 to 0.39063, saving model to ./k_folds_model\\checkpoint_2.h5\n",
      "1069/1069 [==============================] - 389s 364ms/step - loss: 0.3905 - accuracy: 0.8672 - val_loss: 0.3906 - val_accuracy: 0.8670\n",
      "Epoch 9/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8681\n",
      "Epoch 00009: val_loss did not improve from 0.39063\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "1069/1069 [==============================] - 391s 366ms/step - loss: 0.3894 - accuracy: 0.8681 - val_loss: 0.3962 - val_accuracy: 0.8630\n",
      "Epoch 10/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.8692\n",
      "Epoch 00010: val_loss improved from 0.39063 to 0.38950, saving model to ./k_folds_model\\checkpoint_2.h5\n",
      "1069/1069 [==============================] - 390s 365ms/step - loss: 0.3868 - accuracy: 0.8692 - val_loss: 0.3895 - val_accuracy: 0.8684\n",
      "Epoch 11/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8696\n",
      "Epoch 00011: val_loss improved from 0.38950 to 0.38658, saving model to ./k_folds_model\\checkpoint_2.h5\n",
      "1069/1069 [==============================] - 390s 365ms/step - loss: 0.3835 - accuracy: 0.8696 - val_loss: 0.3866 - val_accuracy: 0.8707\n",
      "Epoch 12/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8705\n",
      "Epoch 00012: val_loss improved from 0.38658 to 0.38621, saving model to ./k_folds_model\\checkpoint_2.h5\n",
      "1069/1069 [==============================] - 391s 365ms/step - loss: 0.3854 - accuracy: 0.8705 - val_loss: 0.3862 - val_accuracy: 0.8697\n",
      "Epoch 13/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8697\n",
      "Epoch 00013: val_loss did not improve from 0.38621\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "1069/1069 [==============================] - 385s 360ms/step - loss: 0.3851 - accuracy: 0.8697 - val_loss: 0.3879 - val_accuracy: 0.8681\n",
      "Epoch 14/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.8707\n",
      "Epoch 00014: val_loss did not improve from 0.38621\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "1069/1069 [==============================] - 392s 367ms/step - loss: 0.3842 - accuracy: 0.8707 - val_loss: 0.3889 - val_accuracy: 0.8684\n",
      "Epoch 15/30\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8695Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.38621\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "1069/1069 [==============================] - 388s 363ms/step - loss: 0.3830 - accuracy: 0.8695 - val_loss: 0.3874 - val_accuracy: 0.8677\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4525 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1131 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17117 validated image filenames belonging to 5 classes.\n",
      "Found 4280 validated image filenames belonging to 5 classes.\n",
      "Fold num: 3\n",
      "Train length: 1070\n",
      "Val length: 268\n",
      "Epoch 1/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.7693 - accuracy: 0.7268\n",
      "Epoch 00001: val_loss improved from inf to 8.32767, saving model to ./k_folds_model\\checkpoint_3.h5\n",
      "1070/1070 [==============================] - 392s 366ms/step - loss: 0.7693 - accuracy: 0.7268 - val_loss: 8.3277 - val_accuracy: 0.1491\n",
      "Epoch 2/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.5971 - accuracy: 0.7961\n",
      "Epoch 00002: val_loss improved from 8.32767 to 2.44796, saving model to ./k_folds_model\\checkpoint_3.h5\n",
      "1070/1070 [==============================] - 390s 364ms/step - loss: 0.5971 - accuracy: 0.7961 - val_loss: 2.4480 - val_accuracy: 0.1241\n",
      "Epoch 3/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.8070\n",
      "Epoch 00003: val_loss did not improve from 2.44796\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "1070/1070 [==============================] - 389s 364ms/step - loss: 0.5574 - accuracy: 0.8070 - val_loss: 2.4806 - val_accuracy: 0.1224\n",
      "Epoch 4/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.8473\n",
      "Epoch 00004: val_loss improved from 2.44796 to 1.76596, saving model to ./k_folds_model\\checkpoint_3.h5\n",
      "1070/1070 [==============================] - 389s 364ms/step - loss: 0.4516 - accuracy: 0.8473 - val_loss: 1.7660 - val_accuracy: 0.4280\n",
      "Epoch 5/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.8555\n",
      "Epoch 00005: val_loss improved from 1.76596 to 1.16900, saving model to ./k_folds_model\\checkpoint_3.h5\n",
      "1070/1070 [==============================] - 390s 364ms/step - loss: 0.4164 - accuracy: 0.8555 - val_loss: 1.1690 - val_accuracy: 0.5776\n",
      "Epoch 6/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4060 - accuracy: 0.8616\n",
      "Epoch 00006: val_loss did not improve from 1.16900\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "1070/1070 [==============================] - 390s 364ms/step - loss: 0.4060 - accuracy: 0.8616 - val_loss: 1.6317 - val_accuracy: 0.1273\n",
      "Epoch 7/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3722 - accuracy: 0.8710\n",
      "Epoch 00007: val_loss improved from 1.16900 to 0.50140, saving model to ./k_folds_model\\checkpoint_3.h5\n",
      "1070/1070 [==============================] - 390s 365ms/step - loss: 0.3722 - accuracy: 0.8710 - val_loss: 0.5014 - val_accuracy: 0.8327\n",
      "Epoch 8/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3638 - accuracy: 0.8731\n",
      "Epoch 00008: val_loss did not improve from 0.50140\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "1070/1070 [==============================] - 389s 363ms/step - loss: 0.3638 - accuracy: 0.8731 - val_loss: 0.5025 - val_accuracy: 0.8248\n",
      "Epoch 9/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3500 - accuracy: 0.8788\n",
      "Epoch 00009: val_loss improved from 0.50140 to 0.37745, saving model to ./k_folds_model\\checkpoint_3.h5\n",
      "1070/1070 [==============================] - 391s 365ms/step - loss: 0.3500 - accuracy: 0.8788 - val_loss: 0.3774 - val_accuracy: 0.8734\n",
      "Epoch 10/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3479 - accuracy: 0.8783\n",
      "Epoch 00010: val_loss did not improve from 0.37745\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "1070/1070 [==============================] - 389s 364ms/step - loss: 0.3479 - accuracy: 0.8783 - val_loss: 0.3836 - val_accuracy: 0.8706\n",
      "Epoch 11/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.8792\n",
      "Epoch 00011: val_loss improved from 0.37745 to 0.37708, saving model to ./k_folds_model\\checkpoint_3.h5\n",
      "1070/1070 [==============================] - 392s 367ms/step - loss: 0.3524 - accuracy: 0.8792 - val_loss: 0.3771 - val_accuracy: 0.8727\n",
      "Epoch 12/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3500 - accuracy: 0.8797\n",
      "Epoch 00012: val_loss improved from 0.37708 to 0.37605, saving model to ./k_folds_model\\checkpoint_3.h5\n",
      "1070/1070 [==============================] - 389s 363ms/step - loss: 0.3500 - accuracy: 0.8797 - val_loss: 0.3761 - val_accuracy: 0.8736\n",
      "Epoch 13/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.8784\n",
      "Epoch 00013: val_loss improved from 0.37605 to 0.37524, saving model to ./k_folds_model\\checkpoint_3.h5\n",
      "1070/1070 [==============================] - 386s 360ms/step - loss: 0.3507 - accuracy: 0.8784 - val_loss: 0.3752 - val_accuracy: 0.8724\n",
      "Epoch 14/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.8797\n",
      "Epoch 00014: val_loss did not improve from 0.37524\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "1070/1070 [==============================] - 385s 360ms/step - loss: 0.3518 - accuracy: 0.8797 - val_loss: 0.3775 - val_accuracy: 0.8717\n",
      "Epoch 15/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.8776\n",
      "Epoch 00015: val_loss did not improve from 0.37524\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "1070/1070 [==============================] - 386s 361ms/step - loss: 0.3536 - accuracy: 0.8776 - val_loss: 0.3767 - val_accuracy: 0.8729\n",
      "Epoch 16/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3533 - accuracy: 0.8794Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.37524\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "1070/1070 [==============================] - 385s 359ms/step - loss: 0.3533 - accuracy: 0.8794 - val_loss: 0.3766 - val_accuracy: 0.8715\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4505 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1151 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17138 validated image filenames belonging to 5 classes.\n",
      "Found 4259 validated image filenames belonging to 5 classes.\n",
      "Fold num: 4\n",
      "Train length: 1072\n",
      "Val length: 267\n",
      "Epoch 1/30\n",
      "   2/1072 [..............................] - ETA: 2:58 - loss: 1.5716 - accuracy: 0.4062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1307s vs `on_train_batch_end` time: 0.2044s). Check your callbacks.\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.7728 - accuracy: 0.7274\n",
      "Epoch 00001: val_loss improved from inf to 1.43441, saving model to ./k_folds_model\\checkpoint_4.h5\n",
      "1072/1072 [==============================] - 392s 365ms/step - loss: 0.7728 - accuracy: 0.7274 - val_loss: 1.4344 - val_accuracy: 0.6086\n",
      "Epoch 2/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.7890\n",
      "Epoch 00002: val_loss did not improve from 1.43441\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "1072/1072 [==============================] - 383s 357ms/step - loss: 0.6139 - accuracy: 0.7890 - val_loss: 1.5959 - val_accuracy: 0.1207\n",
      "Epoch 3/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4835 - accuracy: 0.8378\n",
      "Epoch 00003: val_loss did not improve from 1.43441\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "1072/1072 [==============================] - 383s 357ms/step - loss: 0.4835 - accuracy: 0.8378 - val_loss: 2.3213 - val_accuracy: 0.1601\n",
      "Epoch 4/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.8562\n",
      "Epoch 00004: val_loss improved from 1.43441 to 0.38311, saving model to ./k_folds_model\\checkpoint_4.h5\n",
      "1072/1072 [==============================] - 383s 358ms/step - loss: 0.4318 - accuracy: 0.8562 - val_loss: 0.3831 - val_accuracy: 0.8727\n",
      "Epoch 5/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4116 - accuracy: 0.8567\n",
      "Epoch 00005: val_loss did not improve from 0.38311\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "1072/1072 [==============================] - 4665s 4s/step - loss: 0.4116 - accuracy: 0.8567 - val_loss: 0.4548 - val_accuracy: 0.8392\n",
      "Epoch 6/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.8635\n",
      "Epoch 00006: val_loss improved from 0.38311 to 0.36316, saving model to ./k_folds_model\\checkpoint_4.h5\n",
      "1072/1072 [==============================] - 384s 358ms/step - loss: 0.3980 - accuracy: 0.8635 - val_loss: 0.3632 - val_accuracy: 0.8791\n",
      "Epoch 7/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3984 - accuracy: 0.8653\n",
      "Epoch 00007: val_loss improved from 0.36316 to 0.36187, saving model to ./k_folds_model\\checkpoint_4.h5\n",
      "1072/1072 [==============================] - 382s 356ms/step - loss: 0.3984 - accuracy: 0.8653 - val_loss: 0.3619 - val_accuracy: 0.8817\n",
      "Epoch 8/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3985 - accuracy: 0.8645\n",
      "Epoch 00008: val_loss did not improve from 0.36187\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "1072/1072 [==============================] - 382s 356ms/step - loss: 0.3985 - accuracy: 0.8645 - val_loss: 0.3700 - val_accuracy: 0.8774\n",
      "Epoch 9/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.8668\n",
      "Epoch 00009: val_loss improved from 0.36187 to 0.36161, saving model to ./k_folds_model\\checkpoint_4.h5\n",
      "1072/1072 [==============================] - 387s 361ms/step - loss: 0.3957 - accuracy: 0.8668 - val_loss: 0.3616 - val_accuracy: 0.8791\n",
      "Epoch 10/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.8674\n",
      "Epoch 00010: val_loss improved from 0.36161 to 0.36053, saving model to ./k_folds_model\\checkpoint_4.h5\n",
      "1072/1072 [==============================] - 390s 364ms/step - loss: 0.3971 - accuracy: 0.8674 - val_loss: 0.3605 - val_accuracy: 0.8798\n",
      "Epoch 11/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3910 - accuracy: 0.8676\n",
      "Epoch 00011: val_loss improved from 0.36053 to 0.35916, saving model to ./k_folds_model\\checkpoint_4.h5\n",
      "1072/1072 [==============================] - 391s 365ms/step - loss: 0.3910 - accuracy: 0.8676 - val_loss: 0.3592 - val_accuracy: 0.8798\n",
      "Epoch 12/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.8713\n",
      "Epoch 00012: val_loss did not improve from 0.35916\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "1072/1072 [==============================] - 389s 363ms/step - loss: 0.3868 - accuracy: 0.8713 - val_loss: 0.3596 - val_accuracy: 0.8805\n",
      "Epoch 13/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.8659\n",
      "Epoch 00013: val_loss did not improve from 0.35916\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "1072/1072 [==============================] - 389s 363ms/step - loss: 0.3920 - accuracy: 0.8659 - val_loss: 0.3604 - val_accuracy: 0.8805\n",
      "Epoch 14/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.8681\n",
      "Epoch 00014: val_loss improved from 0.35916 to 0.35870, saving model to ./k_folds_model\\checkpoint_4.h5\n",
      "1072/1072 [==============================] - 389s 363ms/step - loss: 0.3899 - accuracy: 0.8681 - val_loss: 0.3587 - val_accuracy: 0.8798\n",
      "Epoch 15/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3917 - accuracy: 0.8671\n",
      "Epoch 00015: val_loss did not improve from 0.35870\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "1072/1072 [==============================] - 390s 364ms/step - loss: 0.3917 - accuracy: 0.8671 - val_loss: 0.3591 - val_accuracy: 0.8798\n",
      "Epoch 16/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.8661\n",
      "Epoch 00016: val_loss did not improve from 0.35870\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
      "1072/1072 [==============================] - 391s 365ms/step - loss: 0.3915 - accuracy: 0.8661 - val_loss: 0.3608 - val_accuracy: 0.8791\n",
      "Epoch 17/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.8659Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.35870\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
      "1072/1072 [==============================] - 389s 363ms/step - loss: 0.3911 - accuracy: 0.8659 - val_loss: 0.3595 - val_accuracy: 0.8807\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4495 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1161 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17148 validated image filenames belonging to 5 classes.\n",
      "Found 4249 validated image filenames belonging to 5 classes.\n",
      "Fold num: 5\n",
      "Train length: 1072\n",
      "Val length: 266\n",
      "Epoch 1/30\n",
      "   2/1072 [..............................] - ETA: 3:01 - loss: 1.3127 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1297s vs `on_train_batch_end` time: 0.2095s). Check your callbacks.\n",
      " 105/1072 [=>............................] - ETA: 5:24 - loss: 1.0437 - accuracy: 0.6202"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[16,144,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sub_72 (defined at <ipython-input-18-88c43b419a63>:32) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_486072]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-88c43b419a63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     history = model.fit(train_generator, epochs=30, validation_data=validation_generator, verbose=1,\n\u001b[0m\u001b[0;32m     33\u001b[0m                         callbacks=[early_stopping, model_checkpoint, reduce_lr])\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[16,144,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sub_72 (defined at <ipython-input-18-88c43b419a63>:32) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_486072]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "for train_idx, val_idx in SKF.split(train, train['label']):\n",
    "    training_data = train.iloc[train_idx]\n",
    "    validation_data = train.iloc[val_idx]\n",
    "    \n",
    "    # generator\n",
    "    train_generator = train_gen.flow_from_dataframe(dataframe=training_data, directory=None, x_col='image_id', y_col='label',\n",
    "                                                batch_size=batch_size, seed=1, shuffle=True,\n",
    "                                                class_mode='categorical', target_size=(image_size,image_size))\n",
    "\n",
    "    validation_generator = val_gen.flow_from_dataframe(dataframe=validation_data, directory=None, x_col='image_id', y_col='label',\n",
    "                                                   batch_size=batch_size, seed=1, shuffle=False,\n",
    "                                                   class_mode='categorical', target_size=(image_size,image_size))\n",
    "    \n",
    "    print('Fold num:', fold_var)\n",
    "    print('Train length:', len(train_generator))\n",
    "    print('Val length:', len(validation_generator))\n",
    "    \n",
    "    # build model\n",
    "    model = build_efficientnet_b3()\n",
    "    \n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
    "    \n",
    "    # callbacks\n",
    "    checkpoint_filename = './k_folds_model/checkpoint_' + str(fold_var) + '.h5'\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_filename, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.2, patience=1, min_lr=0, verbose=1)\n",
    "    \n",
    "    # fit\n",
    "    history = model.fit(train_generator, epochs=30, validation_data=validation_generator, verbose=1,\n",
    "                        callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "                        \n",
    "    # save model\n",
    "    model_filename = './k_folds_model/' + str(fold_var) + '.h5'\n",
    "    model.save(model_filename)\n",
    "    \n",
    "    clear_session()\n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = [], []\n",
    "\n",
    "for i in SKF.split(train, train['label']):\n",
    "    train_idx, val_idx = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fold_var' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-264deedfda48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mfold_var\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fold_var' is not defined"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "del batch_size\n",
    "del fold_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4495 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1161 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17148 validated image filenames belonging to 5 classes.\n",
      "Found 4249 validated image filenames belonging to 5 classes.\n",
      "Fold num: 5\n",
      "Train length: 1072\n",
      "Val length: 266\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[16,144,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sub_72 (defined at <ipython-input-74-00c6b5bf148e>:37) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_627159]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-00c6b5bf148e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m history = model.fit(train_generator, epochs=30, validation_data=validation_generator, verbose=1,\n\u001b[0m\u001b[0;32m     38\u001b[0m                     callbacks=[early_stopping, model_checkpoint, reduce_lr])\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[16,144,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sub_72 (defined at <ipython-input-74-00c6b5bf148e>:37) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_627159]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "training_data = train.iloc[train_idx]\n",
    "validation_data = train.iloc[val_idx]\n",
    "    \n",
    "train_generator = train_gen.flow_from_dataframe(dataframe=training_data, directory=None, x_col='image_id', y_col='label',\n",
    "                                                batch_size=16, seed=1, shuffle=True,\n",
    "                                                class_mode='categorical', target_size=(300,300))\n",
    "\n",
    "validation_generator = val_gen.flow_from_dataframe(dataframe=validation_data, directory=None, x_col='image_id', y_col='label',\n",
    "                                                   batch_size=16, seed=1, shuffle=False,\n",
    "                                                   class_mode='categorical', target_size=(300,300))\n",
    "del train\n",
    "del train_gen\n",
    "del val_gen\n",
    "del training_data\n",
    "del validation_data\n",
    "del train_idx\n",
    "del val_idx\n",
    "    \n",
    "print('Fold num: 5')\n",
    "print('Train length:', len(train_generator))\n",
    "print('Val length:', len(validation_generator))\n",
    "    \n",
    "# build model\n",
    "model = build_efficientnet_b3()\n",
    "\n",
    "del image_size\n",
    "    \n",
    "# compile\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
    "    \n",
    "# callbacks   \n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('./k_folds_model/checkpoint_5.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.2, patience=1, min_lr=0, verbose=1)\n",
    "    \n",
    "# fit\n",
    "history = model.fit(train_generator, epochs=30, validation_data=validation_generator, verbose=1,\n",
    "                    callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "                        \n",
    "# save model\n",
    "model.save('./k_folds_model/5.h5')\n",
    "    \n",
    "# evaluate\n",
    "pred = model.predict(validation_generator)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "all_preds.append(pred)\n",
    "    \n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/cassava-disease/sample_submission_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.132543Z",
     "iopub.status.busy": "2022-05-08T10:53:30.131436Z",
     "iopub.status.idle": "2022-05-08T10:53:30.139242Z",
     "shell.execute_reply": "2022-05-08T10:53:30.138534Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.132482Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = '../input/cassava-disease/test/test/0'\n",
    "\n",
    "def test_image_path(image):\n",
    "    return os.path.join(test_path,image)\n",
    "\n",
    "test['image_id'] = test['image_id'].apply(test_image_path)\n",
    "test['label'].replace('cbb', '0')\n",
    "test['label'].replace('cbsd', '1')\n",
    "test['label'].replace('cgm', '2')\n",
    "test['label'].replace('cmd', '3')\n",
    "test['label'].replace('healthy', '4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.141294Z",
     "iopub.status.busy": "2022-05-08T10:53:30.140700Z",
     "iopub.status.idle": "2022-05-08T10:53:30.156795Z",
     "shell.execute_reply": "2022-05-08T10:53:30.156171Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.141256Z"
    }
   },
   "outputs": [],
   "source": [
    "test_generator = val_gen.flow_from_dataframe(dataframe=test, directory=None, x_col='image_id', y_col='label',\n",
    "                                              preprocessing_function=applications.efficientnet.preprocess_input,\n",
    "                                              class_mode='categorical', target_size=(300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.158574Z",
     "iopub.status.busy": "2022-05-08T10:53:30.157879Z",
     "iopub.status.idle": "2022-05-08T10:53:30.468147Z",
     "shell.execute_reply": "2022-05-08T10:53:30.467298Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.158531Z"
    }
   },
   "outputs": [],
   "source": [
    "output = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(test_generator.classes, output, target_names=['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(load_img('../input/cassava-leaf-disease-classification/test_images/2216849948.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

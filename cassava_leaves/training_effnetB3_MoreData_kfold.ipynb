{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:41.742736Z",
     "iopub.status.busy": "2022-05-08T04:13:41.741911Z",
     "iopub.status.idle": "2022-05-08T04:13:47.164743Z",
     "shell.execute_reply": "2022-05-08T04:13:47.164016Z",
     "shell.execute_reply.started": "2022-05-08T04:13:41.742633Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers, applications, optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.166699Z",
     "iopub.status.busy": "2022-05-08T04:13:47.166440Z",
     "iopub.status.idle": "2022-05-08T04:13:47.171840Z",
     "shell.execute_reply": "2022-05-08T04:13:47.171131Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.166665Z"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 300\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.173585Z",
     "iopub.status.busy": "2022-05-08T04:13:47.173310Z",
     "iopub.status.idle": "2022-05-08T04:13:47.211285Z",
     "shell.execute_reply": "2022-05-08T04:13:47.210666Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.173547Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n",
    "train_path = '../input/cassava-leaf-disease-classification/train_images'\n",
    "\n",
    "train_path_second = '../input/cassava-disease/train/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_id = []\n",
    "second_label = []\n",
    "\n",
    "for img in os.listdir(os.path.join(train_path_second, 'cbb')):\n",
    "    second_id.append('/cbb/'+img)\n",
    "    second_label.append('0')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cbsd')):\n",
    "    second_id.append('/cbsd/'+img)\n",
    "    second_label.append('1')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cgm')):\n",
    "    second_id.append('/cgm/'+img)\n",
    "    second_label.append('2')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cmd')):\n",
    "    second_id.append('/cmd/'+img)\n",
    "    second_label.append('3')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'healthy')):\n",
    "    second_id.append('/healthy/'+img)\n",
    "    second_label.append('4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cbb/train-cbb-0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cbb/train-cbb-1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cbb/train-cbb-10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cbb/train-cbb-100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cbb/train-cbb-101.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image_id label\n",
       "0    /cbb/train-cbb-0.jpg     0\n",
       "1    /cbb/train-cbb-1.jpg     0\n",
       "2   /cbb/train-cbb-10.jpg     0\n",
       "3  /cbb/train-cbb-100.jpg     0\n",
       "4  /cbb/train-cbb-101.jpg     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_second = pd.DataFrame({'image_id':second_id, 'label':second_label})\n",
    "\n",
    "train_second.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del second_id\n",
    "del second_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.213506Z",
     "iopub.status.busy": "2022-05-08T04:13:47.213259Z",
     "iopub.status.idle": "2022-05-08T04:13:47.262727Z",
     "shell.execute_reply": "2022-05-08T04:13:47.262119Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.213472Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_path_first(image):\n",
    "    return os.path.join(train_path,image)\n",
    "\n",
    "def image_path_second(image):\n",
    "    return os.path.join(train_path_second, image)\n",
    "\n",
    "train['image_id'] = train['image_id'].apply(image_path_first)\n",
    "train_second['image_id'] = train_second['image_id'].apply(image_path_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.264008Z",
     "iopub.status.busy": "2022-05-08T04:13:47.263708Z",
     "iopub.status.idle": "2022-05-08T04:13:47.288860Z",
     "shell.execute_reply": "2022-05-08T04:13:47.288111Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.263972Z"
    }
   },
   "outputs": [],
   "source": [
    "train['label'] = train['label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id label\n",
       "0  ../input/cassava-leaf-disease-classification/t...     0\n",
       "1  ../input/cassava-leaf-disease-classification/t...     3\n",
       "2  ../input/cassava-leaf-disease-classification/t...     1\n",
       "3  ../input/cassava-leaf-disease-classification/t...     1\n",
       "4  ../input/cassava-leaf-disease-classification/t...     3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine dataframe to train\n",
    "\n",
    "combined_train = pd.concat([train, train_second], ignore_index=True)\n",
    "\n",
    "combined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27048</th>\n",
       "      <td>/healthy/train-healthy-95.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27049</th>\n",
       "      <td>/healthy/train-healthy-96.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27050</th>\n",
       "      <td>/healthy/train-healthy-97.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27051</th>\n",
       "      <td>/healthy/train-healthy-98.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27052</th>\n",
       "      <td>/healthy/train-healthy-99.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_id label\n",
       "27048  /healthy/train-healthy-95.jpg     4\n",
       "27049  /healthy/train-healthy-96.jpg     4\n",
       "27050  /healthy/train-healthy-97.jpg     4\n",
       "27051  /healthy/train-healthy-98.jpg     4\n",
       "27052  /healthy/train-healthy-99.jpg     4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del train_second\n",
    "\n",
    "train = combined_train\n",
    "\n",
    "del combined_train\n",
    "del train_path\n",
    "del train_path_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27048</th>\n",
       "      <td>/healthy/train-healthy-95.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27049</th>\n",
       "      <td>/healthy/train-healthy-96.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27050</th>\n",
       "      <td>/healthy/train-healthy-97.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27051</th>\n",
       "      <td>/healthy/train-healthy-98.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27052</th>\n",
       "      <td>/healthy/train-healthy-99.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_id label\n",
       "27048  /healthy/train-healthy-95.jpg     4\n",
       "27049  /healthy/train-healthy-96.jpg     4\n",
       "27050  /healthy/train-healthy-97.jpg     4\n",
       "27051  /healthy/train-healthy-98.jpg     4\n",
       "27052  /healthy/train-healthy-99.jpg     4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "SKF = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.290559Z",
     "iopub.status.busy": "2022-05-08T04:13:47.290182Z",
     "iopub.status.idle": "2022-05-08T04:13:47.297720Z",
     "shell.execute_reply": "2022-05-08T04:13:47.296743Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.290501Z"
    }
   },
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
    "                                horizontal_flip=True, vertical_flip=True, fill_mode='nearest', brightness_range=[0.7, 1.3],\n",
    "                                rotation_range=270, zoom_range=0.2, shear_range=10, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                rescale = 1./255)\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:14:31.244455Z",
     "iopub.status.busy": "2022-05-08T04:14:31.244043Z",
     "iopub.status.idle": "2022-05-08T04:14:31.251411Z",
     "shell.execute_reply": "2022-05-08T04:14:31.250572Z",
     "shell.execute_reply.started": "2022-05-08T04:14:31.244416Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_efficientnet_b3():\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB3(input_shape=(image_size,image_size,3), include_top=False, weights='imagenet'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:14:37.434280Z",
     "iopub.status.busy": "2022-05-08T04:14:37.434024Z",
     "iopub.status.idle": "2022-05-08T04:14:38.228147Z",
     "shell.execute_reply": "2022-05-08T04:14:38.227463Z",
     "shell.execute_reply.started": "2022-05-08T04:14:37.434245Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(train['label'])\n",
    "plt.title('Count of disease types')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "fold_var = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 5656 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21397 validated image filenames belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 5656 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21397 validated image filenames belonging to 5 classes.\n",
      "Train length: 1338\n",
      "Val length: 1338\n",
      "Epoch 1/30\n",
      "   2/1338 [..............................] - ETA: 3:48 - loss: 1.6797 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1357s vs `on_train_batch_end` time: 0.2075s). Check your callbacks.\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.7362 - accuracy: 0.7418\n",
      "Epoch 00001: val_loss improved from inf to 1.36735, saving model to ./k_folds_model\\1.ckpt\n",
      "WARNING:tensorflow:From C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./k_folds_model\\1.ckpt\\assets\n",
      "1338/1338 [==============================] - 647s 484ms/step - loss: 0.7362 - accuracy: 0.7418 - val_loss: 1.3673 - val_accuracy: 0.4618\n",
      "Epoch 2/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.8015\n",
      "Epoch 00002: val_loss did not improve from 1.36735\n",
      "1338/1338 [==============================] - 586s 438ms/step - loss: 0.5817 - accuracy: 0.8015 - val_loss: 7.2965 - val_accuracy: 0.1022\n",
      "Epoch 3/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.8176\n",
      "Epoch 00003: val_loss did not improve from 1.36735\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "1338/1338 [==============================] - 584s 437ms/step - loss: 0.5330 - accuracy: 0.8176 - val_loss: 3.1798 - val_accuracy: 0.1204\n",
      "Epoch 4/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.4359 - accuracy: 0.8547\n",
      "Epoch 00004: val_loss did not improve from 1.36735\n",
      "1338/1338 [==============================] - 581s 434ms/step - loss: 0.4359 - accuracy: 0.8547 - val_loss: 3.4569 - val_accuracy: 0.1303\n",
      "Epoch 5/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.4096 - accuracy: 0.8633\n",
      "Epoch 00005: val_loss did not improve from 1.36735\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "1338/1338 [==============================] - 578s 432ms/step - loss: 0.4096 - accuracy: 0.8633 - val_loss: 1.9874 - val_accuracy: 0.3203\n",
      "Epoch 6/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3759 - accuracy: 0.8733\n",
      "Epoch 00006: val_loss improved from 1.36735 to 0.45696, saving model to ./k_folds_model\\1.ckpt\n",
      "INFO:tensorflow:Assets written to: ./k_folds_model\\1.ckpt\\assets\n",
      "1338/1338 [==============================] - 643s 480ms/step - loss: 0.3759 - accuracy: 0.8733 - val_loss: 0.4570 - val_accuracy: 0.8375\n",
      "Epoch 7/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.8726\n",
      "Epoch 00007: val_loss improved from 0.45696 to 0.35357, saving model to ./k_folds_model\\1.ckpt\n",
      "INFO:tensorflow:Assets written to: ./k_folds_model\\1.ckpt\\assets\n",
      "1338/1338 [==============================] - 648s 484ms/step - loss: 0.3738 - accuracy: 0.8726 - val_loss: 0.3536 - val_accuracy: 0.8789\n",
      "Epoch 8/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.8754\n",
      "Epoch 00008: val_loss improved from 0.35357 to 0.34404, saving model to ./k_folds_model\\1.ckpt\n",
      "INFO:tensorflow:Assets written to: ./k_folds_model\\1.ckpt\\assets\n",
      "1338/1338 [==============================] - 649s 485ms/step - loss: 0.3661 - accuracy: 0.8754 - val_loss: 0.3440 - val_accuracy: 0.8807\n",
      "Epoch 9/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.8782\n",
      "Epoch 00009: val_loss did not improve from 0.34404\n",
      "1338/1338 [==============================] - 595s 445ms/step - loss: 0.3593 - accuracy: 0.8782 - val_loss: 0.3636 - val_accuracy: 0.8726\n",
      "Epoch 10/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.8780\n",
      "Epoch 00010: val_loss did not improve from 0.34404\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "1338/1338 [==============================] - 592s 443ms/step - loss: 0.3559 - accuracy: 0.8780 - val_loss: 0.3539 - val_accuracy: 0.8754\n",
      "Epoch 11/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3487 - accuracy: 0.8810\n",
      "Epoch 00011: val_loss improved from 0.34404 to 0.31857, saving model to ./k_folds_model\\1.ckpt\n",
      "INFO:tensorflow:Assets written to: ./k_folds_model\\1.ckpt\\assets\n",
      "1338/1338 [==============================] - 657s 491ms/step - loss: 0.3487 - accuracy: 0.8810 - val_loss: 0.3186 - val_accuracy: 0.8900\n",
      "Epoch 12/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.8802\n",
      "Epoch 00012: val_loss did not improve from 0.31857\n",
      "1338/1338 [==============================] - 595s 445ms/step - loss: 0.3504 - accuracy: 0.8802 - val_loss: 0.3270 - val_accuracy: 0.8847\n",
      "Epoch 13/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.8811\n",
      "Epoch 00013: val_loss improved from 0.31857 to 0.31689, saving model to ./k_folds_model\\1.ckpt\n",
      "INFO:tensorflow:Assets written to: ./k_folds_model\\1.ckpt\\assets\n",
      "1338/1338 [==============================] - 660s 493ms/step - loss: 0.3468 - accuracy: 0.8811 - val_loss: 0.3169 - val_accuracy: 0.8898\n",
      "Epoch 14/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.8820\n",
      "Epoch 00014: val_loss improved from 0.31689 to 0.31195, saving model to ./k_folds_model\\1.ckpt\n",
      "INFO:tensorflow:Assets written to: ./k_folds_model\\1.ckpt\\assets\n",
      "1338/1338 [==============================] - 660s 494ms/step - loss: 0.3446 - accuracy: 0.8820 - val_loss: 0.3119 - val_accuracy: 0.8919\n",
      "Epoch 15/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3413 - accuracy: 0.8822\n",
      "Epoch 00015: val_loss did not improve from 0.31195\n",
      "1338/1338 [==============================] - 597s 446ms/step - loss: 0.3413 - accuracy: 0.8822 - val_loss: 0.3138 - val_accuracy: 0.8917\n",
      "Epoch 16/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.8829\n",
      "Epoch 00016: val_loss did not improve from 0.31195\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "1338/1338 [==============================] - 596s 446ms/step - loss: 0.3430 - accuracy: 0.8829 - val_loss: 0.3169 - val_accuracy: 0.8903\n",
      "Epoch 17/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3385 - accuracy: 0.8820\n",
      "Epoch 00017: val_loss did not improve from 0.31195\n",
      "1338/1338 [==============================] - 596s 446ms/step - loss: 0.3385 - accuracy: 0.8820 - val_loss: 0.3142 - val_accuracy: 0.8907\n",
      "Epoch 18/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3439 - accuracy: 0.8835\n",
      "Epoch 00018: val_loss did not improve from 0.31195\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "1338/1338 [==============================] - 595s 445ms/step - loss: 0.3439 - accuracy: 0.8835 - val_loss: 0.3142 - val_accuracy: 0.8902\n",
      "Epoch 19/30\n",
      "1338/1338 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.8856Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.31195\n",
      "1338/1338 [==============================] - 596s 445ms/step - loss: 0.3421 - accuracy: 0.8856 - val_loss: 0.3136 - val_accuracy: 0.8908\n",
      "Epoch 00019: early stopping\n"
     ]
    },
    {
     "ename": "OpError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[1;34m(filepattern)\u001b[0m\n\u001b[0;32m     94\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m   \u001b[1;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOpError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-0280d11d8939>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# save model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mmodel_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./k_folds_model'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold_var\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2176\u001b[1;33m         \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2177\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2178\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[1;34m(filepattern)\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[1;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0merror_translator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInternalError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNKNOWN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOpError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for train_idx, val_idx in SKF.split(train, train['label']):\n",
    "    training_data = train.iloc[train_idx]\n",
    "    validation_data = train.iloc[val_idx]\n",
    "    \n",
    "    # generator\n",
    "    train_generator = train_gen.flow_from_dataframe(dataframe=train, directory=None, x_col='image_id', y_col='label',\n",
    "                                                batch_size=batch_size, seed=1, shuffle=True,\n",
    "                                                class_mode='categorical', target_size=(image_size,image_size))\n",
    "\n",
    "    validation_generator = val_gen.flow_from_dataframe(dataframe=train, directory=None, x_col='image_id', y_col='label',\n",
    "                                                   batch_size=batch_size, seed=1, shuffle=False,\n",
    "                                                   class_mode='categorical', target_size=(image_size,image_size))\n",
    "    \n",
    "    print('Train length:', len(train_generator))\n",
    "    print('Val length:', len(validation_generator))\n",
    "    \n",
    "    # build model\n",
    "    model = build_efficientnet_b3()\n",
    "    \n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
    "    \n",
    "    # callbacks\n",
    "    checkpoint_filename = './k_folds_model/' + str(fold_var) + '.ckpt'\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_filename, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.2, patience=2, min_lr=0, verbose=1)\n",
    "    \n",
    "    # fit\n",
    "    history = model.fit(train_generator, epochs=30, validation_data=validation_generator, verbose=1,\n",
    "                        callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "                        \n",
    "    # save model\n",
    "    model.save(checkpoint_filename)\n",
    "    model_filename = './k_folds_model/' + str(fold_var) + '.h5'\n",
    "    \n",
    "    # evaluate\n",
    "    results = model.evaluate(validation_generator)\n",
    "    scores.append(results)\n",
    "    \n",
    "    clear_session()\n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:50:58.605371Z",
     "iopub.status.busy": "2022-05-08T10:50:58.605132Z",
     "iopub.status.idle": "2022-05-08T10:50:58.867840Z",
     "shell.execute_reply": "2022-05-08T10:50:58.867108Z",
     "shell.execute_reply.started": "2022-05-08T10:50:58.605336Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Train loss:'+train_loss)\n",
    "print('Train accuracy:'+train_accuracy)\n",
    "print('Val loss:'+validation_loss)\n",
    "print('Val accuracy:'+validation_accuracy)\n",
    "\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/cassava-disease/sample_submission_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.132543Z",
     "iopub.status.busy": "2022-05-08T10:53:30.131436Z",
     "iopub.status.idle": "2022-05-08T10:53:30.139242Z",
     "shell.execute_reply": "2022-05-08T10:53:30.138534Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.132482Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = '../input/cassava-disease/test/test/0'\n",
    "\n",
    "def test_image_path(image):\n",
    "    return os.path.join(test_path,image)\n",
    "\n",
    "test['image_id'] = test['image_id'].apply(test_image_path)\n",
    "test['label'].replace('cbb', '0')\n",
    "test['label'].replace('cbsd', '1')\n",
    "test['label'].replace('cgm', '2')\n",
    "test['label'].replace('cmd', '3')\n",
    "test['label'].replace('healthy', '4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.141294Z",
     "iopub.status.busy": "2022-05-08T10:53:30.140700Z",
     "iopub.status.idle": "2022-05-08T10:53:30.156795Z",
     "shell.execute_reply": "2022-05-08T10:53:30.156171Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.141256Z"
    }
   },
   "outputs": [],
   "source": [
    "test_generator = val_gen.flow_from_dataframe(dataframe=test, directory=None, x_col='image_id', y_col='label',\n",
    "                                              preprocessing_function=applications.efficientnet.preprocess_input,\n",
    "                                              class_mode='categorical', target_size=(image_size,image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.158574Z",
     "iopub.status.busy": "2022-05-08T10:53:30.157879Z",
     "iopub.status.idle": "2022-05-08T10:53:30.468147Z",
     "shell.execute_reply": "2022-05-08T10:53:30.467298Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.158531Z"
    }
   },
   "outputs": [],
   "source": [
    "output = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(test_generator.classes, output, target_names=['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(load_img('../input/cassava-leaf-disease-classification/test_images/2216849948.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0968c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f7bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b15195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers, applications, optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "print(os.listdir(\"./input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 3\n",
    "batch_size = 5\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "filenames = os.listdir(\"./input/train/train\")\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        categories.append('dog')\n",
    "    else:\n",
    "        categories.append('cat')\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b918065",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26456ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see sample image\n",
    "\n",
    "sample = random.choice(filenames)\n",
    "image = load_img(\"./input/train/train/\"+sample)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_block(input_layer, num_cnn=3, channel=64, block_num=1,is_50 = False,is_plain = False):\n",
    "\n",
    "    x = input_layer\n",
    "    \n",
    "    if not is_50:\n",
    "    # CNN 레이어\n",
    "        for cnn_num in range(num_cnn):\n",
    "            identity = x\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters=channel,\n",
    "                kernel_size=(3,3),\n",
    "                activation='relu',\n",
    "                kernel_initializer='he_normal',\n",
    "                padding='same',\n",
    "                name=f'block{block_num}_conv{cnn_num}'\n",
    "            )(x)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters=channel,\n",
    "                kernel_size=(3,3),\n",
    "                activation='relu',\n",
    "                kernel_initializer='he_normal',\n",
    "                padding='same',\n",
    "                name=f'block{block_num}_1_conv{cnn_num}'\n",
    "            )(x)\n",
    "            if not is_plain:\n",
    "                identity_channel = identity.shape.as_list()[-1]    \n",
    "\n",
    "                if identity_channel != channel:\n",
    "                    identity = keras.layers.Conv2D(channel, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(identity)  \n",
    "                # skip connection\n",
    "                x = keras.layers.Add()([x,identity])   \n",
    "            else:\n",
    "                pass\n",
    "    else :\n",
    "        identity = x\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(1,1),\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_conv{cnn_num}'\n",
    "        )(x)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(3,3),\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_1_conv{cnn_num}'\n",
    "        )(x)\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel * 4,\n",
    "            kernel_size=(1,1),\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_2_conv{cnn_num}'\n",
    "        )(x)\n",
    "        if not is_plain:\n",
    "            identity_channel = identity.shape.as_list()[-1]    \n",
    "\n",
    "            if identity_channel != channel:\n",
    "                identity = keras.layers.Conv2D(channel, kernel_size=(1, 1), strides=(1, 1), padding=\"same\")(identity)  \n",
    "            # skip connection\n",
    "            x = keras.layers.Add()([x,identity])   \n",
    "        else:\n",
    "            pass\n",
    "    # Max Pooling 레이어\n",
    "    # 마지막 블록 뒤에는 pooling을 하지 않음\n",
    "    if identity.shape[1] != 1:        \n",
    "        x = keras.layers.MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            strides=2,\n",
    "            name=f'block{block_num}_pooling'\n",
    "        )(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape=(32,32,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10,is_50 = False, is_plain = False):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    if is_50:\n",
    "        num_cnn_list = [3,4,6,3]\n",
    "        channel_list = [64,128,256,512]\n",
    "        num_classes = 10\n",
    "        \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    output = input_layer\n",
    "    #conv1층\n",
    "    output = keras.layers.Conv2D(filters=64,\n",
    "                       kernel_size = (2,2),\n",
    "                       strides = 2,\n",
    "                         padding = 'valid')(output)\n",
    "    output = keras.layers.BatchNormalization()(output)\n",
    "    \n",
    "    #conv2_x pooling\n",
    "    output = keras.layers.MaxPooling2D(pool_size = (2,2),\n",
    "                                      strides = 2,)(output)    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_resnet_block(\n",
    "            output,\n",
    "            num_cnn=num_cnn, \n",
    "            channel=channel,\n",
    "            block_num=i\n",
    "        )\n",
    "    output = keras.layers.AveragePooling2D(padding = 'same')(output)\n",
    "    output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(512, activation='relu', name='fc1')(output)    \n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_34 = build_resnet(is_50 = False)\n",
    "resnet_50 = build_resnet(is_50 = True)\n",
    "plain_resnet_34 = build_resnet(is_50 = False, is_plain = True)\n",
    "plain_resnet_50 = build_resnet(is_50 = True, is_plain = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc69b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train & test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, validate_df = train_test_split(df, test_size=0.1)\n",
    "train_df = train_df.reset_index()\n",
    "validate_df = validate_df.reset_index()\n",
    "\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training generator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    \"./input/train/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    class_mode='binary',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a90d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation generator\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df,\n",
    "    \"./input/train/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    class_mode='binary',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb98b3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fbd518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate_generator(validation_generator, total_validate//batch_size, workers=12)\n",
    "print('test loss: %f  test acc: %f' %(accuracy, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a903ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "axs[0].plot(range(1,len(history.history['accuracy'])+1),history.history['accuracy'])\n",
    "axs[0].plot(range(1,len(history.history['val_accuracy'])+1),history.history['val_accuracy'])\n",
    "axs[0].set_title('Model Accuracy')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_xticks(np.arange(1,len(history.history['accuracy'])+1),len(history.history['accuracy'])/10)\n",
    "axs[0].legend(['train', 'val'], loc='best')\n",
    "axs[1].plot(range(1,len(history.history['loss'])+1),history.history['loss'])\n",
    "axs[1].plot(range(1,len(history.history['val_loss'])+1),history.history['val_loss'])\n",
    "axs[1].set_title('Model Loss')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_xticks(np.arange(1,len(history.history['loss'])+1),len(history.history['loss'])/10)\n",
    "axs[1].legend(['train', 'val'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0436ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = validate_df['category']\n",
    "y_pred =  model.predict_generator(validation_generator)\n",
    "\n",
    "print(y_val)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ace009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = np.where(y_val == 'dog', 1, 0)\n",
    "\n",
    "threshold = 0.5\n",
    "y_final = []\n",
    "for i in y_pred:\n",
    "    if(i[0] > threshold):\n",
    "        y_final.append(0)\n",
    "    else:\n",
    "        y_final.append(1)\n",
    "y_final = np.array(y_final)\n",
    "\n",
    "print(y_val)\n",
    "\n",
    "print(y_true)\n",
    "print(y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_final.size, y_true.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24412d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Predict the values from the validation dataset\n",
    "\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_true, y_final)\n",
    "# plot the confusion matrix\n",
    "f,ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7029de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_true, y_final, target_names=['cat','dog'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a89396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare testing data\n",
    "\n",
    "test_filenames = os.listdir(\"./input/test1/test1\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]\n",
    "\n",
    "# testing generator\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    \"./input/test1/test1/\", \n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa789f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "\n",
    "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict, type(predict))\n",
    "\n",
    "test_df['category'] = np.where(predict>threshold, 'dog', 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see predicted result\n",
    "sample_test = test_df.sample(n=9).reset_index()\n",
    "sample_test.head()\n",
    "plt.figure(figsize=(12, 12))\n",
    "for index, row in sample_test.iterrows():\n",
    "    filename = row['filename']\n",
    "    category = row['category']\n",
    "    img = load_img(\"./input/test1/test1/\"+filename, target_size=(256, 256))\n",
    "    plt.subplot(3, 3, index+1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = test_df.copy()\n",
    "submission_df['id'] = submission_df['filename'].str.split('.').str[0]\n",
    "submission_df['label'] = submission_df['category']\n",
    "submission_df.drop(['filename', 'category'], axis=1, inplace=True)\n",
    "submission_df.to_csv('submission_13010030.csv', index=False)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(submission_df['label'])\n",
    "plt.title(\"(Test data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a96be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0968c0e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 8133552907824534086,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 15581516555459346216\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6918604064\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 15040998855063717675\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 8199571755367449316\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151a9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f7bc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45b15195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers, applications, optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddbb1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "batch_size = 5\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc4f7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[203 164  87]\n",
      "   [206 167  90]\n",
      "   [209 170  93]\n",
      "   ...\n",
      "   [245 203 119]\n",
      "   [241 202 123]\n",
      "   [239 200 121]]\n",
      "\n",
      "  [[203 164  87]\n",
      "   [206 167  90]\n",
      "   [209 170  93]\n",
      "   ...\n",
      "   [245 205 120]\n",
      "   [242 203 124]\n",
      "   [240 201 122]]\n",
      "\n",
      "  [[203 164  87]\n",
      "   [206 167  90]\n",
      "   [209 170  93]\n",
      "   ...\n",
      "   [245 204 122]\n",
      "   [243 204 125]\n",
      "   [241 202 123]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[154 123  56]\n",
      "   [155 124  57]\n",
      "   [156 125  58]\n",
      "   ...\n",
      "   [  3   3   1]\n",
      "   [  3   3   1]\n",
      "   [  3   3   1]]\n",
      "\n",
      "  [[153 122  55]\n",
      "   [153 122  55]\n",
      "   [154 123  56]\n",
      "   ...\n",
      "   [  2   2   0]\n",
      "   [  2   2   0]\n",
      "   [  2   2   0]]\n",
      "\n",
      "  [[151 120  53]\n",
      "   [152 121  54]\n",
      "   [153 122  55]\n",
      "   ...\n",
      "   [  1   1   0]\n",
      "   [  1   1   0]\n",
      "   [  1   1   0]]]\n",
      "\n",
      "\n",
      " [[[ 39  44  40]\n",
      "   [ 40  44  43]\n",
      "   [ 41  45  46]\n",
      "   ...\n",
      "   [210 209 181]\n",
      "   [207 204 171]\n",
      "   [201 199 161]]\n",
      "\n",
      "  [[ 40  45  41]\n",
      "   [ 40  44  43]\n",
      "   [ 41  45  46]\n",
      "   ...\n",
      "   [207 203 176]\n",
      "   [203 200 169]\n",
      "   [197 195 157]]\n",
      "\n",
      "  [[ 39  44  40]\n",
      "   [ 38  42  41]\n",
      "   [ 37  41  42]\n",
      "   ...\n",
      "   [195 191 166]\n",
      "   [198 193 164]\n",
      "   [205 200 168]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 29  27  28]\n",
      "   [ 25  23  24]\n",
      "   [ 22  20  21]\n",
      "   ...\n",
      "   [ 50  37  31]\n",
      "   [ 41  28  22]\n",
      "   [ 49  38  32]]\n",
      "\n",
      "  [[ 32  30  31]\n",
      "   [ 26  24  25]\n",
      "   [ 22  20  21]\n",
      "   ...\n",
      "   [ 44  31  23]\n",
      "   [ 42  29  21]\n",
      "   [ 55  45  36]]\n",
      "\n",
      "  [[ 32  30  31]\n",
      "   [ 25  23  24]\n",
      "   [ 21  19  20]\n",
      "   ...\n",
      "   [ 59  46  38]\n",
      "   [ 51  38  30]\n",
      "   [ 40  30  21]]]\n",
      "\n",
      "\n",
      " [[[ 29  33  42]\n",
      "   [ 19  23  32]\n",
      "   [  8  12  23]\n",
      "   ...\n",
      "   [130 162 159]\n",
      "   [128 160 157]\n",
      "   [125 157 154]]\n",
      "\n",
      "  [[ 36  40  49]\n",
      "   [ 41  45  54]\n",
      "   [ 31  35  46]\n",
      "   ...\n",
      "   [131 163 160]\n",
      "   [129 161 158]\n",
      "   [126 158 155]]\n",
      "\n",
      "  [[ 38  45  51]\n",
      "   [ 41  48  54]\n",
      "   [ 37  44  52]\n",
      "   ...\n",
      "   [132 164 159]\n",
      "   [129 161 156]\n",
      "   [127 159 154]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[178 165 120]\n",
      "   [171 158 114]\n",
      "   [169 156 112]\n",
      "   ...\n",
      "   [190 188   9]\n",
      "   [179 174  12]\n",
      "   [170 163  13]]\n",
      "\n",
      "  [[169 156 111]\n",
      "   [170 157 112]\n",
      "   [156 143  99]\n",
      "   ...\n",
      "   [189 186   9]\n",
      "   [178 173  11]\n",
      "   [168 161  11]]\n",
      "\n",
      "  [[159 145 110]\n",
      "   [147 133  94]\n",
      "   [150 137  93]\n",
      "   ...\n",
      "   [189 187   6]\n",
      "   [180 177   4]\n",
      "   [172 167   3]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 56  51  48]\n",
      "   [ 61  56  53]\n",
      "   [ 62  57  54]\n",
      "   ...\n",
      "   [ 80  73  65]\n",
      "   [ 96  89  83]\n",
      "   [ 73  66  60]]\n",
      "\n",
      "  [[ 42  37  34]\n",
      "   [ 37  32  29]\n",
      "   [ 50  45  42]\n",
      "   ...\n",
      "   [ 68  61  53]\n",
      "   [ 84  75  68]\n",
      "   [ 70  61  54]]\n",
      "\n",
      "  [[ 49  45  42]\n",
      "   [ 59  55  52]\n",
      "   [ 54  50  47]\n",
      "   ...\n",
      "   [ 75  68  60]\n",
      "   [ 94  81  75]\n",
      "   [ 77  64  58]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[108  93  72]\n",
      "   [123 102  81]\n",
      "   [ 93  67  44]\n",
      "   ...\n",
      "   [213 169 124]\n",
      "   [192 150 110]\n",
      "   [178 136  96]]\n",
      "\n",
      "  [[116 101  80]\n",
      "   [ 71  50  29]\n",
      "   [113  87  64]\n",
      "   ...\n",
      "   [227 183 138]\n",
      "   [212 170 130]\n",
      "   [198 156 116]]\n",
      "\n",
      "  [[ 99  84  63]\n",
      "   [120  99  78]\n",
      "   [134 108  85]\n",
      "   ...\n",
      "   [200 157 112]\n",
      "   [199 157 117]\n",
      "   [203 161 121]]]\n",
      "\n",
      "\n",
      " [[[253 255 252]\n",
      "   [252 254 253]\n",
      "   [253 253 253]\n",
      "   ...\n",
      "   [252 255 253]\n",
      "   [250 255 249]\n",
      "   [250 255 248]]\n",
      "\n",
      "  [[254 255 253]\n",
      "   [255 255 255]\n",
      "   [254 254 254]\n",
      "   ...\n",
      "   [250 251 245]\n",
      "   [251 254 247]\n",
      "   [251 254 247]]\n",
      "\n",
      "  [[253 253 253]\n",
      "   [253 253 253]\n",
      "   [253 251 252]\n",
      "   ...\n",
      "   [254 247 239]\n",
      "   [254 250 241]\n",
      "   [253 250 243]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[120 105 100]\n",
      "   [116 101  96]\n",
      "   [104  89  84]\n",
      "   ...\n",
      "   [122 108 108]\n",
      "   [117 103 102]\n",
      "   [112  98  97]]\n",
      "\n",
      "  [[101  86  81]\n",
      "   [ 98  83  78]\n",
      "   [ 86  71  66]\n",
      "   ...\n",
      "   [119 103 104]\n",
      "   [132 116 116]\n",
      "   [123 107 107]]\n",
      "\n",
      "  [[103  87  88]\n",
      "   [102  86  87]\n",
      "   [ 98  82  83]\n",
      "   ...\n",
      "   [123 107 108]\n",
      "   [127 111 112]\n",
      "   [132 116 117]]]\n",
      "\n",
      "\n",
      " [[[245 238 228]\n",
      "   [245 238 228]\n",
      "   [247 240 230]\n",
      "   ...\n",
      "   [247 247 239]\n",
      "   [248 248 240]\n",
      "   [248 248 240]]\n",
      "\n",
      "  [[247 240 230]\n",
      "   [247 240 230]\n",
      "   [248 241 231]\n",
      "   ...\n",
      "   [255 255 248]\n",
      "   [255 255 248]\n",
      "   [255 255 248]]\n",
      "\n",
      "  [[247 240 230]\n",
      "   [247 240 230]\n",
      "   [248 241 231]\n",
      "   ...\n",
      "   [255 255 248]\n",
      "   [255 255 248]\n",
      "   [255 255 248]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 77  85  87]\n",
      "   [ 77  85  87]\n",
      "   [ 70  78  80]\n",
      "   ...\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   [254 254 254]]\n",
      "\n",
      "  [[ 77  85  87]\n",
      "   [ 77  85  87]\n",
      "   [ 70  78  80]\n",
      "   ...\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   [254 254 254]]\n",
      "\n",
      "  [[ 77  85  87]\n",
      "   [ 77  85  87]\n",
      "   [ 69  77  79]\n",
      "   ...\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   [254 254 254]]]]\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#load train data(25000 imgs each)\n",
    "\n",
    "filenames = os.listdir('./input/train/train')\n",
    "data = []\n",
    "categories = []\n",
    "\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "    \n",
    "    image = keras.preprocessing.image.load_img(os.path.join('./input/train/train', filename),\n",
    "                                               color_mode='rgb',\n",
    "                                               target_size= (image_size,image_size))\n",
    "    image = np.array(image)\n",
    "    data.append(image)\n",
    "\n",
    "data = np.array(data)\n",
    "categories = np.array(categories)\n",
    "\n",
    "print(data)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a923474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "\n",
    "idx = np.random.permutation(len(data))\n",
    "data, categories = data[idx], categories[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfc69b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train 6(15,000) / val 2(5,000) / test 2(5,000)\n",
    "\n",
    "x_train = data[:15000]\n",
    "y_train = categories[:15000]\n",
    "x_temp, y_temp = data[-10000:], categories[-10000:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d9823c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[192 191 197]\n",
      "   [210 209 215]\n",
      "   [185 184 190]\n",
      "   ...\n",
      "   [195 192 199]\n",
      "   [198 195 202]\n",
      "   [179 178 186]]\n",
      "\n",
      "  [[199 198 204]\n",
      "   [205 204 210]\n",
      "   [194 193 199]\n",
      "   ...\n",
      "   [195 192 199]\n",
      "   [181 178 185]\n",
      "   [182 181 189]]\n",
      "\n",
      "  [[197 196 202]\n",
      "   [196 195 201]\n",
      "   [193 192 198]\n",
      "   ...\n",
      "   [197 194 201]\n",
      "   [179 176 183]\n",
      "   [195 194 202]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[253 253 253]\n",
      "   [248 248 248]\n",
      "   [251 251 251]\n",
      "   ...\n",
      "   [248 246 247]\n",
      "   [244 242 243]\n",
      "   [245 245 245]]\n",
      "\n",
      "  [[251 251 251]\n",
      "   [248 248 248]\n",
      "   [251 251 251]\n",
      "   ...\n",
      "   [247 245 246]\n",
      "   [245 243 244]\n",
      "   [242 242 242]]\n",
      "\n",
      "  [[247 247 247]\n",
      "   [250 250 250]\n",
      "   [250 250 250]\n",
      "   ...\n",
      "   [240 238 239]\n",
      "   [243 241 242]\n",
      "   [248 248 248]]]\n",
      "\n",
      "\n",
      " [[[141 146 140]\n",
      "   [142 147 141]\n",
      "   [144 149 143]\n",
      "   ...\n",
      "   [186 192 182]\n",
      "   [188 194 184]\n",
      "   [180 186 176]]\n",
      "\n",
      "  [[142 147 141]\n",
      "   [143 148 142]\n",
      "   [144 149 143]\n",
      "   ...\n",
      "   [179 185 175]\n",
      "   [174 180 170]\n",
      "   [175 181 171]]\n",
      "\n",
      "  [[142 147 141]\n",
      "   [143 148 142]\n",
      "   [145 150 144]\n",
      "   ...\n",
      "   [180 186 176]\n",
      "   [186 192 182]\n",
      "   [180 186 176]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[112 106 106]\n",
      "   [104  98  98]\n",
      "   [112 106 106]\n",
      "   ...\n",
      "   [173 166 173]\n",
      "   [169 162 169]\n",
      "   [185 178 185]]\n",
      "\n",
      "  [[118 109 110]\n",
      "   [119 111 109]\n",
      "   [120 113 107]\n",
      "   ...\n",
      "   [173 171 176]\n",
      "   [171 168 175]\n",
      "   [183 180 187]]\n",
      "\n",
      "  [[118 109 110]\n",
      "   [119 111 109]\n",
      "   [120 113 107]\n",
      "   ...\n",
      "   [178 176 181]\n",
      "   [171 168 175]\n",
      "   [179 176 183]]]\n",
      "\n",
      "\n",
      " [[[114  74  39]\n",
      "   [115  75  40]\n",
      "   [116  76  41]\n",
      "   ...\n",
      "   [234 222 224]\n",
      "   [231 234 241]\n",
      "   [240 243 250]]\n",
      "\n",
      "  [[115  75  40]\n",
      "   [115  75  40]\n",
      "   [116  76  41]\n",
      "   ...\n",
      "   [235 223 225]\n",
      "   [230 233 240]\n",
      "   [240 243 250]]\n",
      "\n",
      "  [[115  75  40]\n",
      "   [116  76  41]\n",
      "   [117  77  42]\n",
      "   ...\n",
      "   [237 225 227]\n",
      "   [231 234 241]\n",
      "   [240 243 250]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[219 118  88]\n",
      "   [226 125  95]\n",
      "   [231 130 100]\n",
      "   ...\n",
      "   [233 183 146]\n",
      "   [232 182 149]\n",
      "   [230 180 147]]\n",
      "\n",
      "  [[222 121  91]\n",
      "   [229 128  98]\n",
      "   [234 133 103]\n",
      "   ...\n",
      "   [231 181 144]\n",
      "   [229 179 146]\n",
      "   [227 177 144]]\n",
      "\n",
      "  [[224 123  93]\n",
      "   [230 129  99]\n",
      "   [235 134 104]\n",
      "   ...\n",
      "   [229 179 142]\n",
      "   [229 179 146]\n",
      "   [227 177 144]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 94  56  35]\n",
      "   [103  65  44]\n",
      "   [ 99  61  40]\n",
      "   ...\n",
      "   [ 78  28  21]\n",
      "   [ 78  28  21]\n",
      "   [ 72  26  13]]\n",
      "\n",
      "  [[100  62  41]\n",
      "   [108  70  49]\n",
      "   [104  66  45]\n",
      "   ...\n",
      "   [ 92  42  33]\n",
      "   [ 86  36  27]\n",
      "   [ 87  41  28]]\n",
      "\n",
      "  [[ 95  57  36]\n",
      "   [104  66  45]\n",
      "   [ 99  61  40]\n",
      "   ...\n",
      "   [ 97  47  36]\n",
      "   [ 93  43  32]\n",
      "   [ 92  46  31]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[179 159 152]\n",
      "   [174 154 147]\n",
      "   [178 158 151]\n",
      "   ...\n",
      "   [173 148 143]\n",
      "   [169 144 139]\n",
      "   [168 143 138]]\n",
      "\n",
      "  [[180 160 153]\n",
      "   [179 159 152]\n",
      "   [179 159 152]\n",
      "   ...\n",
      "   [175 150 145]\n",
      "   [170 145 140]\n",
      "   [175 150 145]]\n",
      "\n",
      "  [[184 164 157]\n",
      "   [172 152 145]\n",
      "   [174 154 147]\n",
      "   ...\n",
      "   [174 149 144]\n",
      "   [172 147 142]\n",
      "   [173 148 143]]]\n",
      "\n",
      "\n",
      " [[[181 163 149]\n",
      "   [181 163 149]\n",
      "   [178 160 146]\n",
      "   ...\n",
      "   [227 227 227]\n",
      "   [232 232 232]\n",
      "   [240 240 240]]\n",
      "\n",
      "  [[182 164 150]\n",
      "   [183 165 151]\n",
      "   [182 164 150]\n",
      "   ...\n",
      "   [252 252 252]\n",
      "   [251 251 251]\n",
      "   [252 252 252]]\n",
      "\n",
      "  [[183 165 151]\n",
      "   [183 165 151]\n",
      "   [181 163 149]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[146 137 122]\n",
      "   [151 142 127]\n",
      "   [154 144 132]\n",
      "   ...\n",
      "   [218 200 190]\n",
      "   [211 193 183]\n",
      "   [211 194 186]]\n",
      "\n",
      "  [[148 139 124]\n",
      "   [151 142 127]\n",
      "   [155 145 133]\n",
      "   ...\n",
      "   [219 199 190]\n",
      "   [211 191 182]\n",
      "   [212 195 187]]\n",
      "\n",
      "  [[148 139 124]\n",
      "   [151 142 127]\n",
      "   [155 145 133]\n",
      "   ...\n",
      "   [220 200 191]\n",
      "   [215 192 184]\n",
      "   [212 195 187]]]\n",
      "\n",
      "\n",
      " [[[ 46  47  33]\n",
      "   [ 43  44  30]\n",
      "   [ 41  42  28]\n",
      "   ...\n",
      "   [146 145 143]\n",
      "   [146 145 143]\n",
      "   [148 143 140]]\n",
      "\n",
      "  [[ 39  39  27]\n",
      "   [ 40  40  28]\n",
      "   [ 40  40  28]\n",
      "   ...\n",
      "   [145 144 142]\n",
      "   [146 145 143]\n",
      "   [148 143 140]]\n",
      "\n",
      "  [[ 51  50  45]\n",
      "   [ 55  54  49]\n",
      "   [ 57  56  51]\n",
      "   ...\n",
      "   [144 143 141]\n",
      "   [146 145 143]\n",
      "   [148 143 140]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[217 217 219]\n",
      "   [218 218 220]\n",
      "   [217 217 219]\n",
      "   ...\n",
      "   [ 28  18  27]\n",
      "   [ 26  16  25]\n",
      "   [ 24  14  23]]\n",
      "\n",
      "  [[223 223 225]\n",
      "   [220 220 222]\n",
      "   [222 222 224]\n",
      "   ...\n",
      "   [ 21  14  22]\n",
      "   [ 24  17  25]\n",
      "   [ 22  15  23]]\n",
      "\n",
      "  [[230 230 232]\n",
      "   [225 225 227]\n",
      "   [224 224 226]\n",
      "   ...\n",
      "   [ 21  14  22]\n",
      "   [ 24  17  25]\n",
      "   [ 22  15  23]]]] [0 0 1 ... 0 0 1]\n",
      "[[[[ 47   0   0]\n",
      "   [ 63  16  10]\n",
      "   [ 56  12   0]\n",
      "   ...\n",
      "   [ 23  26  31]\n",
      "   [ 18  21  26]\n",
      "   [ 18  21  26]]\n",
      "\n",
      "  [[ 50   6   5]\n",
      "   [ 58  13   8]\n",
      "   [ 59  11   1]\n",
      "   ...\n",
      "   [ 22  25  30]\n",
      "   [ 21  24  29]\n",
      "   [ 21  24  29]]\n",
      "\n",
      "  [[ 40   5   3]\n",
      "   [ 52   7   4]\n",
      "   [ 69  11   7]\n",
      "   ...\n",
      "   [ 21  24  29]\n",
      "   [ 19  22  27]\n",
      "   [ 19  22  27]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[113 100  83]\n",
      "   [132 116 100]\n",
      "   [143 127 114]\n",
      "   ...\n",
      "   [ 86  77  62]\n",
      "   [ 81  72  55]\n",
      "   [ 81  72  55]]\n",
      "\n",
      "  [[110  97  80]\n",
      "   [134 118 102]\n",
      "   [150 134 121]\n",
      "   ...\n",
      "   [ 88  79  64]\n",
      "   [ 82  73  56]\n",
      "   [ 82  73  56]]\n",
      "\n",
      "  [[112  99  82]\n",
      "   [133 117 101]\n",
      "   [145 129 116]\n",
      "   ...\n",
      "   [ 84  75  60]\n",
      "   [ 80  71  54]\n",
      "   [ 80  71  54]]]\n",
      "\n",
      "\n",
      " [[[121  89  92]\n",
      "   [125  94  92]\n",
      "   [130  96  94]\n",
      "   ...\n",
      "   [217 200 174]\n",
      "   [217 200 174]\n",
      "   [218 201 175]]\n",
      "\n",
      "  [[125  86  91]\n",
      "   [121  82  83]\n",
      "   [120  82  81]\n",
      "   ...\n",
      "   [218 201 175]\n",
      "   [218 201 175]\n",
      "   [220 203 177]]\n",
      "\n",
      "  [[111  64  72]\n",
      "   [104  58  61]\n",
      "   [104  60  61]\n",
      "   ...\n",
      "   [219 202 176]\n",
      "   [219 202 176]\n",
      "   [220 203 177]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[227 228 223]\n",
      "   [230 231 226]\n",
      "   [232 233 228]\n",
      "   ...\n",
      "   [162 156 142]\n",
      "   [165 159 147]\n",
      "   [164 160 148]]\n",
      "\n",
      "  [[199 195 186]\n",
      "   [205 201 192]\n",
      "   [210 206 197]\n",
      "   ...\n",
      "   [160 150 140]\n",
      "   [160 150 140]\n",
      "   [161 157 145]]\n",
      "\n",
      "  [[231 227 218]\n",
      "   [227 223 214]\n",
      "   [223 219 210]\n",
      "   ...\n",
      "   [157 147 137]\n",
      "   [157 147 137]\n",
      "   [155 151 139]]]\n",
      "\n",
      "\n",
      " [[[  6   6   4]\n",
      "   [  6   6   4]\n",
      "   [  6   6   4]\n",
      "   ...\n",
      "   [  7   9   4]\n",
      "   [  7   9   4]\n",
      "   [  7   9   4]]\n",
      "\n",
      "  [[  7   7   5]\n",
      "   [  7   7   5]\n",
      "   [  7   7   5]\n",
      "   ...\n",
      "   [  7   9   4]\n",
      "   [  7   9   4]\n",
      "   [  7   9   4]]\n",
      "\n",
      "  [[  7   7   5]\n",
      "   [  7   7   5]\n",
      "   [  7   7   5]\n",
      "   ...\n",
      "   [  7   9   4]\n",
      "   [  7   9   4]\n",
      "   [  7   9   4]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[253 253 253]\n",
      "   [252 252 252]\n",
      "   [253 253 253]\n",
      "   ...\n",
      "   [180 177 172]\n",
      "   [180 175 169]\n",
      "   [180 176 167]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [177 174 169]\n",
      "   [177 172 166]\n",
      "   [177 173 164]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [176 169 163]\n",
      "   [178 169 162]\n",
      "   [179 169 160]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[119 123 106]\n",
      "   [100 101  95]\n",
      "   [ 33  31  36]\n",
      "   ...\n",
      "   [ 54  42  16]\n",
      "   [ 50  43  14]\n",
      "   [ 50  43  14]]\n",
      "\n",
      "  [[105 109  94]\n",
      "   [ 60  61  55]\n",
      "   [ 21  19  24]\n",
      "   ...\n",
      "   [ 52  40  14]\n",
      "   [ 52  45  16]\n",
      "   [ 52  45  16]]\n",
      "\n",
      "  [[ 83  87  73]\n",
      "   [ 25  26  21]\n",
      "   [ 15  13  18]\n",
      "   ...\n",
      "   [ 56  44  18]\n",
      "   [ 50  43  14]\n",
      "   [ 50  43  14]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 18  17  33]\n",
      "   [ 20  19  33]\n",
      "   [  9   9  21]\n",
      "   ...\n",
      "   [ 80  60   1]\n",
      "   [ 76  56   0]\n",
      "   [ 76  56   0]]\n",
      "\n",
      "  [[ 17  15  28]\n",
      "   [ 10   8  21]\n",
      "   [ 21  20  28]\n",
      "   ...\n",
      "   [ 89  69  10]\n",
      "   [ 85  63   3]\n",
      "   [ 81  59   0]]\n",
      "\n",
      "  [[ 12  10  21]\n",
      "   [ 10   8  19]\n",
      "   [ 42  41  47]\n",
      "   ...\n",
      "   [ 92  72   9]\n",
      "   [ 92  68   6]\n",
      "   [ 91  67   5]]]\n",
      "\n",
      "\n",
      " [[[226 202 132]\n",
      "   [223 199 127]\n",
      "   [221 197 125]\n",
      "   ...\n",
      "   [148 102  68]\n",
      "   [156 110  74]\n",
      "   [169 124  85]]\n",
      "\n",
      "  [[207 179 116]\n",
      "   [209 181 116]\n",
      "   [210 182 117]\n",
      "   ...\n",
      "   [149 103  69]\n",
      "   [158 112  76]\n",
      "   [170 125  86]]\n",
      "\n",
      "  [[207 176 121]\n",
      "   [211 180 125]\n",
      "   [214 183 126]\n",
      "   ...\n",
      "   [151 105  71]\n",
      "   [160 114  78]\n",
      "   [172 127  88]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[112  44  25]\n",
      "   [110  43  26]\n",
      "   [110  43  26]\n",
      "   ...\n",
      "   [ 98  81  97]\n",
      "   [ 92  75  91]\n",
      "   [ 80  64  77]]\n",
      "\n",
      "  [[112  44  25]\n",
      "   [110  43  26]\n",
      "   [110  43  26]\n",
      "   ...\n",
      "   [ 84  66  82]\n",
      "   [ 76  58  72]\n",
      "   [ 87  69  83]]\n",
      "\n",
      "  [[112  44  25]\n",
      "   [110  43  26]\n",
      "   [110  43  26]\n",
      "   ...\n",
      "   [ 56  33  49]\n",
      "   [ 44  21  37]\n",
      "   [ 83  61  74]]]\n",
      "\n",
      "\n",
      " [[[187 134  92]\n",
      "   [186 135  92]\n",
      "   [151 104  62]\n",
      "   ...\n",
      "   [154 141 124]\n",
      "   [102  90  74]\n",
      "   [ 88  76  60]]\n",
      "\n",
      "  [[255 209 167]\n",
      "   [255 214 171]\n",
      "   [198 151 109]\n",
      "   ...\n",
      "   [131 118 101]\n",
      "   [124 112  96]\n",
      "   [107  95  79]]\n",
      "\n",
      "  [[220 167 127]\n",
      "   [255 210 170]\n",
      "   [218 171 129]\n",
      "   ...\n",
      "   [146 133 117]\n",
      "   [171 159 143]\n",
      "   [171 159 145]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 228 201]\n",
      "   [198 171 144]\n",
      "   [203 176 149]\n",
      "   ...\n",
      "   [140 118  95]\n",
      "   [140 118  95]\n",
      "   [156 132 108]]\n",
      "\n",
      "  [[246 219 190]\n",
      "   [149 122  93]\n",
      "   [114  87  58]\n",
      "   ...\n",
      "   [120 100  76]\n",
      "   [102  80  57]\n",
      "   [149 127 103]]\n",
      "\n",
      "  [[248 218 190]\n",
      "   [248 218 190]\n",
      "   [230 200 172]\n",
      "   ...\n",
      "   [112  92  68]\n",
      "   [120 100  76]\n",
      "   [160 140 115]]]] [1 0 0 ... 1 0 1]\n",
      "(10000, 224, 224, 3) (10000,)\n",
      "[[[[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[110  35   0]\n",
      "   [112  36   0]\n",
      "   [116  40   6]\n",
      "   ...\n",
      "   [235 215 190]\n",
      "   [248 232 217]\n",
      "   [252 234 232]]\n",
      "\n",
      "  [[126  50  26]\n",
      "   [124  53  21]\n",
      "   [116  51  11]\n",
      "   ...\n",
      "   [239 223 208]\n",
      "   [248 235 227]\n",
      "   [252 247 244]]\n",
      "\n",
      "  [[117  41  17]\n",
      "   [108  37   5]\n",
      "   [100  35   0]\n",
      "   ...\n",
      "   [244 228 213]\n",
      "   [254 241 233]\n",
      "   [255 252 249]]]\n",
      "\n",
      "\n",
      " [[[ 99  91  80]\n",
      "   [ 79  66  57]\n",
      "   [143 126 118]\n",
      "   ...\n",
      "   [ 75  80  73]\n",
      "   [ 53  48  44]\n",
      "   [ 65  62  55]]\n",
      "\n",
      "  [[115 106  91]\n",
      "   [136 122 109]\n",
      "   [165 147 135]\n",
      "   ...\n",
      "   [ 66  76  67]\n",
      "   [ 41  40  35]\n",
      "   [ 44  43  38]]\n",
      "\n",
      "  [[ 95  82  66]\n",
      "   [117 101  86]\n",
      "   [137 118 104]\n",
      "   ...\n",
      "   [ 78  90  78]\n",
      "   [ 49  52  43]\n",
      "   [ 31  30  28]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[225 212 193]\n",
      "   [223 210 191]\n",
      "   [219 206 187]\n",
      "   ...\n",
      "   [248 253 255]\n",
      "   [245 255 255]\n",
      "   [255 255 245]]\n",
      "\n",
      "  [[217 192 170]\n",
      "   [238 213 191]\n",
      "   [224 202 179]\n",
      "   ...\n",
      "   [255 255 246]\n",
      "   [247 253 243]\n",
      "   [255 254 250]]\n",
      "\n",
      "  [[202 177 155]\n",
      "   [222 197 175]\n",
      "   [228 206 183]\n",
      "   ...\n",
      "   [252 248 239]\n",
      "   [252 255 248]\n",
      "   [255 254 250]]]\n",
      "\n",
      "\n",
      " [[[ 18  17  13]\n",
      "   [ 18  17  13]\n",
      "   [ 18  17  13]\n",
      "   ...\n",
      "   [130  94  78]\n",
      "   [130  90  78]\n",
      "   [119  79  67]]\n",
      "\n",
      "  [[ 18  17  13]\n",
      "   [ 18  17  13]\n",
      "   [ 18  17  13]\n",
      "   ...\n",
      "   [132  95  79]\n",
      "   [135  97  84]\n",
      "   [133  95  82]]\n",
      "\n",
      "  [[ 18  17  13]\n",
      "   [ 18  17  13]\n",
      "   [ 18  17  13]\n",
      "   ...\n",
      "   [129  92  74]\n",
      "   [128  92  76]\n",
      "   [135  99  83]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[123  95  83]\n",
      "   [125  97  85]\n",
      "   [125  97  85]\n",
      "   ...\n",
      "   [166  31  37]\n",
      "   [177  40  50]\n",
      "   [164  27  37]]\n",
      "\n",
      "  [[123  95  83]\n",
      "   [125  97  85]\n",
      "   [125  97  85]\n",
      "   ...\n",
      "   [173  36  43]\n",
      "   [174  33  41]\n",
      "   [167  26  34]]\n",
      "\n",
      "  [[123  95  83]\n",
      "   [125  97  85]\n",
      "   [125  97  85]\n",
      "   ...\n",
      "   [188  48  57]\n",
      "   [173  29  38]\n",
      "   [175  31  40]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[248 131  62]\n",
      "   [248 133  66]\n",
      "   [253 139  76]\n",
      "   ...\n",
      "   [233 138  92]\n",
      "   [225 130  84]\n",
      "   [235 140  94]]\n",
      "\n",
      "  [[251 128  61]\n",
      "   [249 127  62]\n",
      "   [254 136  74]\n",
      "   ...\n",
      "   [232 137  91]\n",
      "   [226 131  85]\n",
      "   [237 142  96]]\n",
      "\n",
      "  [[254 124  62]\n",
      "   [249 123  62]\n",
      "   [255 132  73]\n",
      "   ...\n",
      "   [233 136  91]\n",
      "   [229 132  87]\n",
      "   [242 145 100]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[248 248 255]\n",
      "   [249 249 255]\n",
      "   [246 246 254]\n",
      "   ...\n",
      "   [169 175 201]\n",
      "   [169 175 201]\n",
      "   [163 169 195]]\n",
      "\n",
      "  [[236 236 244]\n",
      "   [240 240 248]\n",
      "   [244 244 252]\n",
      "   ...\n",
      "   [162 169 195]\n",
      "   [163 170 196]\n",
      "   [159 166 192]]\n",
      "\n",
      "  [[236 236 248]\n",
      "   [233 233 243]\n",
      "   [243 243 253]\n",
      "   ...\n",
      "   [159 162 193]\n",
      "   [168 168 194]\n",
      "   [167 163 186]]]\n",
      "\n",
      "\n",
      " [[[ 91  93  72]\n",
      "   [ 91  94  73]\n",
      "   [ 82  86  63]\n",
      "   ...\n",
      "   [130 118 122]\n",
      "   [ 90  86  85]\n",
      "   [104 105 100]]\n",
      "\n",
      "  [[ 89  94  71]\n",
      "   [ 88  93  70]\n",
      "   [ 90  96  70]\n",
      "   ...\n",
      "   [ 83  75  73]\n",
      "   [102 103  97]\n",
      "   [ 72  78  66]]\n",
      "\n",
      "  [[ 75  81  55]\n",
      "   [ 70  79  52]\n",
      "   [ 74  83  54]\n",
      "   ...\n",
      "   [112 109 104]\n",
      "   [106 112 100]\n",
      "   [ 84  95  78]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 77  76  72]\n",
      "   [ 70  70  60]\n",
      "   [101  99  84]\n",
      "   ...\n",
      "   [ 87  97  63]\n",
      "   [ 75  81  55]\n",
      "   [123 127 104]]\n",
      "\n",
      "  [[ 58  57  53]\n",
      "   [ 78  75  66]\n",
      "   [118 117  99]\n",
      "   ...\n",
      "   [ 66  71  41]\n",
      "   [ 76  78  54]\n",
      "   [ 28  27   6]]\n",
      "\n",
      "  [[ 56  52  51]\n",
      "   [ 43  40  33]\n",
      "   [ 82  81  63]\n",
      "   ...\n",
      "   [ 89  89  63]\n",
      "   [ 74  69  47]\n",
      "   [112 105  86]]]\n",
      "\n",
      "\n",
      " [[[211 218 234]\n",
      "   [211 218 234]\n",
      "   [211 218 234]\n",
      "   ...\n",
      "   [253 253 253]\n",
      "   [252 252 252]\n",
      "   [251 251 251]]\n",
      "\n",
      "  [[210 217 233]\n",
      "   [210 217 233]\n",
      "   [210 217 233]\n",
      "   ...\n",
      "   [252 252 252]\n",
      "   [251 251 251]\n",
      "   [250 250 250]]\n",
      "\n",
      "  [[210 217 233]\n",
      "   [210 217 233]\n",
      "   [210 217 233]\n",
      "   ...\n",
      "   [252 252 252]\n",
      "   [251 251 251]\n",
      "   [250 250 250]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[250 212 211]\n",
      "   [250 212 211]\n",
      "   [250 212 211]\n",
      "   ...\n",
      "   [139  89  78]\n",
      "   [141  91  80]\n",
      "   [143  93  82]]\n",
      "\n",
      "  [[250 212 211]\n",
      "   [250 212 211]\n",
      "   [250 212 211]\n",
      "   ...\n",
      "   [139  89  78]\n",
      "   [141  91  80]\n",
      "   [143  93  82]]\n",
      "\n",
      "  [[252 214 213]\n",
      "   [252 214 213]\n",
      "   [252 214 213]\n",
      "   ...\n",
      "   [141  93  81]\n",
      "   [141  93  81]\n",
      "   [142  94  82]]]] [0 1 0 ... 1 1 1]\n",
      "[[[[  1   1   0]\n",
      "   [  5   5   3]\n",
      "   [  8   8   6]\n",
      "   ...\n",
      "   [ 61  47  47]\n",
      "   [ 56  44  44]\n",
      "   [ 45  33  33]]\n",
      "\n",
      "  [[  1   1   0]\n",
      "   [  5   5   3]\n",
      "   [  8   8   6]\n",
      "   ...\n",
      "   [ 58  44  44]\n",
      "   [ 61  47  47]\n",
      "   [ 52  40  40]]\n",
      "\n",
      "  [[  1   1   0]\n",
      "   [  5   5   3]\n",
      "   [  8   8   6]\n",
      "   ...\n",
      "   [ 63  47  48]\n",
      "   [ 55  41  41]\n",
      "   [ 54  40  40]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[118  91  48]\n",
      "   [ 98  76  39]\n",
      "   [ 79  62  36]\n",
      "   ...\n",
      "   [205 158 102]\n",
      "   [207 158 102]\n",
      "   [207 158 102]]\n",
      "\n",
      "  [[124  99  58]\n",
      "   [ 76  53  19]\n",
      "   [ 57  41  16]\n",
      "   ...\n",
      "   [208 163  98]\n",
      "   [206 160  98]\n",
      "   [206 160 101]]\n",
      "\n",
      "  [[123  98  57]\n",
      "   [ 76  53  19]\n",
      "   [ 56  40  15]\n",
      "   ...\n",
      "   [211 166 101]\n",
      "   [209 163 101]\n",
      "   [209 163 104]]]\n",
      "\n",
      "\n",
      " [[[120 153 142]\n",
      "   [114 164 191]\n",
      "   [116  97  80]\n",
      "   ...\n",
      "   [132 120  68]\n",
      "   [141 129  77]\n",
      "   [153 140 108]]\n",
      "\n",
      "  [[ 81 105  89]\n",
      "   [132 179 199]\n",
      "   [138 116  95]\n",
      "   ...\n",
      "   [133 120  68]\n",
      "   [141 128  76]\n",
      "   [160 147 115]]\n",
      "\n",
      "  [[ 62  77  54]\n",
      "   [176 219 235]\n",
      "   [135 115  91]\n",
      "   ...\n",
      "   [132 114  66]\n",
      "   [152 134  86]\n",
      "   [161 147 118]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  5   6  10]\n",
      "   [  5   5   5]\n",
      "   [  8   4   1]\n",
      "   ...\n",
      "   [138 169 163]\n",
      "   [143 174 168]\n",
      "   [131 160 156]]\n",
      "\n",
      "  [[ 12  10  13]\n",
      "   [ 22  18  17]\n",
      "   [ 19  11   8]\n",
      "   ...\n",
      "   [136 166 156]\n",
      "   [142 172 162]\n",
      "   [149 161 161]]\n",
      "\n",
      "  [[ 23  17   5]\n",
      "   [ 18  19  11]\n",
      "   [ 17  20   9]\n",
      "   ...\n",
      "   [ 12  28  28]\n",
      "   [ 17  27  29]\n",
      "   [ 15  26  28]]]\n",
      "\n",
      "\n",
      " [[[ 42  44  43]\n",
      "   [ 27  29  28]\n",
      "   [ 24  25  27]\n",
      "   ...\n",
      "   [ 99  92  84]\n",
      "   [116 106  96]\n",
      "   [ 80  70  60]]\n",
      "\n",
      "  [[ 50  52  51]\n",
      "   [ 26  28  27]\n",
      "   [ 30  31  33]\n",
      "   ...\n",
      "   [ 96  89  81]\n",
      "   [ 75  65  56]\n",
      "   [ 93  83  74]]\n",
      "\n",
      "  [[ 54  56  53]\n",
      "   [ 28  30  29]\n",
      "   [ 37  39  38]\n",
      "   ...\n",
      "   [112 105  97]\n",
      "   [117 106 100]\n",
      "   [ 94  83  77]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[142 135 129]\n",
      "   [138 131 125]\n",
      "   [132 125 119]\n",
      "   ...\n",
      "   [106 104 105]\n",
      "   [106 106 106]\n",
      "   [106 106 106]]\n",
      "\n",
      "  [[133 126 120]\n",
      "   [137 130 124]\n",
      "   [143 136 130]\n",
      "   ...\n",
      "   [ 98  96  97]\n",
      "   [ 92  92  92]\n",
      "   [ 94  94  94]]\n",
      "\n",
      "  [[138 131 125]\n",
      "   [138 131 125]\n",
      "   [141 134 128]\n",
      "   ...\n",
      "   [ 89  87  88]\n",
      "   [ 84  84  84]\n",
      "   [ 89  89  89]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[198   5  10]\n",
      "   [198   5  10]\n",
      "   [198   5  10]\n",
      "   ...\n",
      "   [197   4   9]\n",
      "   [197   4   9]\n",
      "   [193   4   8]]\n",
      "\n",
      "  [[198   5  10]\n",
      "   [198   5  10]\n",
      "   [198   5  10]\n",
      "   ...\n",
      "   [197   4   9]\n",
      "   [197   4   9]\n",
      "   [193   4   8]]\n",
      "\n",
      "  [[198   5  10]\n",
      "   [198   5  10]\n",
      "   [198   5  10]\n",
      "   ...\n",
      "   [197   4   9]\n",
      "   [197   4   9]\n",
      "   [194   5   9]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[202   9  14]\n",
      "   [202   7  13]\n",
      "   [205   6  13]\n",
      "   ...\n",
      "   [199  10  16]\n",
      "   [198   9  15]\n",
      "   [200  11  17]]\n",
      "\n",
      "  [[203   8  14]\n",
      "   [203   6  13]\n",
      "   [205   6  13]\n",
      "   ...\n",
      "   [197  10  17]\n",
      "   [196   9  16]\n",
      "   [204  15  21]]\n",
      "\n",
      "  [[206   7  14]\n",
      "   [206   5  13]\n",
      "   [206   5  13]\n",
      "   ...\n",
      "   [197  10  17]\n",
      "   [196   9  16]\n",
      "   [198  12  17]]]\n",
      "\n",
      "\n",
      " [[[174 141 106]\n",
      "   [168 135 100]\n",
      "   [166 133  98]\n",
      "   ...\n",
      "   [148 117  86]\n",
      "   [150 119  88]\n",
      "   [153 122  91]]\n",
      "\n",
      "  [[175 142 107]\n",
      "   [172 139 104]\n",
      "   [172 139 104]\n",
      "   ...\n",
      "   [150 119  88]\n",
      "   [151 120  89]\n",
      "   [155 124  93]]\n",
      "\n",
      "  [[174 141 106]\n",
      "   [174 141 106]\n",
      "   [177 144 109]\n",
      "   ...\n",
      "   [154 123  92]\n",
      "   [153 122  91]\n",
      "   [152 121  90]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[118  92  95]\n",
      "   [123  97  96]\n",
      "   [124  99  95]\n",
      "   ...\n",
      "   [249 245 109]\n",
      "   [247 243 107]\n",
      "   [244 240 104]]\n",
      "\n",
      "  [[107  81  82]\n",
      "   [126 101  97]\n",
      "   [124  99  94]\n",
      "   ...\n",
      "   [247 243 109]\n",
      "   [246 242 108]\n",
      "   [244 240 106]]\n",
      "\n",
      "  [[101  72  68]\n",
      "   [122  94  90]\n",
      "   [116  91  87]\n",
      "   ...\n",
      "   [248 243  97]\n",
      "   [247 242  98]\n",
      "   [246 239 106]]]\n",
      "\n",
      "\n",
      " [[[124 101  87]\n",
      "   [124 101  87]\n",
      "   [125 102  88]\n",
      "   ...\n",
      "   [ 47  38  59]\n",
      "   [ 44  34  58]\n",
      "   [ 42  32  57]]\n",
      "\n",
      "  [[120  97  83]\n",
      "   [124 101  87]\n",
      "   [127 104  90]\n",
      "   ...\n",
      "   [ 52  43  64]\n",
      "   [ 49  39  63]\n",
      "   [ 46  36  61]]\n",
      "\n",
      "  [[129 106  92]\n",
      "   [133 110  96]\n",
      "   [137 114 100]\n",
      "   ...\n",
      "   [ 50  41  60]\n",
      "   [ 47  38  59]\n",
      "   [ 46  36  60]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[174 156 168]\n",
      "   [173 155 167]\n",
      "   [173 155 167]\n",
      "   ...\n",
      "   [203 181 184]\n",
      "   [202 180 183]\n",
      "   [206 184 187]]\n",
      "\n",
      "  [[175 157 169]\n",
      "   [175 157 169]\n",
      "   [176 158 170]\n",
      "   ...\n",
      "   [203 181 184]\n",
      "   [199 177 180]\n",
      "   [201 179 182]]\n",
      "\n",
      "  [[171 153 165]\n",
      "   [172 154 166]\n",
      "   [172 154 166]\n",
      "   ...\n",
      "   [197 175 178]\n",
      "   [198 176 179]\n",
      "   [202 180 183]]]] [0 0 1 ... 0 1 1]\n",
      "(5000, 224, 224, 3) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train, y_train)\n",
    "\n",
    "print(x_temp, y_temp)\n",
    "print(x_temp.shape, y_temp.shape)\n",
    "\n",
    "print(x_val, y_val)\n",
    "\n",
    "print(x_test, y_test)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89f4b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg_block(input_layer, num_cnn=3, channel=64, block_num=1):\n",
    "    x = input_layer\n",
    "    \n",
    "    for cnn_num in range(num_cnn):\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(3,3),\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_conv{cnn_num}')(x)\n",
    "\n",
    "    x = keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=2,\n",
    "        name=f'block{block_num}_pooling')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb0f591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg(input_shape=(image_size,image_size,3),\n",
    "              num_cnn_list=[2,2,3,3,3],\n",
    "              channel_list=[64,128,256,512,512],\n",
    "              num_classes=2):\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    output = input_layer\n",
    "    \n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_vgg_block(\n",
    "            output,\n",
    "            num_cnn=num_cnn, \n",
    "            channel=channel,\n",
    "            block_num=i\n",
    "    )\n",
    "        \n",
    "    output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(4096, activation='relu', kernel_regularizer='l2', name='fc1')(output)\n",
    "    output = keras.layers.Dropout(0.5)(output)\n",
    "    output = keras.layers.Dense(4096, activation='relu', kernel_regularizer='l2', name='fc2')(output)\n",
    "    output = keras.layers.Dropout(0.5)(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8c8bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8128a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "model = build_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3858fad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, clipnorm=1.),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6b2dd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block0_conv0 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block0_conv1 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block0_pooling (MaxPooling2D (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block1_conv0 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block1_pooling (MaxPooling2D (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv0 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block2_pooling (MaxPooling2D (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv0 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block3_pooling (MaxPooling2D (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv0 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pooling (MaxPooling2D (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 134,268,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92ea648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/vgg_minibatch/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f94db7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "model_checkpoint = ModelCheckpoint('vgg16.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e16c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb98b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op SummaryWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op CreateSummaryFileWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op WriteGraphSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op WriteSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op FlushSummaryWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Epoch 1/50\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "        1/150528000 [..............................] - ETA: 0s - loss: 111.3669 - accuracy: 1.0000Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalAnd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op WriteSummary in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "WARNING:tensorflow:From C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "Executing op FlushSummaryWriter in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "        2/150528000 [..............................] - ETA: 2038:33:58 - loss: 111.3521 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 0.0885s). Check your callbacks.\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "        3/150528000 [..............................] - ETA: 2070:12:29 - loss: 111.3284 - accuracy: 1.0000Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "        5/150528000 [..............................] - ETA: 2068:51:44 - loss: 111.2571 - accuracy: 1.0000Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "        7/150528000 [..............................] - ETA: 2073:31:24 - loss: 213.2949 - accuracy: 0.7143Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "        8/150528000 [..............................] - ETA: 2080:00:45 - loss: 228.3714 - accuracy: 0.6250Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       10/150528000 [..............................] - ETA: 2076:51:40 - loss: 204.8230 - accuracy: 0.7000Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       11/150528000 [..............................] - ETA: 2085:12:21 - loss: 196.2435 - accuracy: 0.7273Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       13/150528000 [..............................] - ETA: 2082:04:24 - loss: 183.0098 - accuracy: 0.7692Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       15/150528000 [..............................] - ETA: 2079:36:57 - loss: 219.7709 - accuracy: 0.6667Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       16/150528000 [..............................] - ETA: 2082:37:12 - loss: 212.8901 - accuracy: 0.6875Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       18/150528000 [..............................] - ETA: 2080:32:56 - loss: 201.3957 - accuracy: 0.7222Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       19/150528000 [..............................] - ETA: 2082:34:15 - loss: 252.4728 - accuracy: 0.6842Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       21/150528000 [..............................] - ETA: 2084:03:34 - loss: 297.5992 - accuracy: 0.6667Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       23/150528000 [..............................] - ETA: 2082:51:19 - loss: 285.5417 - accuracy: 0.6087Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       24/150528000 [..............................] - ETA: 2083:26:48 - loss: 280.6432 - accuracy: 0.5833Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       26/150528000 [..............................] - ETA: 2083:36:59 - loss: 267.3820 - accuracy: 0.6154Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       28/150528000 [..............................] - ETA: 2083:40:52 - loss: 257.6363 - accuracy: 0.6071Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       30/150528000 [..............................] - ETA: 2082:25:24 - loss: 250.5098 - accuracy: 0.6000Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       31/150528000 [..............................] - ETA: 2083:51:34 - loss: 245.8962 - accuracy: 0.6129Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       33/150528000 [..............................] - ETA: 2083:47:18 - loss: 249.1343 - accuracy: 0.6061Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       35/150528000 [..............................] - ETA: 2083:54:35 - loss: 245.2832 - accuracy: 0.5714Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       37/150528000 [..............................] - ETA: 2083:55:53 - loss: 237.7952 - accuracy: 0.5946Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       39/150528000 [..............................] - ETA: 2084:01:12 - loss: 235.7097 - accuracy: 0.5897Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       40/150528000 [..............................] - ETA: 2084:45:49 - loss: 237.7296 - accuracy: 0.5750Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       42/150528000 [..............................] - ETA: 2084:46:36 - loss: 231.4588 - accuracy: 0.5952Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       44/150528000 [..............................] - ETA: 2085:27:35 - loss: 229.0372 - accuracy: 0.5909Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       46/150528000 [..............................] - ETA: 2085:10:08 - loss: 223.6616 - accuracy: 0.6087Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       47/150528000 [..............................] - ETA: 2085:58:15 - loss: 221.1398 - accuracy: 0.6170Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       49/150528000 [..............................] - ETA: 2085:56:13 - loss: 216.3931 - accuracy: 0.6327Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       51/150528000 [..............................] - ETA: 2085:37:17 - loss: 213.1592 - accuracy: 0.6275Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       52/150528000 [..............................] - ETA: 2086:24:54 - loss: 211.0624 - accuracy: 0.6346Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       54/150528000 [..............................] - ETA: 2085:36:56 - loss: 207.9272 - accuracy: 0.6296Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       55/150528000 [..............................] - ETA: 2086:21:49 - loss: 206.2141 - accuracy: 0.6182Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       57/150528000 [..............................] - ETA: 2086:28:58 - loss: 202.6037 - accuracy: 0.6316Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       59/150528000 [..............................] - ETA: 2086:24:29 - loss: 201.5321 - accuracy: 0.6271Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       60/150528000 [..............................] - ETA: 2087:04:55 - loss: 200.2735 - accuracy: 0.6167Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       62/150528000 [..............................] - ETA: 2086:53:18 - loss: 197.1714 - accuracy: 0.6129Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       63/150528000 [..............................] - ETA: 2087:31:23 - loss: 195.6655 - accuracy: 0.6190Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       65/150528000 [..............................] - ETA: 2087:28:50 - loss: 192.8074 - accuracy: 0.6154Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       67/150528000 [..............................] - ETA: 2087:24:34 - loss: 190.8000 - accuracy: 0.6119Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       69/150528000 [..............................] - ETA: 2087:20:32 - loss: 188.2113 - accuracy: 0.6232Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       71/150528000 [..............................] - ETA: 2087:16:43 - loss: 186.4931 - accuracy: 0.6197Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       73/150528000 [..............................] - ETA: 2087:08:49 - loss: 184.2700 - accuracy: 0.6164Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       74/150528000 [..............................] - ETA: 2087:17:29 - loss: 183.1615 - accuracy: 0.6081Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       75/150528000 [..............................] - ETA: 2087:37:20 - loss: 182.0719 - accuracy: 0.6000Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       77/150528000 [..............................] - ETA: 2087:31:33 - loss: 180.0254 - accuracy: 0.5844Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       78/150528000 [..............................] - ETA: 2088:01:46 - loss: 179.0006 - accuracy: 0.5897Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       80/150528000 [..............................] - ETA: 2087:54:02 - loss: 177.0232 - accuracy: 0.6000Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       82/150528000 [..............................] - ETA: 2087:46:24 - loss: 175.3364 - accuracy: 0.5976Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       83/150528000 [..............................] - ETA: 2088:15:34 - loss: 174.4211 - accuracy: 0.6024Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       84/150528000 [..............................] - ETA: 2088:42:11 - loss: 173.5258 - accuracy: 0.6071Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       85/150528000 [..............................] - ETA: 2089:39:20 - loss: 172.6498 - accuracy: 0.6118Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       87/150528000 [..............................] - ETA: 2089:23:07 - loss: 171.5190 - accuracy: 0.5977Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       89/150528000 [..............................] - ETA: 2089:17:16 - loss: 169.8792 - accuracy: 0.6067Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       91/150528000 [..............................] - ETA: 2089:27:58 - loss: 168.5924 - accuracy: 0.6044Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       92/150528000 [..............................] - ETA: 2089:53:11 - loss: 167.8918 - accuracy: 0.5978Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       93/150528000 [..............................] - ETA: 2090:48:07 - loss: 167.1388 - accuracy: 0.6022Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       94/150528000 [..............................] - ETA: 2091:11:09 - loss: 166.4014 - accuracy: 0.6064Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       96/150528000 [..............................] - ETA: 2090:38:11 - loss: 165.1664 - accuracy: 0.6042Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       97/150528000 [..............................] - ETA: 2090:59:50 - loss: 164.5066 - accuracy: 0.5979Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       98/150528000 [..............................] - ETA: 2091:23:31 - loss: 163.8642 - accuracy: 0.5918Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "       99/150528000 [..............................] - ETA: 2091:45:44 - loss: 163.1927 - accuracy: 0.5960Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      100/150528000 [..............................] - ETA: 2092:06:46 - loss: 162.5370 - accuracy: 0.6000Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      101/150528000 [..............................] - ETA: 2092:27:23 - loss: 161.8880 - accuracy: 0.6040Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      102/150528000 [..............................] - ETA: 2092:52:22 - loss: 161.2525 - accuracy: 0.6078Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      104/150528000 [..............................] - ETA: 2092:20:43 - loss: 160.0733 - accuracy: 0.6058Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      106/150528000 [..............................] - ETA: 2091:49:39 - loss: 159.0987 - accuracy: 0.5943Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      107/150528000 [..............................] - ETA: 2091:53:14 - loss: 158.5135 - accuracy: 0.5981Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      109/150528000 [..............................] - ETA: 2091:21:45 - loss: 157.5238 - accuracy: 0.5872Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      110/150528000 [..............................] - ETA: 2091:31:08 - loss: 156.9849 - accuracy: 0.5818Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      112/150528000 [..............................] - ETA: 2090:58:45 - loss: 155.9286 - accuracy: 0.5714Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      114/150528000 [..............................] - ETA: 2090:30:39 - loss: 154.9667 - accuracy: 0.5614Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      116/150528000 [..............................] - ETA: 2090:03:28 - loss: 153.9681 - accuracy: 0.5517Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      118/150528000 [..............................] - ETA: 2089:37:48 - loss: 152.9955 - accuracy: 0.5424Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      120/150528000 [..............................] - ETA: 2089:33:16 - loss: 152.0670 - accuracy: 0.5333Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      121/150528000 [..............................] - ETA: 2089:51:23 - loss: 151.6428 - accuracy: 0.5289Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      123/150528000 [..............................] - ETA: 2089:46:30 - loss: 150.7454 - accuracy: 0.5203Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      125/150528000 [..............................] - ETA: 2089:25:04 - loss: 149.8755 - accuracy: 0.5200Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      126/150528000 [..............................] - ETA: 2089:42:18 - loss: 149.4516 - accuracy: 0.5159Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      128/150528000 [..............................] - ETA: 2089:20:12 - loss: 148.6225 - accuracy: 0.5156Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      130/150528000 [..............................] - ETA: 2089:16:15 - loss: 147.8210 - accuracy: 0.5154Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      132/150528000 [..............................] - ETA: 2089:00:10 - loss: 147.0713 - accuracy: 0.5076Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      134/150528000 [..............................] - ETA: 2088:38:06 - loss: 146.3473 - accuracy: 0.5075Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      135/150528000 [..............................] - ETA: 2088:54:26 - loss: 145.9765 - accuracy: 0.5037Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      137/150528000 [..............................] - ETA: 2088:51:39 - loss: 145.2379 - accuracy: 0.5109Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      139/150528000 [..............................] - ETA: 2088:49:33 - loss: 144.6201 - accuracy: 0.5108Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      141/150528000 [..............................] - ETA: 2088:45:57 - loss: 144.0419 - accuracy: 0.5035Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "      142/150528000 [..............................] - ETA: 2088:50:11 - loss: 143.6974 - accuracy: 0.5070Executing op __inference_train_function_2796 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# without early stopping\n",
    "\n",
    "epoch = 50\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=epoch,\n",
    "    validation_data=(x_val, y_val),\n",
    "    validation_steps=x_val.size//batch_size,\n",
    "    steps_per_epoch=x_test.size//batch_size,\n",
    "    verbose=1,\n",
    "    #callbacks=[tensorboard_callback, early_stopping, model_checkpoint]\n",
    "    callbacks=[tensorboard_callback, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5d9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/vgg_minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a903ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train loss:', history.history['loss'][-1])\n",
    "print('train accuracy:', history.history['accuracy'][-1])\n",
    "\n",
    "print('dev loss:', history.history['val_loss'][-1])\n",
    "print('dev accuracy:', history.history['val_accuracy'][-1])\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "axs[0].plot(range(1,len(history.history['accuracy'])+1), history.history['accuracy'])\n",
    "axs[0].plot(range(1,len(history.history['val_accuracy'])+1),history.history['val_accuracy'])\n",
    "axs[0].set_title('Model Accuracy')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend(['train', 'val'], loc='best')\n",
    "\n",
    "axs[1].plot(range(1,len(history.history['loss'])+1),history.history['loss'])\n",
    "axs[1].plot(range(1,len(history.history['val_loss'])+1),history.history['val_loss'])\n",
    "axs[1].set_title('Model Loss')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend(['train', 'val'], loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('test loss:', test_loss)\n",
    "# print('test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09358675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(predictions)\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in predictions:\n",
    "    if i[0] < i[1]:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10277fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap=\"Greens\",linecolor=\"gray\", fmt='.1f', ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred, target_names=['cat', 'dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf5bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision:- Accuracy of positive predictions.')\n",
    "print('Precision = TP/(TP + FP)')\n",
    "print('Recall:- Fraction of positives that were correctly identified.')\n",
    "print('Recall = TP/(TP+FN)')\n",
    "print('F1 score')\n",
    "print('F1 Score = 2*(Recall * Precision) / (Recall + Precision)')\n",
    "print('Accuracy : (TP+TN) / all')\n",
    "print('macro avg = (normal+abnormal)/2 * precision or recall or f1 score')\n",
    "print('weighted avg = normal/(normal+abnormal) * precision or recall or f1 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a4489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

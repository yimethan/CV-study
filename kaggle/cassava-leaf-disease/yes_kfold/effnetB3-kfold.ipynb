{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:41.742736Z",
     "iopub.status.busy": "2022-05-08T04:13:41.741911Z",
     "iopub.status.idle": "2022-05-08T04:13:47.164743Z",
     "shell.execute_reply": "2022-05-08T04:13:47.164016Z",
     "shell.execute_reply.started": "2022-05-08T04:13:41.742633Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers, applications, optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.166699Z",
     "iopub.status.busy": "2022-05-08T04:13:47.166440Z",
     "iopub.status.idle": "2022-05-08T04:13:47.171840Z",
     "shell.execute_reply": "2022-05-08T04:13:47.171131Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.166665Z"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 300\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.173585Z",
     "iopub.status.busy": "2022-05-08T04:13:47.173310Z",
     "iopub.status.idle": "2022-05-08T04:13:47.211285Z",
     "shell.execute_reply": "2022-05-08T04:13:47.210666Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.173547Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n",
    "train_path = '../input/cassava-leaf-disease-classification/train_images'\n",
    "\n",
    "train_path_second = '../input/more-cassava-disease/train/train/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_id = []\n",
    "second_label = []\n",
    "\n",
    "for img in os.listdir(os.path.join(train_path_second, 'cbb')):\n",
    "    second_id.append('/cbb/'+img)\n",
    "    second_label.append('0')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cbsd')):\n",
    "    second_id.append('/cbsd/'+img)\n",
    "    second_label.append('1')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cgm')):\n",
    "    second_id.append('/cgm/'+img)\n",
    "    second_label.append('2')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'cmd')):\n",
    "    second_id.append('/cmd/'+img)\n",
    "    second_label.append('3')\n",
    "    \n",
    "for img in os.listdir(os.path.join(train_path_second, 'healthy')):\n",
    "    second_id.append('/healthy/'+img)\n",
    "    second_label.append('4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cbb/train-cbb-0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cbb/train-cbb-1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cbb/train-cbb-10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cbb/train-cbb-100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cbb/train-cbb-101.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image_id label\n",
       "0    /cbb/train-cbb-0.jpg     0\n",
       "1    /cbb/train-cbb-1.jpg     0\n",
       "2   /cbb/train-cbb-10.jpg     0\n",
       "3  /cbb/train-cbb-100.jpg     0\n",
       "4  /cbb/train-cbb-101.jpg     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_second = pd.DataFrame({'image_id':second_id, 'label':second_label})\n",
    "\n",
    "train_second.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del second_id\n",
    "del second_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.213506Z",
     "iopub.status.busy": "2022-05-08T04:13:47.213259Z",
     "iopub.status.idle": "2022-05-08T04:13:47.262727Z",
     "shell.execute_reply": "2022-05-08T04:13:47.262119Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.213472Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_path_first(image):\n",
    "    return os.path.join(train_path,image)\n",
    "\n",
    "def image_path_second(image):\n",
    "    return os.path.join(train_path_second, image)\n",
    "\n",
    "train['image_id'] = train['image_id'].apply(image_path_first)\n",
    "train_second['image_id'] = train_second['image_id'].apply(image_path_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.264008Z",
     "iopub.status.busy": "2022-05-08T04:13:47.263708Z",
     "iopub.status.idle": "2022-05-08T04:13:47.288860Z",
     "shell.execute_reply": "2022-05-08T04:13:47.288111Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.263972Z"
    }
   },
   "outputs": [],
   "source": [
    "train['label'] = train['label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id label\n",
       "0  ../input/cassava-leaf-disease-classification/t...     0\n",
       "1  ../input/cassava-leaf-disease-classification/t...     3\n",
       "2  ../input/cassava-leaf-disease-classification/t...     1\n",
       "3  ../input/cassava-leaf-disease-classification/t...     1\n",
       "4  ../input/cassava-leaf-disease-classification/t...     3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine dataframe to train\n",
    "\n",
    "combined_train = pd.concat([train, train_second], ignore_index=True)\n",
    "\n",
    "combined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27048</th>\n",
       "      <td>/healthy/train-healthy-95.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27049</th>\n",
       "      <td>/healthy/train-healthy-96.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27050</th>\n",
       "      <td>/healthy/train-healthy-97.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27051</th>\n",
       "      <td>/healthy/train-healthy-98.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27052</th>\n",
       "      <td>/healthy/train-healthy-99.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_id label\n",
       "27048  /healthy/train-healthy-95.jpg     4\n",
       "27049  /healthy/train-healthy-96.jpg     4\n",
       "27050  /healthy/train-healthy-97.jpg     4\n",
       "27051  /healthy/train-healthy-98.jpg     4\n",
       "27052  /healthy/train-healthy-99.jpg     4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del train_second\n",
    "\n",
    "train = combined_train\n",
    "\n",
    "del combined_train\n",
    "del train_path\n",
    "del train_path_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27048</th>\n",
       "      <td>/healthy/train-healthy-95.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27049</th>\n",
       "      <td>/healthy/train-healthy-96.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27050</th>\n",
       "      <td>/healthy/train-healthy-97.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27051</th>\n",
       "      <td>/healthy/train-healthy-98.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27052</th>\n",
       "      <td>/healthy/train-healthy-99.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_id label\n",
       "27048  /healthy/train-healthy-95.jpg     4\n",
       "27049  /healthy/train-healthy-96.jpg     4\n",
       "27050  /healthy/train-healthy-97.jpg     4\n",
       "27051  /healthy/train-healthy-98.jpg     4\n",
       "27052  /healthy/train-healthy-99.jpg     4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "SKF = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:13:47.290559Z",
     "iopub.status.busy": "2022-05-08T04:13:47.290182Z",
     "iopub.status.idle": "2022-05-08T04:13:47.297720Z",
     "shell.execute_reply": "2022-05-08T04:13:47.296743Z",
     "shell.execute_reply.started": "2022-05-08T04:13:47.290501Z"
    }
   },
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
    "                                horizontal_flip=True, vertical_flip=True, fill_mode='nearest', brightness_range=[0.7, 1.3],\n",
    "                                rotation_range=270, zoom_range=0.2, shear_range=10, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                rescale = 1./255)\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input, rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:14:31.244455Z",
     "iopub.status.busy": "2022-05-08T04:14:31.244043Z",
     "iopub.status.idle": "2022-05-08T04:14:31.251411Z",
     "shell.execute_reply": "2022-05-08T04:14:31.250572Z",
     "shell.execute_reply.started": "2022-05-08T04:14:31.244416Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_efficientnet_b3():\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB3(input_shape=(image_size,image_size,3), include_top=False, weights='imagenet'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T04:14:37.434280Z",
     "iopub.status.busy": "2022-05-08T04:14:37.434024Z",
     "iopub.status.idle": "2022-05-08T04:14:38.228147Z",
     "shell.execute_reply": "2022-05-08T04:14:38.227463Z",
     "shell.execute_reply.started": "2022-05-08T04:14:37.434245Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgZ0lEQVR4nO3dfbhVdZ338fdHMEQNn8ATwwGhPOkIkxpnjPKeOuWU1JRYow2kQRNdTCejmpxKsjvLGeaquwdLS+bmTgPKURl7kJrLyrCtk6M4aBoiGCQGZ0DQfOJYIND3/mP9zpztYe/D5iz22vvE53Vd+2Lt71q/9fuuH5v9ZT3stRQRmJmZDdQhjU7AzMwGNxcSMzPLxYXEzMxycSExM7NcXEjMzCwXFxIzM8vFhcRsACS9XdImSd2STq9h+ZKk96XpCyT9pP5ZmhXDhcQaStK7JK1MX8hbJN0i6X8V0G9IOjHHKr4IfDAijoyIX+xPw4i4LiLelKPvQkgan8ZpaKNzsebmQmINI+mjwFeAfwZagHHA1cC0BqZVqxOA1Y1OwqwZuJBYQ0g6CrgcuCgivhsRz0XEroj4QUR8LC0zTNJXJG1Or69IGpbmvUfSz/us83/2MiQtkvR1Sf8uabukFZJelubdkZo8kPaE/qZCfodI+pSk30jaJmmJpKNSTt3AkNT+11W2742S1kp6RtLXAJXN+5/clbki9fGMpF9KmlS2/V+UtFHSVkn/Iml4mneMpB9KelzSU2m6tU8fj6Rt3yDpgrJ575W0JrX7saQTqvw19YzT02mcXifpSUl/Vrau4yX9XtIoSR2SuiR9UtITkh7t029/2zMybcPTqY//kOTvp0HCf1HWKK8GDgO+188ylwJTgNOAU4EzgE/tRx8zgM8CxwDrgfkAEfHaNP/UdGjqxgpt35NerwdeChwJfC0idkbEkWXtX9a3oaSRwHdSriOBXwNnVsnxTcBrgZcDRwN/A/w2zft8ip8GnAiMAT6d5h0CfJNsz2gc8Hvga6n/I4ArgTdHxIuB1wD3p3nnAp8E3gGMAv4DuL5Kbj3jdHQap9uBG4ALy5aZAfw0Ih5P71+StnkMMAtYKOmkGrbnYqAr5dSScvT9mwaLiPDLr8JfwAXAY/tY5tfAW8renw08mqbfA/y8z/IBnJimFwHfKJv3FmBtpWWr9L0c+EDZ+5OAXcDQfbUHZgJ3l70X2Zfk+/rmDrwB+BVZwTykT5vngJeVxV4NbKjS52nAU2n6COBp4K+B4X2WuwWYXfb+EOB3wAkV1jk+befQstirgE09uQIrgXem6Q5gN3BE2fJLgf+9r+0h2zu9ub+/E7+a9+U9EmuU3wIj93Ei90+A35S9/02K1eqxsunfke1V1KpS30PJ/rdcS9tNPW8i+6bcVGnBiLiNbE/i68BWSQsljSD7n/nhwL3pcM/TwI9SHEmHS/q/6dDbs2SHoY6WNCQiniPbs3k/sCUd3js5dXkC8NWydT5J9iU/pobtIiJWkBWE16V1nggsK1vkqdR/j56/s363B/gC2V7jT9IhuUtqyceagwuJNcpdwA7g3H6W2Uz2xddjXIpB9mV2eM8MSS85wPlV6ns3sLWGtluAsT1vJKn8fV8RcWVETAYmkh36+RjwBNnhqokRcXR6HRW9h9UuJttLelVEjKD3MJTSOn8cEW8ERgNrgf+X5m8C/q5snUdHxPCI+M9KqVVJeTHZ4a13AzdFxI6yecekQ2s9ev7O+t2eiNgeERdHxEuBtwEflXRWtTGz5uJCYg0REc+QHR//uqRz0/+wD5X0Zkn/Jy12PfCpdCJ3ZFr+22neA8BESadJOgz4zH6msJXs3Ec11wN/L2mCpCPJriy7MSJ217Duf0+5vSPtcX2I7NzBXiT9uaRXSTqUrDjuAPZExB/IvvyvkHR8WnaMpLNT0xeTfTE/LelY4LKydbZIOid9oe8EuoE9afa/APMkTUzLHiXp/Crb8TjwB/Yep28BbycrJksqtPuspBdJ+gvgrcC/7Wt7JL1V0omp6D6b8t1TYd3WhFxIrGEi4svAR8lOSj9O9r/lDwLfT4v8E9kx+F8Cq4D7UoyI+BXZcfWfAuuAF1zBVYPPAIvTYZZ3Vph/LdkX5h3ABrIv+Lk1btcTwPnA58gO4bUBd1ZZfATZF+xTZIeBfkv2GxWAT5Ad7rk7Hb76KdleCGSXTQ8n+5/+3WSHiXocQrbHspns0NXrgA+k3L5HdtL7hrTOB4E3V9mO35FdoHBnGqcpKd5F9ncRZCfryz2WtmUzcB3w/ohYW8P2tKX33WR7q1dHRKnKmFmTUXb41sysdpKuBTZHxKfKYh3AtyOitVo7++PkX6ya2X6RNJ7s8uF93hrGDg4+tGVmNZP0j2SHw74QERsanY81Bx/aMjOzXLxHYmZmuRx050hGjhwZ48ePb3QaPPfccxxxxBH7XvAg4LHIeBx6eSx6NctY3HvvvU9ExKhK8w66QjJ+/HhWrlzZ6DQolUp0dHQ0Oo2m4LHIeBx6eSx6NctYSPpNtXk+tGVmZrm4kJiZWS4uJGZmlkvdComka5U9rOfBPvG5kh6WtLrsnkpImidpfZp3dll8sqRVad6V6V48PQ/JuTHFV6QfSZmZWcHquUeyCJhaHpD0erLHqL4iIiaS7ikk6RRgOtndT6cCV0sakpotAOaQ3YunrWyds8luWX0icAXZ/YPMzKxgdSskEXEH2Q3jynUCn4uInWmZbSk+DbghsqfPbSC7sdsZkkYDIyLirvRMhyX03nZ8GtntrAFuAs7q2VsxM7PiFH3578uBv5A0n+xuqv8QEf9F9lCdu8uW60qxXWm6b5z05yaAiNgt6RngOLK7ob6ApDlkezW0tLRQKpUO4CYNTHd3d1Pk0Qw8FhmPQy+PRa/BMBZFF5KhZM/PngL8ObBU0ktJD+PpI/qJs495LwxGLAQWArS3t0czXJPdLNeGNwOPRcbj0Mtj0WswjEXRV211Ad+NzD1kD80ZmeLlT5BrJXueQVea7hunvE16eNBR7H0ozczM6qzoPZLvA28ASpJeDryI7FDUMuBfJX2Z7PnObcA9EbFH0vb0QJ0VwEzgqrSuZcAssofgnAfcFr4D5QGz8fI/K6yv59s62Xh5Tc+MymXcp1fVvQ+zg1HdComk64EOYKSkLrJHgV4LXJsuCX4emJW+/FdLWgo8RPZc7Isioucxm51kV4ANB25JL4BrgG9JWk+2JzK9XttiZmbV1a2QRMSMKrMurLL8fLLHevaNrwQmVYjvIHucqZmZNZB/2W5mZrm4kJiZWS4uJGZmlosLiZmZ5eJCYmZmubiQmJlZLi4kZmaWiwuJmZnl4kJiZma5uJCYmVkuLiRmZpaLC4mZmeXiQmJmZrm4kJiZWS4uJGZmlosLiZmZ5eJCYmZmudStkEi6VtK29FjdvvP+QVJIGlkWmydpvaSHJZ1dFp8saVWad6UkpfgwSTem+ApJ4+u1LWZmVl0990gWAVP7BiWNBd4IbCyLnUL2zPWJqc3Vkoak2QuAOUBbevWsczbwVEScCFwBfL4uW2FmZv2qWyGJiDuAJyvMugL4OBBlsWnADRGxMyI2AOuBMySNBkZExF0REcAS4NyyNovT9E3AWT17K2ZmVpyhRXYm6RzgvyPigT7f+WOAu8ved6XYrjTdN97TZhNAROyW9AxwHPBEhX7nkO3V0NLSQqlUOhCbk0t3d3dT5FHN822dhfW1Y9go1hbQ3yNNPN7Q/J+JInkseg2GsSiskEg6HLgUeFOl2RVi0U+8vzZ7ByMWAgsB2tvbo6OjY1/p1l2pVKIZ8qhm4+VzC+trbVsnJ69bUPd+xs1YVfc+8mj2z0SRPBa9BsNYFHnV1suACcADkh4FWoH7JL2EbE9jbNmyrcDmFG+tEKe8jaShwFFUPpRmZmZ1VFghiYhVEXF8RIyPiPFkheCVEfEYsAyYnq7EmkB2Uv2eiNgCbJc0JZ3/mAncnFa5DJiVps8DbkvnUczMrED1vPz3euAu4CRJXZJmV1s2IlYDS4GHgB8BF0XEnjS7E/gG2Qn4XwO3pPg1wHGS1gMfBS6py4aYmVm/6naOJCJm7GP++D7v5wPzKyy3EphUIb4DOD9flmZmlpd/2W5mZrm4kJiZWS4uJGZmlosLiZmZ5eJCYmZmubiQmJlZLi4kZmaWiwuJmZnl4kJiZma5uJCYmVkuLiRmZpaLC4mZmeXiQmJmZrm4kJiZWS4uJGZmlosLiZmZ5eJCYmZmubiQmJlZLvV8Zvu1krZJerAs9gVJayX9UtL3JB1dNm+epPWSHpZ0dll8sqRVad6VkpTiwyTdmOIrJI2v17aYmVl19dwjWQRM7RO7FZgUEa8AfgXMA5B0CjAdmJjaXC1pSGqzAJgDtKVXzzpnA09FxInAFcDn67YlZmZWVd0KSUTcATzZJ/aTiNid3t4NtKbpacANEbEzIjYA64EzJI0GRkTEXRERwBLg3LI2i9P0TcBZPXsrZmZWnKEN7Pu9wI1pegxZYenRlWK70nTfeE+bTQARsVvSM8BxwBN9O5I0h2yvhpaWFkql0gHbiIHq7u5uijyqeb6ts7C+dgwbxdoC+nukiccbmv8zUSSPRa/BMBYNKSSSLgV2A9f1hCosFv3E+2uzdzBiIbAQoL29PTo6OvYn3boolUo0Qx7VbLx8bmF9rW3r5OR1C+rez7gZq+reRx7N/pkoksei12AYi8Kv2pI0C3grcEE6XAXZnsbYssVagc0p3loh/oI2koYCR9HnUJqZmdVfoYVE0lTgE8A5EfG7slnLgOnpSqwJZCfV74mILcB2SVPS+Y+ZwM1lbWal6fOA28oKk5mZFaRuh7YkXQ90ACMldQGXkV2lNQy4NZ0Xvzsi3h8RqyUtBR4iO+R1UUTsSavqJLsCbDhwS3oBXAN8S9J6sj2R6fXaFjMzq65uhSQiZlQIX9PP8vOB+RXiK4FJFeI7gPPz5GhmZvn5l+1mZpaLC4mZmeXiQmJmZrm4kJiZWS4uJGZmlosLiZmZ5eJCYmZmubiQmJlZLi4kZmaWiwuJmZnl4kJiZma5uJCYmVkuLiRmZpaLC4mZmeXiQmJmZrm4kJiZWS4uJGZmlkvdComkayVtk/RgWexYSbdKWpf+PKZs3jxJ6yU9LOnssvhkSavSvCvTs9tJz3e/McVXSBpfr20xM7Pq6rlHsgiY2id2CbA8ItqA5ek9kk4he+b6xNTmaklDUpsFwBygLb161jkbeCoiTgSuAD5fty0xM7Oq6lZIIuIO4Mk+4WnA4jS9GDi3LH5DROyMiA3AeuAMSaOBERFxV0QEsKRPm5513QSc1bO3YmZmxRlacH8tEbEFICK2SDo+xccAd5ct15Viu9J033hPm01pXbslPQMcBzzRt1NJc8j2amhpaaFUKh2o7Rmw7u7upsijmufbOgvra8ewUawtoL9Hmni8ofk/E0XyWPQaDGNRdCGpptKeRPQT76/N3sGIhcBCgPb29ujo6BhAigdWqVSiGfKoZuPlcwvra21bJyevW1D3fsbNWFX3PvJo9s9EkTwWvQbDWBR91dbWdLiK9Oe2FO8CxpYt1wpsTvHWCvEXtJE0FDiKvQ+lmZlZnRVdSJYBs9L0LODmsvj0dCXWBLKT6vekw2DbJU1J5z9m9mnTs67zgNvSeRQzMytQ3Q5tSboe6ABGSuoCLgM+ByyVNBvYCJwPEBGrJS0FHgJ2AxdFxJ60qk6yK8CGA7ekF8A1wLckrSfbE5ler20xM7Pq6lZIImJGlVlnVVl+PjC/QnwlMKlCfAepEJmZWeP4l+1mZpaLC4mZmeXiQmJmZrm4kJiZWS4uJGZmlktNhUTS8lpiZmZ28On38l9JhwGHk/0W5Bh6b0syAviTOudmZmaDwL5+R/J3wEfIisa99BaSZ4Gv1y8tMzMbLPotJBHxVeCrkuZGxFUF5WRmZoNITb9sj4irJL0GGF/eJiKW1CkvMzMbJGoqJJK+BbwMuB/ouQdWz4OmzMzsIFbrvbbagVN8d10zM+ur1t+RPAi8pJ6JmJnZ4FTrHslI4CFJ9wA7e4IRcU5dsjIzs0Gj1kLymXomYWZmg1etV23dXu9EzMxscKr1qq3tZFdpAbwIOBR4LiJG1CsxMzMbHGo62R4RL46IEel1GPDXwNcG2qmkv5e0WtKDkq6XdJikYyXdKmld+vOYsuXnSVov6WFJZ5fFJ0taleZdmZ7rbmZmBRrQ3X8j4vvAGwbSVtIY4ENAe0RMAoaQPW/9EmB5RLQBy9N7JJ2S5k8EpgJXSxqSVrcAmAO0pdfUgeRkZmYDV+uhrXeUvT2E7HcleX5TMhQYLmkX2U0hNwPzgI40fzFQAj4BTANuiIidwAZJ64EzJD0KjIiIu1KOS4BzgVty5GVmZvup1qu23lY2vRt4lOwLfr9FxH9L+iKwEfg98JOI+ImklojYkpbZIun41GQMcHfZKrpSbFea7hvfi6Q5ZHsutLS0UCqVBpL6AdXd3d0UeVTzfFtnYX3tGDaKtQX090gTjzc0/2eiSB6LXoNhLGq9autvD1SH6dzHNGAC8DTwb5Iu7K9JpZT6ie8djFgILARob2+Pjo6O/ci4PkqlEs2QRzUbL59bWF9r2zo5ed2CuvczbsaquveRR7N/Jorkseg1GMai1gdbtUr6nqRtkrZK+o6k1gH2+ZfAhoh4PCJ2Ad8FXgNslTQ69Tca2JaW7wLGlrVvJTsU1pWm+8bNzKxAtZ5s/yawjOy5JGOAH6TYQGwEpkg6PF1ldRawJq1/VlpmFnBzml4GTJc0TNIEspPq96TDYNslTUnrmVnWxszMClLrOZJREVFeOBZJ+shAOoyIFZJuAu4jO9/yC7LDTkcCSyXNJis256flV0taCjyUlr8oInruQNwJLAKGk51k94l2M7OC1VpInkjnMa5P72cAvx1opxFxGXBZn/BOsr2TSsvPB+ZXiK8EJg00DzMzy6/WQ1vvBd4JPAZsAc4DDtgJeDMzG7xq3SP5R2BWRDwFIOlY4ItkBcbMzA5ite6RvKKniABExJPA6fVJyczMBpNaC8khfe59dSy1782YmdkfsVqLwZeA/0xXWwXZ+ZK9Tn6bmdnBp9Zfti+RtJLsRo0C3hERD9U1MzMzGxRqPjyVCoeLh5mZvcCAbiNvZmbWw4XEzMxycSExM7NcXEjMzCwXFxIzM8vFhcTMzHJxITEzs1xcSMzMLBcXEjMzy8WFxMzMcmlIIZF0tKSbJK2VtEbSqyUdK+lWSevSn+V3G54nab2khyWdXRafLGlVmndlena7mZkVqFF7JF8FfhQRJwOnAmuAS4DlEdEGLE/vkXQKMB2YCEwFrpY0JK1nATAHaEuvqUVuhJmZNaCQSBoBvBa4BiAino+Ip4FpwOK02GLg3DQ9DbghInZGxAZgPXCGpNHAiIi4KyICWFLWxszMCtKIh1O9FHgc+KakU4F7gQ8DLRGxBSAitkg6Pi0/Bri7rH1Xiu1K033je5E0h2zPhZaWFkql0gHbmIHq7u5uijyqeb6ts7C+dgwbxdoC+nukiccbmv8zUSSPRa/BMBaNKCRDgVcCcyNihaSvkg5jVVHpvEf0E987GLEQWAjQ3t4eHR0d+5VwPZRKJZohj2o2Xj63sL7WtnVy8roFde9n3IxVde8jj2b/TBTJY9FrMIxFI86RdAFdEbEivb+JrLBsTYerSH9uK1t+bFn7VmBzirdWiJuZWYEKLyQR8RiwSdJJKXQW2QOzlgGzUmwWcHOaXgZMlzRM0gSyk+r3pMNg2yVNSVdrzSxrY2ZmBWnEoS2AucB1kl4EPAL8LVlRWyppNrAROB8gIlZLWkpWbHYDF0XEnrSeTmARMBy4Jb3MzKxADSkkEXE/0F5h1llVlp8PzK8QXwlMOqDJmZnZfvEv283MLBcXEjMzy8WFxMzMcnEhMTOzXFxIzMwsFxcSMzPLxYXEzMxycSExM7NcXEjMzCwXFxIzM8vFhcTMzHJxITEzs1xcSMzMLBcXEjMzy8WFxMzMcnEhMTOzXFxIzMwsl4YVEklDJP1C0g/T+2Ml3SppXfrzmLJl50laL+lhSWeXxSdLWpXmXZme3W5mZgVq5B7Jh4E1Ze8vAZZHRBuwPL1H0inAdGAiMBW4WtKQ1GYBMAdoS6+pxaRuZmY9GlJIJLUCfwV8oyw8DVicphcD55bFb4iInRGxAVgPnCFpNDAiIu6KiACWlLUxM7OCDG1Qv18BPg68uCzWEhFbACJii6TjU3wMcHfZcl0ptitN943vRdIcsj0XWlpaKJVK+bcgp+7u7qbIo5rn2zoL62vHsFGsLaC/R5p4vKH5PxNF8lj0GgxjUXghkfRWYFtE3Cupo5YmFWLRT3zvYMRCYCFAe3t7dHTU0m19lUolmiGPajZePrewvta2dXLyugV172fcjFV17yOPZv9MFMlj0WswjEUj9kjOBM6R9BbgMGCEpG8DWyWNTnsjo4FtafkuYGxZ+1Zgc4q3VoibmVmBCj9HEhHzIqI1IsaTnUS/LSIuBJYBs9Jis4Cb0/QyYLqkYZImkJ1UvycdBtsuaUq6WmtmWRszMytIo86RVPI5YKmk2cBG4HyAiFgtaSnwELAbuCgi9qQ2ncAiYDhwS3qZmVmBGlpIIqIElNL0b4Gzqiw3H5hfIb4SmFS/DM3gzKvOLKSfmS0zufSqSwvp6865dxbSjx0c/Mt2MzPLxYXEzMxycSExM7NcXEjMzCwXFxIzM8ulmS7/NbMmd/trX1dIP90XvIvbP31ZIX297o7bC+nnj5n3SMzMLBcXEjMzy8WFxMzMcvE5EjOzAfjaxT8opJ+W0/9QWF8f/NLbBtTOeyRmZpaLC4mZmeXiQmJmZrm4kJiZWS4uJGZmlosLiZmZ5eJCYmZmuRReSCSNlfQzSWskrZb04RQ/VtKtktalP48pazNP0npJD0s6uyw+WdKqNO/K9Ox2MzMrUCP2SHYDF0fEnwJTgIsknQJcAiyPiDZgeXpPmjcdmAhMBa6WNCStawEwB2hLr6lFboiZmTWgkETEloi4L01vB9YAY4BpwOK02GLg3DQ9DbghInZGxAZgPXCGpNHAiIi4KyICWFLWxszMCtLQcySSxgOnAyuAlojYAlmxAY5Pi40BNpU160qxMWm6b9zMzArUsHttSToS+A7wkYh4tp/TG5VmRD/xSn3NITsERktLC6VSab/zPdC6u7ubIo9qnm/rLKyvHcNGsbaA/h4Z4HjPbJl5YBOp4rhDjyusr4F+9roveNeBTaSKPccdx/aC+hroWLSc/ocDm0gVQw8vrq+BjkVDComkQ8mKyHUR8d0U3ippdERsSYettqV4FzC2rHkrsDnFWyvE9xIRC4GFAO3t7dHR0XGgNmXASqUSzZBHNRsvn1tYX2vbOjl53YK69zNuxqoBtbv0qksPcCaVzWyZyZKtSwrp68533jmgdkU9bGr7Be/ixdf9ayF9DfTBVkXetHHrL4o5eHT+hR0DateIq7YEXAOsiYgvl81aBsxK07OAm8vi0yUNkzSB7KT6Penw13ZJU9I6Z5a1MTOzgjRij+RM4N3AKkn3p9gngc8BSyXNBjYC5wNExGpJS4GHyK74uigi9qR2ncAiYDhwS3qZmVmBCi8kEfFzKp/fADirSpv5wPwK8ZXApAOXnZmZ7S8/2KrM5I8Vc3wa4H2nHsHFBfR37xeKOXlrZgcv3yLFzMxycSExM7NcXEjMzCwXFxIzM8vFhcTMzHJxITEzs1xcSMzMLBcXEjMzy8WFxMzMcnEhMTOzXFxIzMwsFxcSMzPLxYXEzMxycSExM7NcXEjMzCwXFxIzM8vFhcTMzHIZ9IVE0lRJD0taL+mSRudjZnawGdSFRNIQ4OvAm4FTgBmSTmlsVmZmB5dBXUiAM4D1EfFIRDwP3ABMa3BOZmYHFUVEo3MYMEnnAVMj4n3p/buBV0XEB/ssNweYk96eBDxcaKKVjQSeaHQSTcJjkfE49PJY9GqWsTghIkZVmjG06EwOMFWI7VUZI2IhsLD+6dRO0sqIaG90Hs3AY5HxOPTyWPQaDGMx2A9tdQFjy963ApsblIuZ2UFpsBeS/wLaJE2Q9CJgOrCswTmZmR1UBvWhrYjYLemDwI+BIcC1EbG6wWnVqqkOtTWYxyLjcejlsejV9GMxqE+2m5lZ4w32Q1tmZtZgLiRmZpaLC0nBfEuXjKTDJN0j6QFJqyV9ttE5NYqkayVtk/Rgo3NpNEljJf1M0pr0ufhwo3NqNElDJP1C0g8bnUs1LiQF8i1dXmAn8IaIOBU4DZgqaUpjU2qYRcDURifRJHYDF0fEnwJTgIsO4n8jPT4MrGl0Ev1xISmWb+mSRKY7vT00vQ7KKz8i4g7gyUbn0QwiYktE3Jemt5N9gY5pbFaNI6kV+CvgG43OpT8uJMUaA2wqe9/Fwf2PZIik+4FtwK0RsaLBKVkTkTQeOB04mD8XXwE+DvyhwXn0y4WkWDXd0uVgERF7IuI0sjsSnCFpUoNTsiYh6UjgO8BHIuLZRufTCJLeCmyLiHsbncu+uJAUy7d0qSAingZK+DyBAZIOJSsi10XEdxudTwOdCZwj6VGyw+BvkPTtxqZUmQtJsXxLl0TSKElHp+nhwF8CaxualDWcJAHXAGsi4suNzqeRImJeRLRGxHiy74rbIuLCBqdVkQtJgSJiN9BzS5c1wNJBdEuXA2008DNJvyQrsLdGRNNe3lhPkq4H7gJOktQlaXajc2qgM4F3k/3v+/70ekujk7L++RYpZmaWi/dIzMwsFxcSMzPLxYXEzMxycSExM7NcXEjMzCwXFxKzOpLUvY/54/f3rr+SFkk6L19mZgeOC4mZmeXiQmJWAElHSlou6T5JqySV3/V5qKTFkn4p6SZJh6c2kyXdLuleST+WNLpB6Zv1y4XErBg7gLdHxCuB1wNfSrcDATgJWBgRrwCeBT6Q7jd1FXBeREwGrgXmNyBvs30a2ugEzA4SAv5Z0mvJbgk+BmhJ8zZFxJ1p+tvAh4AfAZOAW1O9GQJsKTRjsxq5kJgV4wJgFDA5InalO7oelub1vU9RkBWe1RHx6uJSNBsYH9oyK8ZRZM+W2CXp9cAJZfPGSeopGDOAnwMPA6N64pIOlTSx0IzNauRCYlaM64B2SSvJ9k7Kb5m/BpiV7oR8LLAgPYr5PODzkh4A7gdeU2zKZrXx3X/NzCwX75GYmVkuLiRmZpaLC4mZmeXiQmJmZrm4kJiZWS4uJGZmlosLiZmZ5fL/AU+h/uYdLyGDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(train['label'])\n",
    "plt.title('Count of disease types')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_var = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4532 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1124 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17110 validated image filenames belonging to 5 classes.\n",
      "Found 4287 validated image filenames belonging to 5 classes.\n",
      "Fold num: 1\n",
      "Train length: 1070\n",
      "Val length: 268\n",
      "Epoch 1/30\n",
      "   2/1070 [..............................] - ETA: 3:00 - loss: 1.5755 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1336s vs `on_train_batch_end` time: 0.2045s). Check your callbacks.\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.7141 - accuracy: 0.7434\n",
      "Epoch 00001: val_loss improved from inf to 1.78438, saving model to ./k_fold_effnet\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 384s 359ms/step - loss: 0.7141 - accuracy: 0.7434 - val_loss: 1.7844 - val_accuracy: 0.3000\n",
      "Epoch 2/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.8188\n",
      "Epoch 00002: val_loss improved from 1.78438 to 1.37277, saving model to ./k_fold_effnet\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 387s 361ms/step - loss: 0.5178 - accuracy: 0.8188 - val_loss: 1.3728 - val_accuracy: 0.4733\n",
      "Epoch 3/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.8412\n",
      "Epoch 00003: val_loss did not improve from 1.37277\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "1070/1070 [==============================] - 387s 361ms/step - loss: 0.4603 - accuracy: 0.8412 - val_loss: 2.0812 - val_accuracy: 0.2414\n",
      "Epoch 4/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.8631\n",
      "Epoch 00004: val_loss improved from 1.37277 to 0.44500, saving model to ./k_fold_effnet\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 382s 357ms/step - loss: 0.3994 - accuracy: 0.8631 - val_loss: 0.4450 - val_accuracy: 0.8470\n",
      "Epoch 5/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.8669\n",
      "Epoch 00005: val_loss did not improve from 0.44500\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "1070/1070 [==============================] - 378s 354ms/step - loss: 0.3856 - accuracy: 0.8669 - val_loss: 0.4622 - val_accuracy: 0.8430\n",
      "Epoch 6/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.8739\n",
      "Epoch 00006: val_loss improved from 0.44500 to 0.41703, saving model to ./k_fold_effnet\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 380s 355ms/step - loss: 0.3682 - accuracy: 0.8739 - val_loss: 0.4170 - val_accuracy: 0.8537\n",
      "Epoch 7/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.8717\n",
      "Epoch 00007: val_loss improved from 0.41703 to 0.40972, saving model to ./k_fold_effnet\\checkpoint_1.h5\n",
      "1070/1070 [==============================] - 380s 356ms/step - loss: 0.3661 - accuracy: 0.8717 - val_loss: 0.4097 - val_accuracy: 0.8575\n",
      "Epoch 8/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.8749\n",
      "Epoch 00008: val_loss did not improve from 0.40972\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "1070/1070 [==============================] - 379s 354ms/step - loss: 0.3651 - accuracy: 0.8749 - val_loss: 0.4100 - val_accuracy: 0.8579\n",
      "Epoch 9/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3544 - accuracy: 0.8761\n",
      "Epoch 00009: val_loss did not improve from 0.40972\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "1070/1070 [==============================] - 384s 359ms/step - loss: 0.3544 - accuracy: 0.8761 - val_loss: 0.4104 - val_accuracy: 0.8575\n",
      "Epoch 10/30\n",
      "1070/1070 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8754Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.40972\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "1070/1070 [==============================] - 385s 360ms/step - loss: 0.3596 - accuracy: 0.8754 - val_loss: 0.4108 - val_accuracy: 0.8575\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4491 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1165 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17151 validated image filenames belonging to 5 classes.\n",
      "Found 4246 validated image filenames belonging to 5 classes.\n",
      "Fold num: 2\n",
      "Train length: 1072\n",
      "Val length: 266\n",
      "Epoch 1/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.7097 - accuracy: 0.7468\n",
      "Epoch 00001: val_loss improved from inf to 1.64895, saving model to ./k_fold_effnet\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 386s 360ms/step - loss: 0.7097 - accuracy: 0.7468 - val_loss: 1.6490 - val_accuracy: 0.2614\n",
      "Epoch 2/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.5286 - accuracy: 0.8187\n",
      "Epoch 00002: val_loss did not improve from 1.64895\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "1072/1072 [==============================] - 380s 354ms/step - loss: 0.5286 - accuracy: 0.8187 - val_loss: 2.3175 - val_accuracy: 0.1705\n",
      "Epoch 3/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.8435\n",
      "Epoch 00003: val_loss improved from 1.64895 to 0.63772, saving model to ./k_fold_effnet\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 381s 356ms/step - loss: 0.4496 - accuracy: 0.8435 - val_loss: 0.6377 - val_accuracy: 0.7659\n",
      "Epoch 4/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4194 - accuracy: 0.8562\n",
      "Epoch 00004: val_loss did not improve from 0.63772\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "1072/1072 [==============================] - 384s 359ms/step - loss: 0.4194 - accuracy: 0.8562 - val_loss: 0.6512 - val_accuracy: 0.7711\n",
      "Epoch 5/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.4001 - accuracy: 0.8620\n",
      "Epoch 00005: val_loss improved from 0.63772 to 0.43844, saving model to ./k_fold_effnet\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 387s 361ms/step - loss: 0.4001 - accuracy: 0.8620 - val_loss: 0.4384 - val_accuracy: 0.8585\n",
      "Epoch 6/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8613\n",
      "Epoch 00006: val_loss improved from 0.43844 to 0.43824, saving model to ./k_fold_effnet\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 381s 356ms/step - loss: 0.3982 - accuracy: 0.8613 - val_loss: 0.4382 - val_accuracy: 0.8559\n",
      "Epoch 7/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3960 - accuracy: 0.8633\n",
      "Epoch 00007: val_loss improved from 0.43824 to 0.43256, saving model to ./k_fold_effnet\\checkpoint_2.h5\n",
      "1072/1072 [==============================] - 383s 358ms/step - loss: 0.3960 - accuracy: 0.8633 - val_loss: 0.4326 - val_accuracy: 0.8556\n",
      "Epoch 8/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.8645\n",
      "Epoch 00008: val_loss did not improve from 0.43256\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "1072/1072 [==============================] - 383s 357ms/step - loss: 0.3971 - accuracy: 0.8645 - val_loss: 0.4388 - val_accuracy: 0.8554\n",
      "Epoch 9/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8681\n",
      "Epoch 00009: val_loss did not improve from 0.43256\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "1072/1072 [==============================] - 380s 355ms/step - loss: 0.3828 - accuracy: 0.8681 - val_loss: 0.4391 - val_accuracy: 0.8556\n",
      "Epoch 10/30\n",
      "1072/1072 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.8683Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.43256\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "1072/1072 [==============================] - 377s 352ms/step - loss: 0.3815 - accuracy: 0.8683 - val_loss: 0.4384 - val_accuracy: 0.8570\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4470 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1186 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17172 validated image filenames belonging to 5 classes.\n",
      "Found 4225 validated image filenames belonging to 5 classes.\n",
      "Fold num: 3\n",
      "Train length: 1074\n",
      "Val length: 265\n",
      "Epoch 1/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.7084 - accuracy: 0.7477\n",
      "Epoch 00001: val_loss improved from inf to 1.82931, saving model to ./k_fold_effnet\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 382s 356ms/step - loss: 0.7084 - accuracy: 0.7477 - val_loss: 1.8293 - val_accuracy: 0.3198\n",
      "Epoch 2/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.5209 - accuracy: 0.8171\n",
      "Epoch 00002: val_loss improved from 1.82931 to 1.42245, saving model to ./k_fold_effnet\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 380s 354ms/step - loss: 0.5209 - accuracy: 0.8171 - val_loss: 1.4224 - val_accuracy: 0.4026\n",
      "Epoch 3/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.4710 - accuracy: 0.8374\n",
      "Epoch 00003: val_loss did not improve from 1.42245\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "1074/1074 [==============================] - 379s 352ms/step - loss: 0.4710 - accuracy: 0.8374 - val_loss: 1.9020 - val_accuracy: 0.2232\n",
      "Epoch 4/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.8596\n",
      "Epoch 00004: val_loss improved from 1.42245 to 0.47350, saving model to ./k_fold_effnet\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 383s 357ms/step - loss: 0.4070 - accuracy: 0.8596 - val_loss: 0.4735 - val_accuracy: 0.8376\n",
      "Epoch 5/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8679\n",
      "Epoch 00005: val_loss improved from 0.47350 to 0.45332, saving model to ./k_fold_effnet\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 382s 356ms/step - loss: 0.3851 - accuracy: 0.8679 - val_loss: 0.4533 - val_accuracy: 0.8471\n",
      "Epoch 6/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3706 - accuracy: 0.8720\n",
      "Epoch 00006: val_loss did not improve from 0.45332\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "1074/1074 [==============================] - 383s 356ms/step - loss: 0.3706 - accuracy: 0.8720 - val_loss: 0.4749 - val_accuracy: 0.8379\n",
      "Epoch 7/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3622 - accuracy: 0.8762\n",
      "Epoch 00007: val_loss improved from 0.45332 to 0.41849, saving model to ./k_fold_effnet\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 387s 360ms/step - loss: 0.3622 - accuracy: 0.8762 - val_loss: 0.4185 - val_accuracy: 0.8537\n",
      "Epoch 8/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3582 - accuracy: 0.8751\n",
      "Epoch 00008: val_loss improved from 0.41849 to 0.41215, saving model to ./k_fold_effnet\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 386s 359ms/step - loss: 0.3582 - accuracy: 0.8751 - val_loss: 0.4121 - val_accuracy: 0.8573\n",
      "Epoch 9/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3472 - accuracy: 0.8797\n",
      "Epoch 00009: val_loss improved from 0.41215 to 0.41041, saving model to ./k_fold_effnet\\checkpoint_3.h5\n",
      "1074/1074 [==============================] - 386s 360ms/step - loss: 0.3472 - accuracy: 0.8797 - val_loss: 0.4104 - val_accuracy: 0.8580\n",
      "Epoch 10/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3433 - accuracy: 0.8803\n",
      "Epoch 00010: val_loss did not improve from 0.41041\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "1074/1074 [==============================] - 389s 362ms/step - loss: 0.3433 - accuracy: 0.8803 - val_loss: 0.4168 - val_accuracy: 0.8566\n",
      "Epoch 11/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.8817\n",
      "Epoch 00011: val_loss did not improve from 0.41041\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "1074/1074 [==============================] - 389s 362ms/step - loss: 0.3399 - accuracy: 0.8817 - val_loss: 0.4142 - val_accuracy: 0.8561\n",
      "Epoch 12/30\n",
      "1074/1074 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.8832Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.41041\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "1074/1074 [==============================] - 390s 363ms/step - loss: 0.3361 - accuracy: 0.8832 - val_loss: 0.4139 - val_accuracy: 0.8556\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4563 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1093 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17080 validated image filenames belonging to 5 classes.\n",
      "Found 4317 validated image filenames belonging to 5 classes.\n",
      "Fold num: 4\n",
      "Train length: 1068\n",
      "Val length: 270\n",
      "Epoch 1/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.7127 - accuracy: 0.7426\n",
      "Epoch 00001: val_loss improved from inf to 1.60570, saving model to ./k_fold_effnet\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 392s 367ms/step - loss: 0.7127 - accuracy: 0.7426 - val_loss: 1.6057 - val_accuracy: 0.2367\n",
      "Epoch 2/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.5184 - accuracy: 0.8198\n",
      "Epoch 00002: val_loss improved from 1.60570 to 1.41007, saving model to ./k_fold_effnet\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 390s 365ms/step - loss: 0.5184 - accuracy: 0.8198 - val_loss: 1.4101 - val_accuracy: 0.4825\n",
      "Epoch 3/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4617 - accuracy: 0.8410\n",
      "Epoch 00003: val_loss did not improve from 1.41007\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "1068/1068 [==============================] - 388s 364ms/step - loss: 0.4617 - accuracy: 0.8410 - val_loss: 20.1928 - val_accuracy: 0.1223\n",
      "Epoch 4/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.8586\n",
      "Epoch 00004: val_loss improved from 1.41007 to 0.51413, saving model to ./k_fold_effnet\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 390s 365ms/step - loss: 0.4048 - accuracy: 0.8586 - val_loss: 0.5141 - val_accuracy: 0.8205\n",
      "Epoch 5/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8662\n",
      "Epoch 00005: val_loss improved from 0.51413 to 0.48332, saving model to ./k_fold_effnet\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 391s 366ms/step - loss: 0.3838 - accuracy: 0.8662 - val_loss: 0.4833 - val_accuracy: 0.8302\n",
      "Epoch 6/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3683 - accuracy: 0.8709\n",
      "Epoch 00006: val_loss did not improve from 0.48332\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "1068/1068 [==============================] - 390s 365ms/step - loss: 0.3683 - accuracy: 0.8709 - val_loss: 1.2892 - val_accuracy: 0.5483\n",
      "Epoch 7/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3508 - accuracy: 0.8772\n",
      "Epoch 00007: val_loss improved from 0.48332 to 0.41139, saving model to ./k_fold_effnet\\checkpoint_4.h5\n",
      "1068/1068 [==============================] - 393s 368ms/step - loss: 0.3508 - accuracy: 0.8772 - val_loss: 0.4114 - val_accuracy: 0.8589\n",
      "Epoch 8/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8783\n",
      "Epoch 00008: val_loss did not improve from 0.41139\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "1068/1068 [==============================] - 381s 357ms/step - loss: 0.3511 - accuracy: 0.8783 - val_loss: 0.4132 - val_accuracy: 0.8562\n",
      "Epoch 9/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3444 - accuracy: 0.8797\n",
      "Epoch 00009: val_loss did not improve from 0.41139\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "1068/1068 [==============================] - 382s 357ms/step - loss: 0.3444 - accuracy: 0.8797 - val_loss: 0.4142 - val_accuracy: 0.8589\n",
      "Epoch 10/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3432 - accuracy: 0.8802Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41139\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "1068/1068 [==============================] - 385s 360ms/step - loss: 0.3432 - accuracy: 0.8802 - val_loss: 0.4120 - val_accuracy: 0.8592\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 4568 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17075 validated image filenames belonging to 5 classes.\n",
      "Found 4322 validated image filenames belonging to 5 classes.\n",
      "Fold num: 5\n",
      "Train length: 1068\n",
      "Val length: 271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pomat\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:279: UserWarning: Found 1088 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.7219 - accuracy: 0.7405\n",
      "Epoch 00001: val_loss improved from inf to 1.49216, saving model to ./k_fold_effnet\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 393s 368ms/step - loss: 0.7219 - accuracy: 0.7405 - val_loss: 1.4922 - val_accuracy: 0.3734\n",
      "Epoch 2/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.5366 - accuracy: 0.8141\n",
      "Epoch 00002: val_loss improved from 1.49216 to 1.43435, saving model to ./k_fold_effnet\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 391s 366ms/step - loss: 0.5366 - accuracy: 0.8141 - val_loss: 1.4343 - val_accuracy: 0.4137\n",
      "Epoch 3/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.8357\n",
      "Epoch 00003: val_loss did not improve from 1.43435\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "1068/1068 [==============================] - 391s 366ms/step - loss: 0.4746 - accuracy: 0.8357 - val_loss: 2.4541 - val_accuracy: 0.1219\n",
      "Epoch 4/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.8572\n",
      "Epoch 00004: val_loss improved from 1.43435 to 0.43961, saving model to ./k_fold_effnet\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 391s 366ms/step - loss: 0.4098 - accuracy: 0.8572 - val_loss: 0.4396 - val_accuracy: 0.8438\n",
      "Epoch 5/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.8644\n",
      "Epoch 00005: val_loss improved from 0.43961 to 0.38860, saving model to ./k_fold_effnet\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 392s 367ms/step - loss: 0.3924 - accuracy: 0.8644 - val_loss: 0.3886 - val_accuracy: 0.8665\n",
      "Epoch 6/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.8727\n",
      "Epoch 00006: val_loss did not improve from 0.38860\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "1068/1068 [==============================] - 393s 368ms/step - loss: 0.3752 - accuracy: 0.8727 - val_loss: 0.9859 - val_accuracy: 0.6312\n",
      "Epoch 7/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3635 - accuracy: 0.8751\n",
      "Epoch 00007: val_loss improved from 0.38860 to 0.37526, saving model to ./k_fold_effnet\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 390s 365ms/step - loss: 0.3635 - accuracy: 0.8751 - val_loss: 0.3753 - val_accuracy: 0.8665\n",
      "Epoch 8/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.8775\n",
      "Epoch 00008: val_loss improved from 0.37526 to 0.37014, saving model to ./k_fold_effnet\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 391s 366ms/step - loss: 0.3517 - accuracy: 0.8775 - val_loss: 0.3701 - val_accuracy: 0.8677\n",
      "Epoch 9/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8782\n",
      "Epoch 00009: val_loss did not improve from 0.37014\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "1068/1068 [==============================] - 391s 366ms/step - loss: 0.3548 - accuracy: 0.8782 - val_loss: 0.3734 - val_accuracy: 0.8690\n",
      "Epoch 10/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.8771\n",
      "Epoch 00010: val_loss improved from 0.37014 to 0.36959, saving model to ./k_fold_effnet\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 390s 365ms/step - loss: 0.3526 - accuracy: 0.8771 - val_loss: 0.3696 - val_accuracy: 0.8688\n",
      "Epoch 11/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3492 - accuracy: 0.8772\n",
      "Epoch 00011: val_loss improved from 0.36959 to 0.36782, saving model to ./k_fold_effnet\\checkpoint_5.h5\n",
      "1068/1068 [==============================] - 395s 370ms/step - loss: 0.3492 - accuracy: 0.8772 - val_loss: 0.3678 - val_accuracy: 0.8711\n",
      "Epoch 12/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8798\n",
      "Epoch 00012: val_loss did not improve from 0.36782\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "1068/1068 [==============================] - 394s 369ms/step - loss: 0.3511 - accuracy: 0.8798 - val_loss: 0.3707 - val_accuracy: 0.8693\n",
      "Epoch 13/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8785\n",
      "Epoch 00013: val_loss did not improve from 0.36782\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "1068/1068 [==============================] - 389s 364ms/step - loss: 0.3513 - accuracy: 0.8785 - val_loss: 0.3720 - val_accuracy: 0.8693\n",
      "Epoch 14/30\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.8766Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.36782\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "1068/1068 [==============================] - 391s 366ms/step - loss: 0.3510 - accuracy: 0.8766 - val_loss: 0.3722 - val_accuracy: 0.8693\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "for train_idx, val_idx in SKF.split(train, train['label']):\n",
    "    training_data = train.iloc[train_idx]\n",
    "    validation_data = train.iloc[val_idx]\n",
    "    \n",
    "    # generator\n",
    "    train_generator = train_gen.flow_from_dataframe(dataframe=training_data, directory=None, x_col='image_id', y_col='label',\n",
    "                                                batch_size=batch_size, seed=1, shuffle=True,\n",
    "                                                class_mode='categorical', target_size=(image_size,image_size))\n",
    "\n",
    "    validation_generator = val_gen.flow_from_dataframe(dataframe=validation_data, directory=None, x_col='image_id', y_col='label',\n",
    "                                                   batch_size=batch_size, seed=1, shuffle=False,\n",
    "                                                   class_mode='categorical', target_size=(image_size,image_size))\n",
    "    \n",
    "    print('Fold num:', fold_var)\n",
    "    print('Train length:', len(train_generator))\n",
    "    print('Val length:', len(validation_generator))\n",
    "    \n",
    "    # build model\n",
    "    model = build_efficientnet_b3()\n",
    "    \n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "    \n",
    "    # callbacks\n",
    "    checkpoint_filename = './k_fold_effnet/checkpoint_' + str(fold_var) + '.h5'\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_filename, monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.2, patience=1, min_lr=0, verbose=1)\n",
    "    \n",
    "    # fit\n",
    "    history = model.fit(train_generator, epochs=30, validation_data=validation_generator, verbose=1,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "                        \n",
    "    # save model\n",
    "    model_filename = './k_fold_effnet/' + str(fold_var) + '.h5'\n",
    "    model.save(model_filename)\n",
    "    \n",
    "    clear_session()\n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/more-cassava-disease/sample_submission_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.132543Z",
     "iopub.status.busy": "2022-05-08T10:53:30.131436Z",
     "iopub.status.idle": "2022-05-08T10:53:30.139242Z",
     "shell.execute_reply": "2022-05-08T10:53:30.138534Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.132482Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = '../input/more-cassava-disease/test/test/test/0'\n",
    "\n",
    "def test_image_path(image):\n",
    "    return os.path.join(test_path,image)\n",
    "\n",
    "test['image_id'] = test['image_id'].apply(test_image_path)\n",
    "test['label'].replace('cbb', '0', inplace=True)\n",
    "test['label'].replace('cbsd', '1', inplace=True)\n",
    "test['label'].replace('cgm', '2', inplace=True)\n",
    "test['label'].replace('cmd', '3', inplace=True)\n",
    "test['label'].replace('healthy', '4', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.141294Z",
     "iopub.status.busy": "2022-05-08T10:53:30.140700Z",
     "iopub.status.idle": "2022-05-08T10:53:30.156795Z",
     "shell.execute_reply": "2022-05-08T10:53:30.156171Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.141256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3774 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = val_gen.flow_from_dataframe(dataframe=test, directory=None, x_col='image_id', y_col='label',\n",
    "                                              preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
    "                                              class_mode='categorical', target_size=(image_size,image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-08T10:53:30.158574Z",
     "iopub.status.busy": "2022-05-08T10:53:30.157879Z",
     "iopub.status.idle": "2022-05-08T10:53:30.468147Z",
     "shell.execute_reply": "2022-05-08T10:53:30.467298Z",
     "shell.execute_reply.started": "2022-05-08T10:53:30.158531Z"
    }
   },
   "outputs": [],
   "source": [
    "output = model.predict(test_generator)\n",
    "output = np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CBB       0.22      0.08      0.12       753\n",
      "        CBSD       0.18      0.18      0.18       731\n",
      "         CGM       0.19      0.14      0.16       706\n",
      "         CMD       0.22      0.45      0.29       800\n",
      "     Healthy       0.21      0.15      0.17       784\n",
      "\n",
      "    accuracy                           0.20      3774\n",
      "   macro avg       0.20      0.20      0.19      3774\n",
      "weighted avg       0.20      0.20      0.19      3774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(test_generator.classes, output, target_names=['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0968c0e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f7bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b15195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers, applications, optimizers\n",
    "from keras.layers import Conv2D, MaxPool2D, AveragePooling2D, Dropout, Flatten, Dense, Activation, GlobalAveragePooling2D, GlobalMaxPooling2D, Input, concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 5\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train data(25000 imgs each)\n",
    "\n",
    "filenames = os.listdir('./input/train/train')\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "    \n",
    "    image = keras.preprocessing.image.load_img(os.path.join('./input/train/train', filename),\n",
    "                                               color_mode='rgb',\n",
    "                                               target_size= (image_size,image_size))\n",
    "    image = np.array(image)\n",
    "    data.append(image)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(data)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d425f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "\n",
    "idx = np.random.permutation(len(data))\n",
    "data, labels = data[idx], labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc69b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train 6(15,000) / val 2(5,000) / test 2(5,000)\n",
    "\n",
    "x_train = data[:15000]\n",
    "y_train = labels[:15000]\n",
    "x_temp, y_temp = data[-10000:], labels[-10000:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947bb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train, y_train)\n",
    "\n",
    "print(x_temp, y_temp)\n",
    "print(x_temp.shape, y_temp.shape)\n",
    "\n",
    "print(x_val, y_val)\n",
    "\n",
    "print(x_test, y_test)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c451b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation in train set (train 15,000 to 75,000)\n",
    "\n",
    "x_train_temp = x_train\n",
    "y_train_temp = y_train\n",
    "\n",
    "x_train_aug = []\n",
    "y_train_aug = []\n",
    "\n",
    "for img, label in zip(x_train_temp, y_train_temp):\n",
    "    curImg = img\n",
    "    \n",
    "    flipped1 = tf.image.flip_left_right(curImg)\n",
    "    flipped2 = tf.image.flip_up_down(curImg)\n",
    "    \n",
    "    x_train_aug.append(flipped1)\n",
    "    x_train_aug.append(flipped2)\n",
    "    \n",
    "    for i in range(3):\n",
    "        cropped = curImg[random.randrange(0,100):random.randrange(180,225), random.randrange(0,100):random.randrange(180,225)]\n",
    "        cropped = cv2.resize(cropped, (image_size, image_size))\n",
    "        x_train_aug.append(cropped)\n",
    "    \n",
    "    for i in range(0, 5):\n",
    "        y_train_aug.append(label)\n",
    "        \n",
    "x_train_aug = np.array(x_train_aug)\n",
    "y_train_aug = np.array(y_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b03430",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train, x_train_aug))\n",
    "y_train = np.concatenate((y_train, y_train_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(x,\n",
    "                     filters_1x1,\n",
    "                     filters_3x3_reduce,\n",
    "                     filters_3x3,\n",
    "                     filters_5x5_reduce,\n",
    "                     filters_5x5,\n",
    "                     filters_pool_proj,\n",
    "                     name=None):\n",
    "    \n",
    "    conv1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu',\n",
    "                    bias_initializer=bias_init)(x)\n",
    "    \n",
    "    conv3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu',\n",
    "                    bias_initializer=bias_init)(x)\n",
    "    conv3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu',\n",
    "                    bias_initializer=bias_init)(conv3x3)\n",
    "\n",
    "    conv5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu',\n",
    "                    bias_initializer=bias_init)(x)\n",
    "    conv5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu',\n",
    "                    bias_initializer=bias_init)(conv5x5)\n",
    "\n",
    "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu',\n",
    "                    bias_initializer=bias_init)(pool_proj)\n",
    "\n",
    "    module = concatenate([conv1x1, conv3x3, conv5x5, pool_proj], axis=3, name=name)\n",
    "    \n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_init = keras.initializers.Constant(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(image_size, image_size, 3))\n",
    "\n",
    "x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2',\n",
    "           bias_initializer=bias_init)(input_layer)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
    "x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n",
    "x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x, filters_1x1=64, filters_3x3_reduce=96, filters_3x3=128,\n",
    "                     filters_5x5_reduce=16, filters_5x5=32, filters_pool_proj=32,\n",
    "                     name='inception_3a')\n",
    "\n",
    "x = inception_module(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=192,\n",
    "                     filters_5x5_reduce=32, filters_5x5=96, filters_pool_proj=64,\n",
    "                     name='inception_3b')\n",
    "\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x, filters_1x1=192, filters_3x3_reduce=96, filters_3x3=208,\n",
    "                     filters_5x5_reduce=16, filters_5x5=48, filters_pool_proj=64,\n",
    "                     name='inception_4a')\n",
    "\n",
    "\n",
    "x1 = AveragePooling2D((5, 5), strides=3)(x)\n",
    "x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n",
    "x1 = Flatten()(x1)\n",
    "x1 = Dense(1024, activation='relu')(x1)\n",
    "x1 = Dropout(0.7)(x1)\n",
    "x1 = Dense(2, activation='softmax', name='auxilliary_output_1')(x1)\n",
    "\n",
    "x = inception_module(x, filters_1x1=160, filters_3x3_reduce=112, filters_3x3=224,\n",
    "                     filters_5x5_reduce=24, filters_5x5=64, filters_pool_proj=64,\n",
    "                     name='inception_4b')\n",
    "\n",
    "x = inception_module(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=256,\n",
    "                     filters_5x5_reduce=24, filters_5x5=64, filters_pool_proj=64,\n",
    "                     name='inception_4c')\n",
    "\n",
    "x = inception_module(x, filters_1x1=112, filters_3x3_reduce=144, filters_3x3=288,\n",
    "                     filters_5x5_reduce=32, filters_5x5=64, filters_pool_proj=64,\n",
    "                     name='inception_4d')\n",
    "\n",
    "\n",
    "x2 = AveragePooling2D((5, 5), strides=3)(x)\n",
    "x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n",
    "x2 = Flatten()(x2)\n",
    "x2 = Dense(1024, activation='relu')(x2)\n",
    "x2 = Dropout(0.7)(x2)\n",
    "x2 = Dense(2, activation='softmax', name='auxilliary_output_2')(x2)\n",
    "\n",
    "x = inception_module(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320,\n",
    "                     filters_5x5_reduce=32, filters_5x5=128, filters_pool_proj=128,\n",
    "                     name='inception_4e')\n",
    "\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320,\n",
    "                     filters_5x5_reduce=32, filters_5x5=128, filters_pool_proj=128,\n",
    "                     name='inception_5a')\n",
    "\n",
    "x = inception_module(x, filters_1x1=384, filters_3x3_reduce=192, filters_3x3=384,\n",
    "                     filters_5x5_reduce=48, filters_5x5=128, filters_pool_proj=128,\n",
    "                     name='inception_5b')\n",
    "\n",
    "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Dense(2, activation='softmax', name='output')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c8bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128a715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model(input_layer, [x, x1, x2], name='inception_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858fad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, clipnorm=1.),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2dd6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/inception_da_new/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a8d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "   if epoch < 10:\n",
    "     return lr\n",
    "   else:\n",
    "     return lr * 0.96\n",
    "    \n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5d9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/inception_da_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without early stopping\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    # validation_steps=x_val.size//batch_size,\n",
    "    # steps_per_epoch=x_train.size//batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train loss:', history.history['loss'][-1])\n",
    "print('train accuracy:', history.history['output_accuracy'][-1])\n",
    "\n",
    "print('dev loss:', history.history['val_loss'][-1])\n",
    "print('dev accuracy:', history.history['val_output_accuracy'][-1])\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "axs[0].plot(range(1,len(history.history['output_accuracy'])+1), history.history['output_accuracy'])\n",
    "axs[0].plot(range(1,len(history.history['val_output_accuracy'])+1),history.history['val_output_accuracy'])\n",
    "axs[0].set_title('Model Accuracy')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend(['train', 'val'], loc='best')\n",
    "\n",
    "axs[1].plot(range(1,len(history.history['output_loss'])+1),history.history['output_loss'])\n",
    "axs[1].plot(range(1,len(history.history['val_output_loss'])+1),history.history['val_output_loss'])\n",
    "axs[1].set_title('Model Loss')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend(['train', 'val'], loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf29d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train loss:', history.history['loss'][-2])\n",
    "print('train accuracy:', history.history['output_accuracy'][-2])\n",
    "\n",
    "print('dev loss:', history.history['val_loss'][-2])\n",
    "print('dev accuracy:', history.history['val_output_accuracy'][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a903ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc8d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)\n",
    "\n",
    "pred = np.array(predictions)\n",
    "\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f346997",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for i in pred[2]:\n",
    "    if i[0] < i[1]:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c505da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbfc402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap=\"Greens\",linecolor=\"gray\", fmt='.1f', ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b98f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred, target_names=['cat', 'dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dccc8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05826f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "14c94b3f8c43df1b6fe55e78369e473655c4a8ca1d6af69cac212f43f7c4f7c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
